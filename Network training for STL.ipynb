{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcf59b9",
   "metadata": {
    "id": "0bcf59b9"
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from torchsummary import summary\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR, MultiStepLR\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10596314",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10596314",
    "outputId": "1d400f3d-811d-4c27-9fba-f3b3faa1384c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device for training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f1aea1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05f1aea1",
    "outputId": "af49d8c9-cc37-4dea-b685-162d616e2707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define transformations \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(96, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "trainset = datasets.STL10(root='../datasets', split='train', download=True, transform=train_transform)\n",
    "valset = datasets.STL10(root='../datasets', split='train', download=True, transform=test_transform)\n",
    "testset = datasets.STL10(root='../datasets', split='test', download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38672bd1",
   "metadata": {
    "id": "38672bd1"
   },
   "outputs": [],
   "source": [
    "# Create rotation function \n",
    "def rotate(image, degree=1):\n",
    "    reshape = np.transpose(image, (1, 2, 0))\n",
    "    rot_image = np.rot90(reshape, degree)\n",
    "    return torch.Tensor(np.transpose(rot_image, (2, 0, 1)).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff73be1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bff73be1",
    "outputId": "6a885803-381b-43ed-b53f-137d1d10dc96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3, 96, 96)\n",
      "<class 'numpy.ndarray'>\n",
      "(5000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_x = trainset.data\n",
    "train_y = trainset.labels\n",
    "val_x = valset.data\n",
    "val_y = valset.labels\n",
    "test_x = testset.data\n",
    "test_y = testset.labels\n",
    "\n",
    "print(train_x.shape)\n",
    "print(type(train_x))\n",
    "print(train_y.shape)\n",
    "print(type(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e398c337",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "e398c337",
    "outputId": "8d9b2b82-fd2b-44b6-8222-b9d6fa2c3ab0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc627bf9f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.transpose(train_x[0], (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd58f00c",
   "metadata": {
    "id": "dd58f00c"
   },
   "outputs": [],
   "source": [
    "# # Expand x_train and y_train\n",
    "# x_train_all = []\n",
    "# y_train_all = []\n",
    "\n",
    "# for inx in range(5000):\n",
    "#     x_train_all.append(train_x[inx])\n",
    "#     x_train_all.append(rotate(train_x[inx]))\n",
    "#     x_train_all.append(rotate(train_x[inx], 2))\n",
    "#     x_train_all.append(rotate(train_x[inx], 3))\n",
    "\n",
    "#     for iny in range(4):\n",
    "#         y_train_all.append((train_y[inx], iny))\n",
    "        \n",
    "# x_train_all = torch.Tensor(x_train_all)\n",
    "# y_train_all = torch.Tensor(y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nGTZoXMhm4hU",
   "metadata": {
    "id": "nGTZoXMhm4hU"
   },
   "outputs": [],
   "source": [
    "# Expand X_train and y_train\n",
    "X_train_all = []\n",
    "y_train_all = []\n",
    "\n",
    "for (x, y) in trainset:\n",
    "    deg = np.random.randint(0, 4)\n",
    "    X_train_all.append(x)\n",
    "    y_train_all.append((y, 0))\n",
    "    X_train_all.append(rotate(x, deg))\n",
    "    y_train_all.append((y, deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "TIvnqQKInmXv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIvnqQKInmXv",
    "outputId": "1534dc71-1d85-4d19-cc2f-e78aad3e3b2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d890e1",
   "metadata": {
    "id": "d5d890e1"
   },
   "outputs": [],
   "source": [
    "# Define my dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a26b26d",
   "metadata": {
    "id": "5a26b26d"
   },
   "outputs": [],
   "source": [
    "# Create DataLoader for the STL10 dataset\n",
    "train_all_loader = DataLoader(MyDataset(X_train_all, y_train_all), batch_size=128, num_workers=2, \n",
    "                                          sampler=sampler.SubsetRandomSampler(range(8000)))\n",
    "\n",
    "val_all_loader = DataLoader(MyDataset(X_train_all, y_train_all), batch_size=128, num_workers=2, \n",
    "                                          sampler=sampler.SubsetRandomSampler(range(8000, 10000)))\n",
    "\n",
    "testloader = DataLoader(testset, batch_size=64, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a5f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.7804,  0.7804,  0.7725,  ...,  0.7961,  0.7882,  0.7961],\n",
      "          [ 0.7804,  0.7725,  0.7882,  ...,  0.7882,  0.7961,  0.7882],\n",
      "          [ 0.7804,  0.7804,  0.7804,  ...,  0.7882,  0.7961,  0.7961],\n",
      "          ...,\n",
      "          [ 0.7412,  0.7804,  0.8118,  ...,  0.3333,  0.5373,  0.5608],\n",
      "          [ 0.8275,  0.6706,  0.5843,  ...,  0.5922,  0.6157,  0.5216],\n",
      "          [ 0.7569,  0.7647,  0.7569,  ...,  0.5373,  0.4039,  0.3647]],\n",
      "\n",
      "         [[ 0.8431,  0.8431,  0.8510,  ...,  0.8275,  0.8353,  0.8431],\n",
      "          [ 0.8431,  0.8431,  0.8431,  ...,  0.8275,  0.8275,  0.8353],\n",
      "          [ 0.8431,  0.8510,  0.8510,  ...,  0.8275,  0.8275,  0.8275],\n",
      "          ...,\n",
      "          [ 0.3647,  0.4431,  0.4588,  ...,  0.1529,  0.2784,  0.3098],\n",
      "          [ 0.5059,  0.3647,  0.2784,  ...,  0.3176,  0.3098,  0.2392],\n",
      "          [ 0.4196,  0.4431,  0.4431,  ...,  0.2000,  0.1451,  0.0824]],\n",
      "\n",
      "         [[ 0.8588,  0.8588,  0.8588,  ...,  0.8510,  0.8510,  0.8431],\n",
      "          [ 0.8588,  0.8588,  0.8588,  ...,  0.8510,  0.8510,  0.8353],\n",
      "          [ 0.8588,  0.8510,  0.8431,  ...,  0.8510,  0.8510,  0.8431],\n",
      "          ...,\n",
      "          [-0.0980, -0.0667, -0.0588,  ..., -0.1059, -0.0431,  0.0588],\n",
      "          [ 0.0431, -0.0510, -0.1451,  ..., -0.0118, -0.0510, -0.1059],\n",
      "          [ 0.0275,  0.0196,  0.0510,  ..., -0.1843, -0.1608, -0.2078]]],\n",
      "\n",
      "\n",
      "        [[[-0.3255, -0.2157, -0.1843,  ..., -0.1059, -0.0745, -0.0902],\n",
      "          [-0.3569, -0.2784, -0.2000,  ..., -0.1451, -0.0667, -0.0667],\n",
      "          [-0.4196, -0.3255, -0.2471,  ..., -0.1373, -0.0824, -0.0353],\n",
      "          ...,\n",
      "          [-0.0667,  0.0667,  0.0353,  ...,  0.2314,  0.0745,  0.1843],\n",
      "          [ 0.2941, -0.0588,  0.0039,  ...,  0.1529,  0.0667, -0.0902],\n",
      "          [ 0.0039,  0.2000, -0.0745,  ...,  0.0275,  0.0667, -0.0353]],\n",
      "\n",
      "         [[-0.4275, -0.3647, -0.3020,  ..., -0.2078, -0.1686, -0.1922],\n",
      "          [-0.4431, -0.3804, -0.3255,  ..., -0.2471, -0.1686, -0.1686],\n",
      "          [-0.4980, -0.3961, -0.3725,  ..., -0.2549, -0.2000, -0.1608],\n",
      "          ...,\n",
      "          [ 0.0118, -0.0118, -0.0902,  ...,  0.6000,  0.4667,  0.5373],\n",
      "          [ 0.5216, -0.0510, -0.0980,  ...,  0.5529,  0.4588,  0.2784],\n",
      "          [ 0.2392,  0.3255, -0.1373,  ...,  0.4667,  0.4902,  0.3569]],\n",
      "\n",
      "         [[-0.4745, -0.4039, -0.3569,  ..., -0.3098, -0.2706, -0.2863],\n",
      "          [-0.4824, -0.4353, -0.3882,  ..., -0.3569, -0.2706, -0.2863],\n",
      "          [-0.5451, -0.4667, -0.4353,  ..., -0.3647, -0.3176, -0.2784],\n",
      "          ...,\n",
      "          [-0.2078, -0.1373, -0.1922,  ...,  0.0353, -0.2157, -0.1373],\n",
      "          [ 0.2471, -0.2314, -0.2235,  ..., -0.0588, -0.2706, -0.3961],\n",
      "          [-0.0824,  0.0745, -0.2627,  ..., -0.1451, -0.1294, -0.2863]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4196,  0.4196,  0.4196,  ...,  0.4353,  0.4431,  0.4353],\n",
      "          [ 0.4196,  0.4118,  0.4196,  ...,  0.4353,  0.4431,  0.4353],\n",
      "          [ 0.4118,  0.4118,  0.4118,  ...,  0.4353,  0.4353,  0.4431],\n",
      "          ...,\n",
      "          [ 0.4118,  0.4118,  0.4275,  ...,  0.3569,  0.3490,  0.3255],\n",
      "          [ 0.4196,  0.4118,  0.4196,  ...,  0.3333,  0.3255,  0.3176],\n",
      "          [ 0.4275,  0.4196,  0.4275,  ...,  0.3255,  0.3176,  0.3176]],\n",
      "\n",
      "         [[ 0.4353,  0.4275,  0.4275,  ...,  0.4431,  0.4431,  0.4510],\n",
      "          [ 0.4275,  0.4196,  0.4275,  ...,  0.4431,  0.4431,  0.4510],\n",
      "          [ 0.4196,  0.4196,  0.4196,  ...,  0.4431,  0.4510,  0.4431],\n",
      "          ...,\n",
      "          [ 0.4118,  0.4118,  0.4275,  ...,  0.3490,  0.3490,  0.3333],\n",
      "          [ 0.4196,  0.4118,  0.4196,  ...,  0.3333,  0.3255,  0.3176],\n",
      "          [ 0.4275,  0.4196,  0.4275,  ...,  0.3255,  0.3176,  0.3098]],\n",
      "\n",
      "         [[ 0.4431,  0.4431,  0.4353,  ...,  0.4431,  0.4431,  0.4431],\n",
      "          [ 0.4431,  0.4431,  0.4431,  ...,  0.4431,  0.4431,  0.4431],\n",
      "          [ 0.4353,  0.4353,  0.4353,  ...,  0.4510,  0.4431,  0.4431],\n",
      "          ...,\n",
      "          [ 0.4118,  0.4196,  0.4353,  ...,  0.3333,  0.3176,  0.3098],\n",
      "          [ 0.4275,  0.4196,  0.4275,  ...,  0.3255,  0.3020,  0.2863],\n",
      "          [ 0.4353,  0.4353,  0.4275,  ...,  0.3176,  0.3020,  0.3020]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0902, -0.0275, -0.0667,  ..., -0.5765, -0.5843, -0.5529],\n",
      "          [-0.1059, -0.0745, -0.0353,  ..., -0.5843, -0.5765, -0.6314],\n",
      "          [-0.0902, -0.0667, -0.0039,  ..., -0.5529, -0.5529, -0.5529],\n",
      "          ...,\n",
      "          [ 0.5843,  0.5765,  0.5765,  ...,  0.5529,  0.5843,  0.5922],\n",
      "          [ 0.5216,  0.5294,  0.5373,  ...,  0.5608,  0.5765,  0.6000],\n",
      "          [ 0.4667,  0.4745,  0.4745,  ...,  0.5686,  0.5765,  0.6078]],\n",
      "\n",
      "         [[ 0.1529,  0.2157,  0.1765,  ..., -0.4667, -0.4510, -0.4118],\n",
      "          [ 0.1373,  0.1686,  0.2078,  ..., -0.4745, -0.4431, -0.4902],\n",
      "          [ 0.1451,  0.1686,  0.2314,  ..., -0.4588, -0.4196, -0.4667],\n",
      "          ...,\n",
      "          [ 0.2471,  0.2549,  0.2706,  ...,  0.2941,  0.3176,  0.3176],\n",
      "          [ 0.2000,  0.2235,  0.2314,  ...,  0.3020,  0.3176,  0.3255],\n",
      "          [ 0.1373,  0.1608,  0.1765,  ...,  0.3176,  0.3333,  0.3412]],\n",
      "\n",
      "         [[ 0.0275,  0.0902,  0.0353,  ..., -0.5608, -0.5373, -0.5294],\n",
      "          [ 0.0196,  0.0431,  0.0745,  ..., -0.5451, -0.5451, -0.6078],\n",
      "          [ 0.0196,  0.0510,  0.0902,  ..., -0.5294, -0.5686, -0.5686],\n",
      "          ...,\n",
      "          [ 0.1765,  0.1765,  0.1922,  ...,  0.2314,  0.2549,  0.2706],\n",
      "          [ 0.0980,  0.0980,  0.1059,  ...,  0.2314,  0.2471,  0.2627],\n",
      "          [ 0.0118,  0.0275,  0.0353,  ...,  0.2471,  0.2549,  0.2706]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2784,  0.2471,  0.2863,  ...,  0.3804,  0.3333,  0.3176],\n",
      "          [ 0.2784,  0.2627,  0.2863,  ...,  0.6941,  0.7098,  0.7490],\n",
      "          [ 0.2706,  0.2784,  0.2706,  ...,  0.9686,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 0.1922,  0.2157,  0.2314,  ...,  0.3098,  0.3098,  0.3333],\n",
      "          [ 0.2000,  0.2000,  0.2000,  ...,  0.3255,  0.3176,  0.3412],\n",
      "          [ 0.2078,  0.1843,  0.1686,  ...,  0.3490,  0.3333,  0.3412]],\n",
      "\n",
      "         [[ 0.4118,  0.3804,  0.4196,  ...,  0.4824,  0.4824,  0.4667],\n",
      "          [ 0.4118,  0.3961,  0.4196,  ...,  0.7961,  0.7647,  0.7804],\n",
      "          [ 0.4118,  0.4118,  0.4118,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 0.3333,  0.3569,  0.3725,  ...,  0.4588,  0.4588,  0.4824],\n",
      "          [ 0.3412,  0.3412,  0.3412,  ...,  0.4745,  0.4667,  0.4902],\n",
      "          [ 0.3490,  0.3255,  0.3098,  ...,  0.4980,  0.4824,  0.4902]],\n",
      "\n",
      "         [[ 0.6314,  0.6000,  0.6392,  ...,  0.6000,  0.5686,  0.5529],\n",
      "          [ 0.6314,  0.6157,  0.6471,  ...,  0.8353,  0.8039,  0.8275],\n",
      "          [ 0.6157,  0.6157,  0.6078,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 0.4980,  0.5137,  0.5294,  ...,  0.5765,  0.5765,  0.6000],\n",
      "          [ 0.4980,  0.4980,  0.4980,  ...,  0.5922,  0.5843,  0.6078],\n",
      "          [ 0.5059,  0.4824,  0.4667,  ...,  0.6157,  0.6000,  0.6078]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3882,  0.6078,  0.7569,  ...,  0.1294, -0.0118,  0.1608],\n",
      "          [ 0.1765,  0.2392,  0.5059,  ...,  0.6314, -0.0980,  0.3882],\n",
      "          [ 0.2000,  0.1843,  0.0431,  ...,  0.7647,  0.1765,  0.4039],\n",
      "          ...,\n",
      "          [-0.4196, -0.4118, -0.3098,  ...,  0.1686,  0.1059, -0.1529],\n",
      "          [-0.4431, -0.4196, -0.3255,  ...,  0.3804,  0.6706,  0.1529],\n",
      "          [-0.5529, -0.4431, -0.4196,  ...,  0.5216,  0.5608,  0.2784]],\n",
      "\n",
      "         [[ 0.4667,  0.6627,  0.7804,  ...,  0.4510,  0.3176,  0.2706],\n",
      "          [ 0.2471,  0.3333,  0.6235,  ...,  0.7569,  0.1843,  0.4196],\n",
      "          [ 0.3098,  0.3098,  0.2392,  ...,  0.8510,  0.4824,  0.4667],\n",
      "          ...,\n",
      "          [-0.3176, -0.3255, -0.2314,  ...,  0.3647,  0.2549,  0.0353],\n",
      "          [-0.3490, -0.3333, -0.2471,  ...,  0.4824,  0.7412,  0.4118],\n",
      "          [-0.4745, -0.3804, -0.3490,  ...,  0.6392,  0.6706,  0.4431]],\n",
      "\n",
      "         [[-0.3176,  0.2863,  0.3804,  ..., -0.4667, -0.4902, -0.1608],\n",
      "          [-0.1294,  0.0824, -0.0510,  ...,  0.3647, -0.4510,  0.2863],\n",
      "          [ 0.3176,  0.0824, -0.0980,  ...,  0.5843, -0.2941,  0.0980],\n",
      "          ...,\n",
      "          [-0.2784, -0.3255, -0.3176,  ..., -0.1294, -0.2235, -0.3725],\n",
      "          [-0.3725, -0.4431, -0.3569,  ...,  0.1451,  0.5373,  0.1137],\n",
      "          [-0.5843, -0.5451, -0.5451,  ...,  0.3490,  0.4745,  0.4667]]]]) tensor([6, 7, 5, 0, 3, 1, 1, 1, 4, 4, 0, 0, 4, 0, 1, 5, 4, 9, 0, 6, 5, 3, 1, 3,\n",
      "        2, 6, 5, 5, 2, 7, 1, 6, 3, 7, 9, 2, 4, 7, 9, 5, 1, 9, 0, 6, 4, 9, 1, 1,\n",
      "        3, 2, 5, 4, 0, 0, 9, 8, 6, 7, 2, 0, 0, 1, 1, 7])\n",
      "tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0824,  0.0980,  0.1059,  ...,  0.2549,  0.2314,  0.1922],\n",
      "          [ 0.0510,  0.0824,  0.0824,  ...,  0.2157,  0.2078,  0.2000],\n",
      "          [ 0.0353,  0.0588,  0.0588,  ...,  0.2235,  0.2157,  0.1922],\n",
      "          ...,\n",
      "          [-0.9294, -0.8824, -0.8275,  ..., -0.9373, -0.9059, -0.9843],\n",
      "          [-0.8353, -0.7490, -0.8118,  ..., -0.9451, -0.9529, -0.9294],\n",
      "          [-0.8588, -0.6706, -0.8431,  ..., -0.9216, -0.9373, -0.9529]],\n",
      "\n",
      "         [[ 0.0431,  0.0353,  0.0431,  ...,  0.1922,  0.1686,  0.1294],\n",
      "          [ 0.0118,  0.0196,  0.0118,  ...,  0.1529,  0.1451,  0.1294],\n",
      "          [-0.0118,  0.0039,  0.0039,  ...,  0.1608,  0.1529,  0.1294],\n",
      "          ...,\n",
      "          [-0.9843, -0.9922, -0.9686,  ..., -0.9922, -0.9686, -0.9843],\n",
      "          [-0.9843, -0.9373, -0.9216,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [-0.9922, -0.8431, -0.8667,  ..., -0.9922, -0.9843, -0.9922]],\n",
      "\n",
      "         [[ 0.0196,  0.0196,  0.0275,  ...,  0.1686,  0.1451,  0.1059],\n",
      "          [-0.0118,  0.0039,  0.0039,  ...,  0.1294,  0.1216,  0.1059],\n",
      "          [-0.0353, -0.0196, -0.0118,  ...,  0.1373,  0.1294,  0.1137],\n",
      "          ...,\n",
      "          [-1.0000, -0.9922, -0.9608,  ..., -1.0000, -0.9686, -0.9922],\n",
      "          [-1.0000, -0.9765, -0.9373,  ..., -0.9922, -0.9922, -0.9843],\n",
      "          [-0.9843, -0.8588, -0.9059,  ..., -0.9922, -0.9765, -0.9922]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 0.0902,  0.1216,  0.1216,  ..., -0.2314, -0.2471, -0.2549],\n",
      "          [ 0.0980,  0.1137,  0.1216,  ..., -0.2157, -0.2157, -0.2314],\n",
      "          [ 0.0902,  0.0902,  0.0980,  ..., -0.2078, -0.2078, -0.2078]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [-0.3490, -0.3412, -0.3333,  ..., -0.2392, -0.2471, -0.2627],\n",
      "          [-0.3569, -0.3490, -0.3412,  ..., -0.2157, -0.2392, -0.2314],\n",
      "          [-0.3647, -0.3490, -0.3412,  ..., -0.2235, -0.2235, -0.2235]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [-0.5216, -0.4980, -0.5137,  ..., -0.1529, -0.1451, -0.1765],\n",
      "          [-0.5216, -0.5216, -0.5137,  ..., -0.1373, -0.1373, -0.1608],\n",
      "          [-0.5137, -0.5137, -0.5216,  ..., -0.1608, -0.1451, -0.1294]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2549,  0.2471,  0.2314,  ...,  0.1059,  0.1059,  0.0980],\n",
      "          [ 0.2314,  0.2157,  0.2078,  ...,  0.0588,  0.0667,  0.0196],\n",
      "          [ 0.2392,  0.2000,  0.1843,  ..., -0.0196,  0.0039, -0.0039],\n",
      "          ...,\n",
      "          [ 0.3725,  0.4039,  0.1765,  ...,  0.3255,  0.4745,  0.4824],\n",
      "          [ 0.3804,  0.4196,  0.3098,  ...,  0.4118,  0.3882,  0.4667],\n",
      "          [ 0.3020,  0.3255,  0.3647,  ...,  0.3804,  0.3255,  0.4039]],\n",
      "\n",
      "         [[ 0.5137,  0.5137,  0.5137,  ...,  0.3804,  0.3804,  0.3804],\n",
      "          [ 0.5137,  0.4980,  0.4980,  ...,  0.3412,  0.3490,  0.3412],\n",
      "          [ 0.5216,  0.4824,  0.4824,  ...,  0.2941,  0.3098,  0.3020],\n",
      "          ...,\n",
      "          [ 0.4824,  0.4745,  0.4118,  ...,  0.4824,  0.6392,  0.6863],\n",
      "          [ 0.5216,  0.5373,  0.4510,  ...,  0.5373,  0.6078,  0.6863],\n",
      "          [ 0.3647,  0.5059,  0.4588,  ...,  0.5294,  0.5216,  0.6157]],\n",
      "\n",
      "         [[ 0.3098,  0.2471,  0.2000,  ...,  0.1294,  0.1216,  0.0667],\n",
      "          [ 0.2549,  0.2157,  0.1608,  ...,  0.0510,  0.0824,  0.0510],\n",
      "          [ 0.2706,  0.1922,  0.1216,  ..., -0.0980, -0.0118,  0.0196],\n",
      "          ...,\n",
      "          [ 0.1765,  0.1137, -0.0431,  ..., -0.0431,  0.1529,  0.2314],\n",
      "          [ 0.1922,  0.2392,  0.0902,  ..., -0.0353,  0.0902,  0.2863],\n",
      "          [ 0.0431,  0.1608,  0.1451,  ..., -0.0588,  0.0275,  0.2235]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.7647, -0.8118, -0.8196,  ...,  0.5765,  0.5451,  0.5294],\n",
      "          [-0.5922, -0.5294, -0.4353,  ...,  0.4039,  0.2941,  0.3176],\n",
      "          [ 0.2000,  0.2706,  0.4510,  ...,  0.5843,  0.5529,  0.3725],\n",
      "          ...,\n",
      "          [-0.0824, -0.1608, -0.2000,  ...,  0.6471,  0.7333,  0.6392],\n",
      "          [-0.0039, -0.0667, -0.1451,  ...,  0.6863,  0.5922,  0.5373],\n",
      "          [-0.1529, -0.1843, -0.2235,  ...,  0.4745,  0.5216,  0.6000]],\n",
      "\n",
      "         [[-0.9294, -0.9451, -0.9137,  ...,  0.5137,  0.4902,  0.4745],\n",
      "          [-0.8118, -0.7412, -0.6000,  ...,  0.3412,  0.2235,  0.2627],\n",
      "          [-0.0588,  0.0118,  0.2078,  ...,  0.5294,  0.4902,  0.3176],\n",
      "          ...,\n",
      "          [-0.1294, -0.2471, -0.3098,  ...,  0.5843,  0.6784,  0.5922],\n",
      "          [-0.0588, -0.1608, -0.2627,  ...,  0.6314,  0.5373,  0.4902],\n",
      "          [-0.2078, -0.2706, -0.3333,  ...,  0.4196,  0.4667,  0.5529]],\n",
      "\n",
      "         [[-0.8902, -0.8980, -0.8902,  ...,  0.4118,  0.3647,  0.3255],\n",
      "          [-0.9843, -0.9216, -0.7569,  ...,  0.2549,  0.1294,  0.1216],\n",
      "          [-0.4902, -0.3961, -0.1373,  ...,  0.4667,  0.4196,  0.2235],\n",
      "          ...,\n",
      "          [-0.4824, -0.6000, -0.6784,  ...,  0.3725,  0.4510,  0.3333],\n",
      "          [-0.4039, -0.5137, -0.6314,  ...,  0.4118,  0.3098,  0.2235],\n",
      "          [-0.5529, -0.6314, -0.7020,  ...,  0.2078,  0.2471,  0.2863]]]]) tensor([9, 6, 1, 8, 0, 4, 2, 1, 7, 1, 2, 7, 5, 3, 5, 7, 3, 0, 9, 3, 0, 1, 8, 0,\n",
      "        2, 5, 4, 1, 3, 6, 5, 1, 7, 5, 8, 5, 8, 3, 0, 2, 8, 7, 1, 2, 3, 4, 3, 2,\n",
      "        8, 1, 9, 0, 1, 4, 8, 1, 4, 1, 8, 5, 2, 7, 8, 3])\n",
      "tensor([[[[ 0.0039, -0.0039,  0.0039,  ...,  0.3176,  0.3333,  0.2863],\n",
      "          [-0.0353, -0.0275, -0.0275,  ...,  0.3333,  0.3098,  0.3098],\n",
      "          [-0.1451, -0.1216, -0.0824,  ...,  0.2706,  0.2784,  0.2549],\n",
      "          ...,\n",
      "          [-0.4431, -0.4510, -0.3882,  ..., -0.4588, -0.4588, -0.5216],\n",
      "          [-0.4745, -0.4980, -0.4275,  ..., -0.4824, -0.4902, -0.5216],\n",
      "          [-0.4745, -0.4745, -0.4431,  ..., -0.5137, -0.5137, -0.6000]],\n",
      "\n",
      "         [[ 0.3569,  0.3333,  0.3412,  ...,  0.5373,  0.5451,  0.5059],\n",
      "          [ 0.3176,  0.3098,  0.2941,  ...,  0.5451,  0.5216,  0.5451],\n",
      "          [ 0.2078,  0.2078,  0.2392,  ...,  0.4980,  0.4980,  0.5216],\n",
      "          ...,\n",
      "          [ 0.2549,  0.2235,  0.2314,  ...,  0.2000,  0.2000,  0.1765],\n",
      "          [ 0.1922,  0.1529,  0.2000,  ...,  0.2000,  0.1843,  0.2078],\n",
      "          [ 0.1294,  0.1294,  0.1373,  ...,  0.1765,  0.1765,  0.1608]],\n",
      "\n",
      "         [[-0.1843, -0.2078, -0.2000,  ...,  0.1373,  0.1451,  0.0510],\n",
      "          [-0.2235, -0.2314, -0.2314,  ...,  0.1216,  0.0902,  0.0431],\n",
      "          [-0.3333, -0.2863, -0.2314,  ...,  0.0745,  0.0980,  0.0588],\n",
      "          ...,\n",
      "          [-0.5137, -0.5373, -0.5137,  ..., -0.6078, -0.6078, -0.6078],\n",
      "          [-0.5216, -0.5529, -0.4980,  ..., -0.6157, -0.6078, -0.6078],\n",
      "          [-0.4980, -0.4980, -0.4667,  ..., -0.6235, -0.6235, -0.6784]]],\n",
      "\n",
      "\n",
      "        [[[-0.5765, -0.5765, -0.5608,  ..., -0.5765, -0.4902, -0.3569],\n",
      "          [-0.5765, -0.5843, -0.5765,  ..., -0.5765, -0.4745, -0.3412],\n",
      "          [-0.5765, -0.5843, -0.5843,  ..., -0.5686, -0.4510, -0.3098],\n",
      "          ...,\n",
      "          [-0.4667, -0.4745, -0.4745,  ...,  0.1294,  0.1294,  0.1059],\n",
      "          [-0.5765, -0.5843, -0.5922,  ..., -0.1059, -0.1137, -0.1373],\n",
      "          [-0.9922, -0.9922, -0.9922,  ..., -0.9922, -0.9922, -0.9922]],\n",
      "\n",
      "         [[-0.5922, -0.6078, -0.6000,  ..., -0.5373, -0.4510, -0.3255],\n",
      "          [-0.5922, -0.6157, -0.6000,  ..., -0.5451, -0.4431, -0.3020],\n",
      "          [-0.5843, -0.6000, -0.5922,  ..., -0.5373, -0.4196, -0.2706],\n",
      "          ...,\n",
      "          [-0.4588, -0.4588, -0.4667,  ...,  0.1373,  0.1373,  0.1137],\n",
      "          [-0.5686, -0.5765, -0.5843,  ..., -0.0980, -0.1059, -0.1294],\n",
      "          [-0.9922, -0.9922, -0.9922,  ..., -0.9922, -0.9922, -0.9922]],\n",
      "\n",
      "         [[-0.6235, -0.6392, -0.6314,  ..., -0.5294, -0.4510, -0.3333],\n",
      "          [-0.6235, -0.6392, -0.6314,  ..., -0.5451, -0.4510, -0.3255],\n",
      "          [-0.6157, -0.6314, -0.6235,  ..., -0.5529, -0.4431, -0.3020],\n",
      "          ...,\n",
      "          [-0.4431, -0.4353, -0.4275,  ...,  0.1686,  0.1686,  0.1529],\n",
      "          [-0.5451, -0.5451, -0.5529,  ..., -0.0667, -0.0745, -0.0980],\n",
      "          [-0.9922, -0.9922, -0.9922,  ..., -0.9922, -0.9922, -0.9922]]],\n",
      "\n",
      "\n",
      "        [[[-0.3569, -0.7569, -0.8980,  ..., -0.8039, -0.7882, -0.7804],\n",
      "          [-0.4353, -0.9137, -0.3490,  ..., -0.8118, -0.8275, -0.7882],\n",
      "          [-0.6078, -0.3647, -0.0039,  ..., -0.8196, -0.8118, -0.8039],\n",
      "          ...,\n",
      "          [ 0.2471,  0.2863,  0.3020,  ..., -0.2392, -0.0745, -0.0745],\n",
      "          [ 0.3098,  0.3333,  0.3725,  ..., -0.2157, -0.0980, -0.0039],\n",
      "          [ 0.4039,  0.4118,  0.4118,  ..., -0.2314, -0.1373,  0.3255]],\n",
      "\n",
      "         [[-0.2392, -0.7882, -0.9216,  ..., -0.7961, -0.8039, -0.7961],\n",
      "          [-0.4196, -0.9294, -0.4667,  ..., -0.7647, -0.8039, -0.7882],\n",
      "          [-0.7333, -0.4353,  0.0353,  ..., -0.8118, -0.8196, -0.8039],\n",
      "          ...,\n",
      "          [ 0.3098,  0.3255,  0.3412,  ..., -0.2314, -0.0510, -0.0431],\n",
      "          [ 0.3412,  0.3490,  0.3961,  ..., -0.2235, -0.0667,  0.0431],\n",
      "          [ 0.4588,  0.4353,  0.4275,  ..., -0.2314, -0.1059,  0.3961]],\n",
      "\n",
      "         [[-0.3176, -0.7804, -0.8902,  ..., -0.6863, -0.7255, -0.7098],\n",
      "          [-0.4353, -0.9059, -0.5765,  ..., -0.6941, -0.7412, -0.7020],\n",
      "          [-0.6941, -0.4824, -0.2314,  ..., -0.7725, -0.7725, -0.7569],\n",
      "          ...,\n",
      "          [ 0.3961,  0.4039,  0.4196,  ..., -0.2392, -0.0353, -0.0431],\n",
      "          [ 0.3804,  0.3961,  0.4431,  ..., -0.2235, -0.0510,  0.0588],\n",
      "          [ 0.5059,  0.4902,  0.5059,  ..., -0.2392, -0.1059,  0.3725]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2863,  0.5529, -0.3490,  ..., -0.5765, -0.5686, -0.6078],\n",
      "          [-0.2078,  0.0902, -0.4667,  ..., -0.6941, -0.6235, -0.6314],\n",
      "          [-0.2784,  0.1216, -0.4902,  ..., -0.7490, -0.6157, -0.6784],\n",
      "          ...,\n",
      "          [-0.0510, -0.0667, -0.1765,  ..., -0.0824, -0.1529, -0.1059],\n",
      "          [-0.0353, -0.0588, -0.0588,  ..., -0.1529, -0.1059,  0.0275],\n",
      "          [-0.0118, -0.0588, -0.0118,  ..., -0.0275, -0.0510,  0.0118]],\n",
      "\n",
      "         [[ 0.0431,  0.3255, -0.3333,  ..., -0.4824, -0.5059, -0.5216],\n",
      "          [-0.2863, -0.0196, -0.4510,  ..., -0.6157, -0.5451, -0.5529],\n",
      "          [-0.3020, -0.0745, -0.4588,  ..., -0.7020, -0.6235, -0.6392],\n",
      "          ...,\n",
      "          [ 0.0510,  0.0196, -0.0588,  ...,  0.0431, -0.0118,  0.0196],\n",
      "          [ 0.0824,  0.0588,  0.0510,  ..., -0.0275,  0.0196,  0.0980],\n",
      "          [ 0.0510,  0.0039,  0.0667,  ...,  0.0588,  0.0588,  0.0902]],\n",
      "\n",
      "         [[-0.6627, -0.6314, -0.7647,  ..., -0.7255, -0.7255, -0.7647],\n",
      "          [-0.7176, -0.6863, -0.7569,  ..., -0.7725, -0.7412, -0.7255],\n",
      "          [-0.7255, -0.7412, -0.7961,  ..., -0.7725, -0.6784, -0.7333],\n",
      "          ...,\n",
      "          [-0.4431, -0.4196, -0.4902,  ..., -0.4275, -0.4588, -0.3961],\n",
      "          [-0.4196, -0.4431, -0.4431,  ..., -0.5216, -0.4667, -0.3255],\n",
      "          [-0.3490, -0.3961, -0.3804,  ..., -0.3882, -0.4118, -0.3725]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]]) tensor([4, 3, 6, 9, 7, 1, 5, 3, 0, 1, 5, 7, 1, 7, 1, 4, 4, 3, 3, 9, 6, 3, 3, 8,\n",
      "        7, 5, 0, 1, 7, 1, 2, 8, 6, 5, 5, 3, 3, 8, 9, 1, 0, 6, 6, 4, 4, 4, 8, 2,\n",
      "        3, 3, 1, 2, 0, 5, 8, 7, 8, 3, 7, 2, 6, 9, 6, 9])\n",
      "tensor([[[[-0.8510, -0.8353, -0.8275,  ..., -0.3804, -0.3647, -0.3804],\n",
      "          [-0.8039, -0.8118, -0.8118,  ..., -0.3020, -0.3098, -0.2784],\n",
      "          [-0.7804, -0.7255, -0.7098,  ..., -0.4353, -0.4588, -0.3882],\n",
      "          ...,\n",
      "          [-0.8353, -0.8275, -0.8353,  ..., -0.8039, -0.8118, -0.8118],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.8196, -0.8118, -0.7961,  ..., -0.3412, -0.3255, -0.3333],\n",
      "          [-0.7882, -0.7647, -0.7490,  ..., -0.2706, -0.2706, -0.2549],\n",
      "          [-0.7490, -0.7020, -0.7020,  ..., -0.3647, -0.3725, -0.3333],\n",
      "          ...,\n",
      "          [-0.8353, -0.8353, -0.8510,  ..., -0.8118, -0.8275, -0.8196],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.7961, -0.7804, -0.7725,  ..., -0.3255, -0.3098, -0.3333],\n",
      "          [-0.7569, -0.7490, -0.7412,  ..., -0.2392, -0.2392, -0.2314],\n",
      "          [-0.7569, -0.7176, -0.7176,  ..., -0.3647, -0.3725, -0.3255],\n",
      "          ...,\n",
      "          [-0.8510, -0.8510, -0.8667,  ..., -0.8275, -0.8431, -0.8431],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9686,  0.9686,  0.9529,  ...,  0.9922,  0.9843,  0.9608],\n",
      "          [ 0.9608,  0.9686,  0.9608,  ...,  0.9843,  0.9843,  0.9765],\n",
      "          [ 0.9686,  0.9686,  0.9608,  ...,  0.9922,  0.9922,  0.9765],\n",
      "          ...,\n",
      "          [-0.0745, -0.0824, -0.1137,  ...,  0.8431,  0.7176,  0.6314],\n",
      "          [-0.1451, -0.1765, -0.1922,  ...,  0.8353,  0.8824,  0.8118],\n",
      "          [-0.0745, -0.0980, -0.1059,  ...,  0.8902,  0.9216,  0.8431]],\n",
      "\n",
      "         [[ 0.6235,  0.6314,  0.6392,  ...,  0.7725,  0.7725,  0.7725],\n",
      "          [ 0.6471,  0.6549,  0.6627,  ...,  0.7961,  0.7961,  0.8039],\n",
      "          [ 0.6706,  0.6706,  0.6784,  ...,  0.8196,  0.8196,  0.8118],\n",
      "          ...,\n",
      "          [-0.4431, -0.4510, -0.4667,  ...,  0.7725,  0.6235,  0.5373],\n",
      "          [-0.5216, -0.5294, -0.5373,  ...,  0.7490,  0.7804,  0.7098],\n",
      "          [-0.4510, -0.4667, -0.4745,  ...,  0.8824,  0.9059,  0.8118]],\n",
      "\n",
      "         [[-0.1216, -0.1137, -0.1137,  ..., -0.0667, -0.0667, -0.0745],\n",
      "          [-0.1059, -0.0980, -0.0980,  ..., -0.0510, -0.0510, -0.0510],\n",
      "          [-0.0902, -0.0902, -0.0824,  ..., -0.0353, -0.0353, -0.0431],\n",
      "          ...,\n",
      "          [-0.4902, -0.4980, -0.5137,  ...,  0.3804,  0.2157,  0.0824],\n",
      "          [-0.5529, -0.5686, -0.5843,  ...,  0.3882,  0.3882,  0.2863],\n",
      "          [-0.5294, -0.5451, -0.5529,  ...,  0.4667,  0.5216,  0.4824]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-0.8902, -0.8667, -0.8510,  ..., -0.8667, -0.8667, -0.8510],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-0.8431, -0.8353, -0.8039,  ..., -0.8275, -0.8196, -0.8039],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-0.7725, -0.7804, -0.7490,  ..., -0.7882, -0.7725, -0.7412],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.5451,  0.5765,  0.6863,  ...,  0.6627,  0.7490,  0.7804],\n",
      "          [ 0.6235,  0.6392,  0.7255,  ...,  0.7098,  0.7490,  0.8118],\n",
      "          [ 0.6471,  0.7176,  0.7647,  ...,  0.6392,  0.7020,  0.7490],\n",
      "          ...,\n",
      "          [ 0.0745, -0.1059, -0.3333,  ...,  0.6471,  0.7255,  0.8745],\n",
      "          [-0.0039, -0.1843, -0.3569,  ...,  0.6549,  0.6784,  0.7647],\n",
      "          [-0.0275, -0.1216, -0.3569,  ...,  0.5686,  0.5765,  0.5765]],\n",
      "\n",
      "         [[ 0.4902,  0.5529,  0.6784,  ...,  0.6235,  0.7020,  0.7412],\n",
      "          [ 0.5765,  0.6235,  0.7176,  ...,  0.6471,  0.6863,  0.7647],\n",
      "          [ 0.5686,  0.6941,  0.7569,  ...,  0.5529,  0.6471,  0.6941],\n",
      "          ...,\n",
      "          [-0.0902, -0.2471, -0.4667,  ...,  0.4824,  0.5294,  0.6863],\n",
      "          [-0.1529, -0.3333, -0.4902,  ...,  0.4902,  0.4980,  0.5843],\n",
      "          [-0.1765, -0.3647, -0.4902,  ...,  0.4118,  0.4431,  0.3961]],\n",
      "\n",
      "         [[ 0.5137,  0.5451,  0.6863,  ...,  0.5843,  0.6471,  0.7098],\n",
      "          [ 0.5843,  0.6157,  0.7412,  ...,  0.5922,  0.6314,  0.7176],\n",
      "          [ 0.5608,  0.6784,  0.7725,  ...,  0.4902,  0.5686,  0.6471],\n",
      "          ...,\n",
      "          [-0.2392, -0.3961, -0.5765,  ...,  0.2863,  0.3176,  0.3020],\n",
      "          [-0.2941, -0.4902, -0.6000,  ...,  0.3176,  0.2784,  0.2784],\n",
      "          [-0.3255, -0.5137, -0.6000,  ...,  0.2392,  0.2784,  0.2078]]],\n",
      "\n",
      "\n",
      "        [[[-0.5765, -0.6706, -0.6941,  ..., -0.7098, -0.7725, -0.6784],\n",
      "          [-0.5294, -0.6392, -0.6706,  ..., -0.7098, -0.7412, -0.6941],\n",
      "          [-0.5765, -0.6314, -0.7020,  ..., -0.7098, -0.7176, -0.6941],\n",
      "          ...,\n",
      "          [-0.0353, -0.1451, -0.0902,  ...,  0.0902,  0.0510,  0.1059],\n",
      "          [-0.2784, -0.3255,  0.0118,  ...,  0.0039,  0.0824,  0.1765],\n",
      "          [-0.2314, -0.0510, -0.0039,  ...,  0.1686,  0.0980,  0.0510]],\n",
      "\n",
      "         [[-0.5765, -0.6706, -0.6941,  ..., -0.7098, -0.7725, -0.6784],\n",
      "          [-0.5294, -0.6392, -0.6706,  ..., -0.7098, -0.7412, -0.6941],\n",
      "          [-0.5765, -0.6314, -0.7020,  ..., -0.7098, -0.7176, -0.6941],\n",
      "          ...,\n",
      "          [-0.0353, -0.1451, -0.0902,  ...,  0.0902,  0.0510,  0.1059],\n",
      "          [-0.2784, -0.3255,  0.0118,  ...,  0.0039,  0.0824,  0.1765],\n",
      "          [-0.2314, -0.0510, -0.0039,  ...,  0.1686,  0.0980,  0.0510]],\n",
      "\n",
      "         [[-0.5765, -0.6706, -0.6941,  ..., -0.7098, -0.7725, -0.6784],\n",
      "          [-0.5294, -0.6392, -0.6706,  ..., -0.7098, -0.7412, -0.6941],\n",
      "          [-0.5765, -0.6314, -0.7020,  ..., -0.7098, -0.7176, -0.6941],\n",
      "          ...,\n",
      "          [-0.0353, -0.1451, -0.0902,  ...,  0.0902,  0.0510,  0.1059],\n",
      "          [-0.2784, -0.3255,  0.0118,  ...,  0.0039,  0.0824,  0.1765],\n",
      "          [-0.2314, -0.0510, -0.0039,  ...,  0.1686,  0.0980,  0.0510]]],\n",
      "\n",
      "\n",
      "        [[[-0.9137, -0.9137, -0.8980,  ..., -0.8745, -0.8510, -0.8588],\n",
      "          [-0.9137, -0.9059, -0.8980,  ..., -0.8745, -0.8588, -0.8353],\n",
      "          [-0.9137, -0.9059, -0.9216,  ..., -0.8824, -0.8588, -0.8902],\n",
      "          ...,\n",
      "          [ 0.4431,  0.4902,  0.5843,  ...,  0.3412,  0.4196,  0.3961],\n",
      "          [ 0.4902,  0.4980,  0.6392,  ...,  0.5059,  0.3882,  0.3647],\n",
      "          [ 0.5059,  0.5294,  0.6235,  ...,  0.5529,  0.3333,  0.3098]],\n",
      "\n",
      "         [[-0.8902, -0.8902, -0.8667,  ..., -0.8353, -0.7961, -0.7882],\n",
      "          [-0.8902, -0.8824, -0.8824,  ..., -0.8275, -0.7882, -0.7647],\n",
      "          [-0.8902, -0.8667, -0.8902,  ..., -0.8039, -0.7804, -0.8275],\n",
      "          ...,\n",
      "          [ 0.5451,  0.5294,  0.6000,  ...,  0.3725,  0.5059,  0.4745],\n",
      "          [ 0.6784,  0.5765,  0.6706,  ...,  0.4275,  0.4745,  0.5059],\n",
      "          [ 0.6157,  0.5765,  0.5922,  ...,  0.5451,  0.4667,  0.4667]],\n",
      "\n",
      "         [[-0.8980, -0.8980, -0.8745,  ..., -0.8588, -0.8039, -0.8196],\n",
      "          [-0.8980, -0.8902, -0.8902,  ..., -0.8353, -0.7961, -0.7647],\n",
      "          [-0.8902, -0.8824, -0.9059,  ..., -0.8118, -0.7961, -0.8588],\n",
      "          ...,\n",
      "          [ 0.0196,  0.0275,  0.1059,  ..., -0.1922, -0.0039, -0.0824],\n",
      "          [ 0.1294,  0.0431,  0.1765,  ...,  0.0039, -0.0353, -0.1137],\n",
      "          [ 0.1922,  0.0275,  0.1373,  ...,  0.0980, -0.0510, -0.0824]]]]) tensor([2, 8, 8, 6, 8, 9, 1, 4, 2, 7, 8, 7, 3, 3, 4, 4, 2, 5, 9, 4, 8, 3, 4, 1,\n",
      "        9, 3, 6, 1, 0, 0, 0, 4, 2, 1, 4, 3, 9, 8, 7, 2, 8, 1, 6, 1, 6, 8, 5, 9,\n",
      "        8, 0, 8, 9, 0, 5, 1, 6, 0, 3, 0, 2, 9, 6, 7, 6])\n",
      "tensor([[[[ 0.0667,  0.0588,  0.0745,  ..., -0.1216, -0.0118, -0.0902],\n",
      "          [ 0.0667,  0.0745,  0.0902,  ..., -0.3098, -0.2392, -0.2157],\n",
      "          [-0.0196, -0.0039,  0.0824,  ..., -0.1529, -0.1608, -0.0588],\n",
      "          ...,\n",
      "          [ 0.1373,  0.1451,  0.1216,  ..., -0.1373, -0.4588, -0.7412],\n",
      "          [ 0.1059,  0.1294,  0.0902,  ..., -0.2078, -0.5686, -0.7490],\n",
      "          [-0.0667,  0.0118,  0.0353,  ..., -0.1843, -0.4980, -0.7490]],\n",
      "\n",
      "         [[ 0.0353,  0.0667,  0.0588,  ..., -0.1216,  0.0353, -0.0902],\n",
      "          [ 0.1137,  0.1294,  0.1137,  ..., -0.3020, -0.2314, -0.2000],\n",
      "          [ 0.1137,  0.1765,  0.2078,  ..., -0.1451, -0.2000, -0.0667],\n",
      "          ...,\n",
      "          [ 0.1843,  0.1686,  0.1059,  ..., -0.2941, -0.5451, -0.7961],\n",
      "          [ 0.1294,  0.1373,  0.0824,  ..., -0.3725, -0.6471, -0.7961],\n",
      "          [-0.0510, -0.0039,  0.0196,  ..., -0.3569, -0.5843, -0.7804]],\n",
      "\n",
      "         [[-0.4196, -0.4118, -0.4196,  ..., -0.3804, -0.2863, -0.3804],\n",
      "          [-0.4196, -0.4039, -0.4275,  ..., -0.4824, -0.4275, -0.4039],\n",
      "          [-0.3647, -0.2863, -0.3333,  ..., -0.4275, -0.4431, -0.3725],\n",
      "          ...,\n",
      "          [-0.3412, -0.3569, -0.3882,  ..., -0.4745, -0.5922, -0.7961],\n",
      "          [-0.3804, -0.3647, -0.3961,  ..., -0.4902, -0.6784, -0.8196],\n",
      "          [-0.4118, -0.3882, -0.4118,  ..., -0.4980, -0.6471, -0.8118]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4902,  0.5686,  0.6784,  ...,  0.6078,  0.7333,  0.6706],\n",
      "          [ 0.1529,  0.2627,  0.2157,  ...,  0.4824,  0.5843,  0.4902],\n",
      "          [ 0.2392,  0.2392,  0.1765,  ...,  0.6078,  0.4039,  0.4745],\n",
      "          ...,\n",
      "          [-0.0196,  0.0039,  0.0667,  ...,  0.8902,  0.8824,  0.8588],\n",
      "          [ 0.1686,  0.2314,  0.3020,  ...,  0.8510,  0.8510,  0.8510],\n",
      "          [ 0.4196,  0.4588,  0.4196,  ...,  0.8667,  0.8667,  0.8902]],\n",
      "\n",
      "         [[ 0.6314,  0.7020,  0.6941,  ...,  0.7882,  0.8824,  0.7020],\n",
      "          [ 0.2157,  0.3176,  0.3020,  ...,  0.5843,  0.6549,  0.5922],\n",
      "          [ 0.2784,  0.2549,  0.1843,  ...,  0.7020,  0.4353,  0.6627],\n",
      "          ...,\n",
      "          [-0.0510, -0.0588,  0.0275,  ...,  0.9137,  0.9137,  0.8824],\n",
      "          [ 0.1529,  0.2157,  0.3176,  ...,  0.8588,  0.8824,  0.8667],\n",
      "          [ 0.4196,  0.4353,  0.4275,  ...,  0.8745,  0.8824,  0.8980]],\n",
      "\n",
      "         [[ 0.5765,  0.6549,  0.6471,  ...,  0.4667,  0.5294,  0.5529],\n",
      "          [ 0.1451,  0.2235,  0.2078,  ...,  0.4667,  0.4353,  0.3098],\n",
      "          [ 0.3882,  0.3020,  0.2314,  ...,  0.6941,  0.3961,  0.3412],\n",
      "          ...,\n",
      "          [-0.0431, -0.0353,  0.0431,  ...,  0.9529,  0.9529,  0.9294],\n",
      "          [ 0.1765,  0.2392,  0.3255,  ...,  0.8980,  0.9137,  0.9059],\n",
      "          [ 0.4431,  0.4588,  0.4196,  ...,  0.9059,  0.9059,  0.9294]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1216,  0.2941,  0.4431,  ...,  0.6706,  0.6706,  0.6549],\n",
      "          [ 0.1137,  0.2863,  0.4431,  ...,  0.7255,  0.7098,  0.6627],\n",
      "          [ 0.1059,  0.3333,  0.4824,  ...,  0.6627,  0.6863,  0.6706],\n",
      "          ...,\n",
      "          [-0.3725, -0.3725, -0.4667,  ...,  0.1686,  0.2314,  0.2235],\n",
      "          [-0.2941, -0.4510, -0.4824,  ...,  0.0902,  0.1765,  0.1059],\n",
      "          [-0.2392, -0.3725, -0.3882,  ...,  0.2392,  0.1451,  0.2314]],\n",
      "\n",
      "         [[-0.0980,  0.0667,  0.2471,  ...,  0.4745,  0.4667,  0.4431],\n",
      "          [-0.1137,  0.0588,  0.2549,  ...,  0.5373,  0.5059,  0.4431],\n",
      "          [-0.1216,  0.1059,  0.2863,  ...,  0.4588,  0.4824,  0.4588],\n",
      "          ...,\n",
      "          [-0.5765, -0.5765, -0.6784,  ..., -0.0902, -0.0275, -0.0353],\n",
      "          [-0.5059, -0.6549, -0.6863,  ..., -0.1686, -0.0824, -0.1608],\n",
      "          [-0.4431, -0.5765, -0.5922,  ..., -0.0196, -0.1137, -0.0431]],\n",
      "\n",
      "         [[-0.2863,  0.0588,  0.1922,  ...,  0.3569,  0.3490,  0.3255],\n",
      "          [-0.3020,  0.0510,  0.2078,  ...,  0.4118,  0.3882,  0.3333],\n",
      "          [-0.3098,  0.0980,  0.2471,  ...,  0.3333,  0.3647,  0.3569],\n",
      "          ...,\n",
      "          [-0.5451, -0.5608, -0.6784,  ..., -0.1608, -0.1059, -0.1137],\n",
      "          [-0.4745, -0.6314, -0.6863,  ..., -0.2078, -0.1451, -0.2392],\n",
      "          [-0.4196, -0.5686, -0.5843,  ..., -0.0431, -0.1608, -0.0980]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.8588, -0.8275, -0.8275,  ..., -0.9059, -0.8745, -0.8980],\n",
      "          [-0.8824, -0.8980, -0.8824,  ..., -0.8824, -0.8980, -0.9059],\n",
      "          [-0.8980, -0.9059, -0.8902,  ..., -0.9059, -0.8824, -0.8902],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.8510, -0.8118, -0.8118,  ..., -0.9137, -0.8824, -0.9137],\n",
      "          [-0.8745, -0.8824, -0.8745,  ..., -0.8902, -0.9059, -0.9137],\n",
      "          [-0.8902, -0.8902, -0.8824,  ..., -0.9059, -0.8824, -0.8902],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.9373, -0.9294, -0.9529,  ..., -0.9451, -0.9137, -0.9451],\n",
      "          [-0.9216, -0.9451, -0.9451,  ..., -0.9137, -0.9373, -0.9451],\n",
      "          [-0.9529, -0.9686, -0.9529,  ..., -0.9451, -0.9294, -0.9294],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.5137, -0.3412, -0.4039,  ..., -0.5843, -0.6235, -0.6235],\n",
      "          [-0.5529, -0.3490, -0.3882,  ..., -0.5686, -0.5922, -0.5765],\n",
      "          [-0.5451, -0.3882, -0.4118,  ..., -0.5922, -0.5608, -0.5451],\n",
      "          ...,\n",
      "          [-0.6706, -0.5608, -0.5294,  ..., -0.9373, -0.9294, -0.9294],\n",
      "          [-0.6471, -0.5137, -0.5216,  ..., -0.9294, -0.9294, -0.9373],\n",
      "          [-0.6627, -0.4980, -0.5373,  ..., -0.9294, -0.9373, -0.9294]],\n",
      "\n",
      "         [[-0.5686, -0.4196, -0.4745,  ..., -0.6706, -0.6941, -0.6941],\n",
      "          [-0.6157, -0.4275, -0.4588,  ..., -0.6627, -0.6627, -0.6549],\n",
      "          [-0.5922, -0.4667, -0.4824,  ..., -0.6784, -0.6549, -0.6471],\n",
      "          ...,\n",
      "          [-0.7333, -0.6314, -0.6157,  ..., -0.9294, -0.9294, -0.9294],\n",
      "          [-0.7176, -0.6000, -0.6078,  ..., -0.9373, -0.9373, -0.9373],\n",
      "          [-0.7176, -0.6000, -0.6157,  ..., -0.9373, -0.9373, -0.9373]],\n",
      "\n",
      "         [[-0.6392, -0.5137, -0.5765,  ..., -0.7882, -0.7961, -0.7961],\n",
      "          [-0.6784, -0.5216, -0.5529,  ..., -0.7569, -0.7725, -0.7569],\n",
      "          [-0.6549, -0.5529, -0.5608,  ..., -0.7804, -0.7647, -0.7647],\n",
      "          ...,\n",
      "          [-0.8118, -0.7490, -0.7412,  ..., -0.9451, -0.9451, -0.9451],\n",
      "          [-0.7961, -0.7176, -0.7255,  ..., -0.9373, -0.9451, -0.9529],\n",
      "          [-0.8118, -0.7176, -0.7333,  ..., -0.9451, -0.9373, -0.9451]]]]) tensor([3, 7, 5, 5, 7, 1, 6, 9, 2, 3, 8, 2, 5, 7, 8, 2, 1, 8, 1, 1, 9, 0, 8, 0,\n",
      "        4, 1, 8, 0, 0, 2, 9, 0, 9, 1, 8, 3, 7, 7, 5, 3, 4, 9, 0, 4, 8, 9, 1, 9,\n",
      "        1, 5, 0, 1, 6, 7, 5, 4, 5, 2, 5, 0, 3, 2, 8, 5])\n",
      "tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3176,  0.3647,  0.3569,  ...,  0.1686, -0.3020, -0.3255],\n",
      "          [ 0.3725,  0.3804,  0.3255,  ..., -0.2000, -0.3882, -0.3333],\n",
      "          [ 0.3804,  0.3569,  0.3098,  ..., -0.3725, -0.3176, -0.3569],\n",
      "          ...,\n",
      "          [-0.5608, -0.4353, -0.4118,  ...,  0.8118,  0.8510,  0.2627],\n",
      "          [-0.0745, -0.1608,  0.1294,  ...,  0.8039,  0.7020,  0.7176],\n",
      "          [ 0.0353,  0.1765,  0.3961,  ...,  0.7098,  0.6627,  0.6627]],\n",
      "\n",
      "         [[ 0.2549,  0.3255,  0.3176,  ...,  0.0745, -0.3725, -0.3255],\n",
      "          [ 0.3098,  0.3412,  0.3176,  ..., -0.2471, -0.4118, -0.3569],\n",
      "          [ 0.3255,  0.3020,  0.3020,  ..., -0.4353, -0.3255, -0.3490],\n",
      "          ...,\n",
      "          [-0.6157, -0.4275, -0.4039,  ...,  0.6392,  0.6784,  0.0824],\n",
      "          [-0.0980, -0.1922,  0.0431,  ...,  0.5843,  0.4980,  0.5686],\n",
      "          [-0.0902,  0.0196,  0.2314,  ...,  0.4667,  0.4118,  0.4431]],\n",
      "\n",
      "         [[ 0.2627,  0.3333,  0.3412,  ..., -0.0275, -0.4353, -0.3020],\n",
      "          [ 0.3333,  0.3569,  0.3490,  ..., -0.2706, -0.4039, -0.3490],\n",
      "          [ 0.3333,  0.3255,  0.3255,  ..., -0.4431, -0.3176, -0.3882],\n",
      "          ...,\n",
      "          [-0.6078, -0.3647, -0.3490,  ...,  0.6000,  0.6627,  0.0980],\n",
      "          [-0.0902, -0.1843,  0.0275,  ...,  0.5294,  0.4275,  0.4980],\n",
      "          [-0.1216,  0.0118,  0.1922,  ...,  0.4118,  0.3255,  0.3098]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1922,  0.1451,  0.1059,  ...,  0.4431,  0.4431,  0.4431],\n",
      "          [ 0.2863,  0.2078,  0.1843,  ...,  0.4431,  0.4510,  0.4431],\n",
      "          [ 0.2784,  0.3098,  0.2706,  ...,  0.4431,  0.4510,  0.4431],\n",
      "          ...,\n",
      "          [ 0.0275,  0.0353,  0.0510,  ...,  0.3176,  0.2941,  0.3412],\n",
      "          [ 0.0431,  0.0039,  0.0039,  ...,  0.4039,  0.4039,  0.3804],\n",
      "          [ 0.0039,  0.0039,  0.0196,  ...,  0.3490,  0.3882,  0.4431]],\n",
      "\n",
      "         [[ 0.2078,  0.1529,  0.1137,  ...,  0.5059,  0.5137,  0.5216],\n",
      "          [ 0.3020,  0.2235,  0.1922,  ...,  0.5137,  0.5216,  0.5373],\n",
      "          [ 0.2863,  0.3255,  0.2784,  ...,  0.5216,  0.5216,  0.5294],\n",
      "          ...,\n",
      "          [-0.0118, -0.0039,  0.0275,  ...,  0.2471,  0.2078,  0.2549],\n",
      "          [ 0.0118, -0.0275, -0.0275,  ...,  0.3804,  0.3725,  0.3255],\n",
      "          [-0.0275, -0.0039, -0.0118,  ...,  0.2941,  0.3490,  0.4275]],\n",
      "\n",
      "         [[ 0.2078,  0.1294,  0.0980,  ...,  0.5529,  0.5529,  0.5686],\n",
      "          [ 0.3412,  0.2471,  0.2000,  ...,  0.5608,  0.5686,  0.5686],\n",
      "          [ 0.2863,  0.3412,  0.3098,  ...,  0.5608,  0.5686,  0.5686],\n",
      "          ...,\n",
      "          [-0.0510, -0.0588, -0.0118,  ...,  0.1373,  0.0980,  0.1686],\n",
      "          [-0.0275, -0.0824, -0.0745,  ...,  0.3569,  0.3412,  0.2863],\n",
      "          [-0.0667, -0.0431, -0.0510,  ...,  0.2549,  0.3176,  0.4039]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4196,  0.4510,  0.6000,  ..., -0.0353, -0.0667, -0.0431],\n",
      "          [ 0.4353,  0.3725,  0.6235,  ..., -0.0510,  0.0275,  0.1373],\n",
      "          [ 0.6627,  0.4510,  0.5137,  ...,  0.0510,  0.1216,  0.2078],\n",
      "          ...,\n",
      "          [ 0.2941,  0.6863,  0.6627,  ...,  0.2392, -0.0980,  0.4745],\n",
      "          [ 0.4588,  0.5922,  0.3882,  ...,  0.2392,  0.2235,  0.5137],\n",
      "          [ 0.5373,  0.4196,  0.4902,  ...,  0.3333,  0.2784,  0.5608]],\n",
      "\n",
      "         [[ 0.2235,  0.2392,  0.3804,  ..., -0.0588, -0.1529, -0.1216],\n",
      "          [ 0.2627,  0.2157,  0.4275,  ..., -0.0745, -0.0902, -0.0353],\n",
      "          [ 0.4588,  0.2784,  0.3098,  ..., -0.0196, -0.0275,  0.0588],\n",
      "          ...,\n",
      "          [ 0.0980,  0.5451,  0.5059,  ...,  0.2863, -0.1686,  0.3961],\n",
      "          [ 0.3255,  0.4196,  0.1373,  ...,  0.2392,  0.2000,  0.4353],\n",
      "          [ 0.3961,  0.2392,  0.2627,  ...,  0.2471,  0.2078,  0.4431]],\n",
      "\n",
      "         [[-0.0039, -0.0745,  0.1294,  ..., -0.2784, -0.3098, -0.3020],\n",
      "          [ 0.0353, -0.0588,  0.1529,  ..., -0.2863, -0.2784, -0.2392],\n",
      "          [ 0.2157,  0.0431,  0.0275,  ..., -0.2471, -0.2471, -0.2000],\n",
      "          ...,\n",
      "          [-0.1216,  0.2863,  0.2706,  ..., -0.0588, -0.4196,  0.1529],\n",
      "          [ 0.1059,  0.2314, -0.0588,  ..., -0.0510, -0.0510,  0.1922],\n",
      "          [ 0.2078,  0.0588,  0.0353,  ...,  0.0431, -0.0118,  0.2235]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7725,  0.7725,  0.7725,  ...,  0.7725,  0.7647,  0.7647],\n",
      "          [ 0.7647,  0.7647,  0.7725,  ...,  0.7961,  0.7647,  0.7725],\n",
      "          [ 0.7647,  0.7647,  0.7647,  ...,  0.5922,  0.7961,  0.7647],\n",
      "          ...,\n",
      "          [-0.6471, -0.6392, -0.6157,  ..., -0.4353, -0.3255, -0.3412],\n",
      "          [-0.6157, -0.6157, -0.6706,  ..., -0.3490, -0.3333, -0.3412],\n",
      "          [-0.5843, -0.6392, -0.7098,  ..., -0.3412, -0.3255, -0.3333]],\n",
      "\n",
      "         [[ 0.7647,  0.7647,  0.7647,  ...,  0.7725,  0.7725,  0.7725],\n",
      "          [ 0.7569,  0.7569,  0.7647,  ...,  0.7961,  0.7725,  0.7804],\n",
      "          [ 0.7569,  0.7569,  0.7647,  ...,  0.6078,  0.8039,  0.7725],\n",
      "          ...,\n",
      "          [-0.6078, -0.6157, -0.6000,  ..., -0.4510, -0.3255, -0.3255],\n",
      "          [-0.5765, -0.6000, -0.6627,  ..., -0.3412, -0.3255, -0.3255],\n",
      "          [-0.5529, -0.6157, -0.7020,  ..., -0.3255, -0.3020, -0.3098]],\n",
      "\n",
      "         [[ 0.8039,  0.8039,  0.8039,  ...,  0.8118,  0.8039,  0.8039],\n",
      "          [ 0.7961,  0.7961,  0.8039,  ...,  0.8275,  0.8039,  0.8118],\n",
      "          [ 0.7961,  0.7961,  0.8039,  ...,  0.6706,  0.8353,  0.8039],\n",
      "          ...,\n",
      "          [-0.8431, -0.8118, -0.7961,  ..., -0.6706, -0.6392, -0.6157],\n",
      "          [-0.7882, -0.7647, -0.8118,  ..., -0.5686, -0.5922, -0.5843],\n",
      "          [-0.7490, -0.8275, -0.8510,  ..., -0.5686, -0.5294, -0.5294]]]]) tensor([9, 4, 5, 7, 3, 7, 5, 6, 0, 2, 5, 1, 2, 6, 8, 1, 1, 5, 8, 0, 6, 9, 7, 9,\n",
      "        4, 1, 4, 9, 8, 7, 6, 3, 9, 7, 5, 6, 4, 7, 2, 0, 6, 4, 8, 5, 5, 3, 8, 5,\n",
      "        1, 2, 7, 9, 3, 3, 8, 9, 2, 7, 5, 1, 9, 2, 1, 6])\n",
      "tensor([[[[ 0.9529,  0.4902,  0.2157,  ...,  0.9059,  0.8431,  0.7882],\n",
      "          [ 0.9529,  0.5059,  0.2000,  ...,  0.8824,  0.8824,  0.8980],\n",
      "          [ 0.8980,  0.3882,  0.0745,  ...,  0.8510,  0.9529,  0.9843],\n",
      "          ...,\n",
      "          [ 0.9765,  0.5137,  0.2157,  ...,  0.9059,  1.0000,  0.9922],\n",
      "          [ 0.9608,  0.5216,  0.2706,  ...,  0.9137,  1.0000,  0.9843],\n",
      "          [ 0.9765,  0.5216,  0.2549,  ...,  0.9059,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 0.9765,  0.5373,  0.2627,  ...,  0.9294,  0.8667,  0.8196],\n",
      "          [ 0.9686,  0.5529,  0.2549,  ...,  0.8980,  0.8902,  0.9216],\n",
      "          [ 0.9294,  0.4667,  0.1608,  ...,  0.8588,  0.9529,  1.0000],\n",
      "          ...,\n",
      "          [ 0.9765,  0.5451,  0.2863,  ...,  0.9137,  1.0000,  1.0000],\n",
      "          [ 0.9529,  0.5529,  0.3412,  ...,  0.9216,  1.0000,  0.9843],\n",
      "          [ 0.9765,  0.5529,  0.3255,  ...,  0.9216,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 0.8902,  0.4431,  0.1686,  ...,  0.8667,  0.8039,  0.7098],\n",
      "          [ 0.8902,  0.4588,  0.1608,  ...,  0.8431,  0.8353,  0.8510],\n",
      "          [ 0.8588,  0.3725,  0.0510,  ...,  0.8039,  0.9059,  0.9451],\n",
      "          ...,\n",
      "          [ 0.9373,  0.4667,  0.1686,  ...,  0.8824,  1.0000,  0.9843],\n",
      "          [ 0.9216,  0.4745,  0.2235,  ...,  0.8824,  1.0000,  0.9686],\n",
      "          [ 0.9608,  0.4745,  0.2078,  ...,  0.8667,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3255, -0.1059,  0.4275,  ..., -0.2941, -0.3098, -0.2627],\n",
      "          [ 0.3176, -0.1059,  0.4431,  ..., -0.2392, -0.3098, -0.2863],\n",
      "          [ 0.3490, -0.0980,  0.4510,  ..., -0.2235, -0.3333, -0.3255],\n",
      "          ...,\n",
      "          [ 0.0196,  0.0588,  0.0980,  ..., -0.4824, -0.4353, -0.2627],\n",
      "          [ 0.1373,  0.2392,  0.1686,  ..., -0.3882, -0.4196, -0.5059],\n",
      "          [ 0.2235,  0.1608,  0.1059,  ..., -0.6706, -0.5529, -0.7961]],\n",
      "\n",
      "         [[ 0.3255, -0.1137,  0.4118,  ..., -0.3882, -0.3647, -0.2941],\n",
      "          [ 0.3098, -0.1137,  0.4196,  ..., -0.3333, -0.3569, -0.3098],\n",
      "          [ 0.3098, -0.1294,  0.4118,  ..., -0.3176, -0.3725, -0.3412],\n",
      "          ...,\n",
      "          [ 0.0510,  0.0902,  0.1216,  ..., -0.4980, -0.4510, -0.2627],\n",
      "          [ 0.1608,  0.2706,  0.1843,  ..., -0.4353, -0.4667, -0.5294],\n",
      "          [ 0.2392,  0.1765,  0.1216,  ..., -0.6627, -0.5451, -0.7961]],\n",
      "\n",
      "         [[ 0.3020, -0.1294,  0.3804,  ..., -0.4667, -0.4118, -0.3255],\n",
      "          [ 0.2941, -0.1294,  0.3961,  ..., -0.4118, -0.4118, -0.3490],\n",
      "          [ 0.3255, -0.1294,  0.3961,  ..., -0.3961, -0.4353, -0.3725],\n",
      "          ...,\n",
      "          [ 0.0275,  0.0745,  0.1137,  ..., -0.5922, -0.5451, -0.3569],\n",
      "          [ 0.1137,  0.2157,  0.1529,  ..., -0.5294, -0.5686, -0.6392],\n",
      "          [ 0.1843,  0.1373,  0.0980,  ..., -0.7333, -0.6078, -0.8431]]],\n",
      "\n",
      "\n",
      "        [[[-0.9922, -0.9922, -0.9922,  ..., -0.9922, -0.9922, -0.9922],\n",
      "          [-0.9922, -0.9922, -0.9922,  ..., -0.9922, -0.9922, -0.9922],\n",
      "          [-0.9922, -0.9922, -0.9922,  ..., -0.9922, -0.9922, -0.9922],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.9843, -0.9843, -0.9843,  ..., -0.9843, -0.9843, -0.9843],\n",
      "          [-0.9843, -0.9843, -0.9843,  ..., -0.9765, -0.9765, -0.9765],\n",
      "          [-0.9843, -0.9843, -0.9843,  ..., -0.9843, -0.9686, -0.9686],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-0.5608, -0.5608, -0.5608,  ..., -0.5608, -0.5608, -0.5608],\n",
      "          [-0.5608, -0.5608, -0.5608,  ..., -0.5922, -0.5922, -0.5922],\n",
      "          [-0.5608, -0.5608, -0.5608,  ..., -0.6471, -0.6314, -0.6314],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9843,  0.9843,  0.9843,  ...,  0.9059,  0.9294,  0.9608],\n",
      "          [ 0.9843,  0.9843,  0.9843,  ...,  0.9373,  0.9529,  0.9686],\n",
      "          [ 0.9843,  0.9843,  0.9765,  ...,  0.9608,  0.9686,  0.9765],\n",
      "          ...,\n",
      "          [-0.0667,  0.0275,  0.0431,  ..., -0.3176, -0.3176, -0.2706],\n",
      "          [-0.0275,  0.0510,  0.1529,  ..., -0.2784, -0.2314, -0.2157],\n",
      "          [ 0.0039,  0.0196,  0.1451,  ..., -0.1373, -0.1059, -0.1137]],\n",
      "\n",
      "         [[ 0.9686,  0.9686,  0.9686,  ...,  0.9059,  0.9294,  0.9451],\n",
      "          [ 0.9686,  0.9686,  0.9608,  ...,  0.9294,  0.9373,  0.9451],\n",
      "          [ 0.9686,  0.9608,  0.9529,  ...,  0.9294,  0.9294,  0.9373],\n",
      "          ...,\n",
      "          [-0.3255, -0.2863, -0.2471,  ..., -0.3725, -0.3725, -0.3098],\n",
      "          [-0.3804, -0.2863, -0.1529,  ..., -0.3804, -0.3647, -0.3098],\n",
      "          [-0.4824, -0.4196, -0.1843,  ..., -0.3412, -0.3255, -0.3255]],\n",
      "\n",
      "         [[ 0.8745,  0.8745,  0.8745,  ...,  0.8510,  0.8667,  0.8745],\n",
      "          [ 0.8745,  0.8745,  0.8745,  ...,  0.8667,  0.8667,  0.8745],\n",
      "          [ 0.8745,  0.8824,  0.8824,  ...,  0.8667,  0.8745,  0.8902],\n",
      "          ...,\n",
      "          [-0.5137, -0.4745, -0.4824,  ..., -0.2627, -0.2784, -0.2157],\n",
      "          [-0.5922, -0.5216, -0.4431,  ..., -0.2863, -0.3020, -0.2784],\n",
      "          [-0.6627, -0.6314, -0.4667,  ..., -0.3176, -0.3333, -0.3490]]],\n",
      "\n",
      "\n",
      "        [[[-0.9137, -0.0667,  0.0275,  ..., -0.3412, -0.3647, -0.3647],\n",
      "          [-0.9529, -0.2235,  0.0667,  ..., -0.6627, -0.7412, -0.7725],\n",
      "          [-0.9451, -0.1686,  0.0588,  ..., -0.9137, -0.9059, -0.8745],\n",
      "          ...,\n",
      "          [-0.9686, -0.7412, -0.7647,  ..., -0.7490, -0.6706, -0.7490],\n",
      "          [-0.9686, -0.7412, -0.7725,  ..., -0.7569, -0.6627, -0.6471],\n",
      "          [-0.9373, -0.6078, -0.7725,  ..., -0.7412, -0.7490, -0.6471]],\n",
      "\n",
      "         [[-0.9137, -0.0902, -0.0353,  ..., -0.2941, -0.3098, -0.3255],\n",
      "          [-0.9216, -0.2000, -0.0588,  ..., -0.6157, -0.7176, -0.7412],\n",
      "          [-0.9373, -0.2235, -0.0275,  ..., -0.9137, -0.9059, -0.8824],\n",
      "          ...,\n",
      "          [-0.9608, -0.6471, -0.6941,  ..., -0.5686, -0.4745, -0.5608],\n",
      "          [-0.9451, -0.6000, -0.7020,  ..., -0.5843, -0.4745, -0.4431],\n",
      "          [-0.9137, -0.4039, -0.6314,  ..., -0.5686, -0.5686, -0.4510]],\n",
      "\n",
      "         [[-0.9373, -0.2863, -0.2392,  ..., -0.4118, -0.4275, -0.4431],\n",
      "          [-0.9608, -0.4431, -0.2471,  ..., -0.6549, -0.7255, -0.7569],\n",
      "          [-0.9608, -0.4196, -0.2235,  ..., -0.9216, -0.9216, -0.8902],\n",
      "          ...,\n",
      "          [-0.9686, -0.6784, -0.7098,  ..., -0.4275, -0.3176, -0.4118],\n",
      "          [-0.9529, -0.6314, -0.7098,  ..., -0.4431, -0.3255, -0.2941],\n",
      "          [-0.9137, -0.4353, -0.6392,  ..., -0.4510, -0.4196, -0.2941]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5137,  0.5137,  0.5137,  ...,  0.5137,  0.5137,  0.5137],\n",
      "          [ 0.5137,  0.5137,  0.5137,  ...,  0.5137,  0.5137,  0.5137],\n",
      "          [ 0.5137,  0.5137,  0.5137,  ...,  0.5137,  0.5137,  0.5137],\n",
      "          ...,\n",
      "          [ 0.5137,  0.5137,  0.5137,  ...,  0.5216,  0.5529,  0.4980],\n",
      "          [ 0.5137,  0.5137,  0.5137,  ...,  0.5294,  0.5529,  0.4902],\n",
      "          [ 0.5137,  0.5137,  0.5137,  ...,  0.5294,  0.5451,  0.4902]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  0.9843,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  0.9843,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9922,  0.9843,  1.0000]],\n",
      "\n",
      "         [[ 0.5059,  0.5059,  0.5059,  ...,  0.5059,  0.5059,  0.5059],\n",
      "          [ 0.5059,  0.5059,  0.5059,  ...,  0.5059,  0.5059,  0.5059],\n",
      "          [ 0.5059,  0.5059,  0.5059,  ...,  0.5059,  0.5059,  0.5059],\n",
      "          ...,\n",
      "          [ 0.5059,  0.5059,  0.5059,  ...,  0.5059,  0.5059,  0.5059],\n",
      "          [ 0.5059,  0.5059,  0.5059,  ...,  0.5059,  0.5059,  0.5059],\n",
      "          [ 0.5059,  0.5059,  0.5059,  ...,  0.4980,  0.5059,  0.5059]]]]) tensor([5, 3, 3, 1, 8, 0, 2, 3, 0, 4, 3, 7, 4, 0, 1, 0, 1, 5, 9, 5, 0, 0, 9, 2,\n",
      "        7, 2, 9, 7, 6, 8, 8, 7, 3, 9, 0, 9, 1, 1, 0, 1, 2, 6, 2, 3, 5, 9, 8, 6,\n",
      "        6, 4, 6, 3, 1, 2, 0, 2, 3, 8, 0, 6, 0, 4, 5, 5])\n",
      "tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.4588, -0.4667, -0.4510,  ...,  0.9373,  0.6392,  0.4510],\n",
      "          [-0.4588, -0.4588, -0.4431,  ...,  0.8039,  0.5137,  0.5373],\n",
      "          [-0.4431, -0.4588, -0.4510,  ...,  0.8118,  0.7725,  0.8667],\n",
      "          ...,\n",
      "          [-0.5451, -0.7098, -0.2784,  ..., -0.5765, -0.6235, -0.4824],\n",
      "          [-0.5765, -0.3725, -0.3333,  ..., -0.3176, -0.2314, -0.3882],\n",
      "          [-0.6471, -0.3882, -0.3333,  ..., -0.1294, -0.0980,  0.0431]],\n",
      "\n",
      "         [[-0.0039, -0.0118, -0.0039,  ...,  0.9451,  0.7490,  0.6706],\n",
      "          [ 0.0039,  0.0039,  0.0039,  ...,  0.8667,  0.6392,  0.6863],\n",
      "          [ 0.0353,  0.0353,  0.0431,  ...,  0.8824,  0.8196,  0.8980],\n",
      "          ...,\n",
      "          [-0.5922, -0.7412, -0.4980,  ..., -0.6078, -0.6314, -0.5137],\n",
      "          [-0.6314, -0.4275, -0.4588,  ..., -0.3804, -0.2706, -0.4353],\n",
      "          [-0.6863, -0.5216, -0.4980,  ..., -0.2549, -0.2549, -0.0588]],\n",
      "\n",
      "         [[ 0.5529,  0.5451,  0.5529,  ...,  0.9608,  0.9373,  0.8980],\n",
      "          [ 0.5686,  0.5529,  0.5608,  ...,  0.9529,  0.8980,  0.8902],\n",
      "          [ 0.6000,  0.5765,  0.5843,  ...,  0.9529,  0.9059,  0.9216],\n",
      "          ...,\n",
      "          [-0.7098, -0.8118, -0.6314,  ..., -0.6941, -0.7333, -0.6784],\n",
      "          [-0.6863, -0.5451, -0.5843,  ..., -0.5294, -0.3804, -0.4980],\n",
      "          [-0.8275, -0.6549, -0.6078,  ..., -0.4039, -0.5059, -0.3176]]],\n",
      "\n",
      "\n",
      "        [[[-0.1451, -0.1922, -0.2392,  ...,  0.0353,  0.0353,  0.0431],\n",
      "          [-0.1686, -0.2314, -0.2471,  ...,  0.0510,  0.0431,  0.0431],\n",
      "          [-0.2000, -0.2314, -0.2863,  ...,  0.0510,  0.0510,  0.0510],\n",
      "          ...,\n",
      "          [ 0.4039,  0.4039,  0.2392,  ..., -0.1059, -0.1059, -0.0980],\n",
      "          [ 0.1686,  0.2941,  0.4588,  ..., -0.1137, -0.1216, -0.1216],\n",
      "          [ 0.1765,  0.3176,  0.4510,  ..., -0.1216, -0.1216, -0.1216]],\n",
      "\n",
      "         [[-0.0353, -0.0353, -0.0353,  ...,  0.1059,  0.1137,  0.1059],\n",
      "          [-0.0431, -0.0275, -0.0196,  ...,  0.0980,  0.1059,  0.1137],\n",
      "          [-0.0275, -0.0118, -0.0196,  ...,  0.0980,  0.1059,  0.1059],\n",
      "          ...,\n",
      "          [ 0.2235,  0.2314,  0.1294,  ..., -0.0039, -0.0039, -0.0196],\n",
      "          [ 0.0588,  0.2078,  0.2863,  ..., -0.0196, -0.0196, -0.0275],\n",
      "          [ 0.0902,  0.2314,  0.3569,  ..., -0.0275, -0.0353, -0.0353]],\n",
      "\n",
      "         [[-0.5529, -0.5765, -0.6000,  ..., -0.2471, -0.2549, -0.2627],\n",
      "          [-0.5608, -0.6000, -0.6235,  ..., -0.2549, -0.2784, -0.2863],\n",
      "          [-0.5922, -0.6078, -0.6078,  ..., -0.2549, -0.2706, -0.2784],\n",
      "          ...,\n",
      "          [ 0.0510,  0.1137, -0.0039,  ..., -0.3490, -0.3569, -0.3490],\n",
      "          [-0.0353,  0.0902,  0.1373,  ..., -0.3647, -0.3647, -0.3647],\n",
      "          [-0.0196,  0.0980,  0.2627,  ..., -0.3647, -0.3804, -0.3804]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9922,  1.0000,  0.2784,  ...,  0.3647,  0.0353,  0.2157],\n",
      "          [ 0.9451,  0.9294,  0.1843,  ...,  0.3804,  0.0353,  0.2314],\n",
      "          [ 0.7569,  0.7882,  0.4431,  ...,  0.3569, -0.0039,  0.1137],\n",
      "          ...,\n",
      "          [-0.2235, -0.3647, -0.1451,  ..., -0.4118, -0.5373, -0.4039],\n",
      "          [-0.3725, -0.4588, -0.1765,  ..., -0.5529, -0.4431, -0.2157],\n",
      "          [-0.4118, -0.6000, -0.3961,  ..., -0.6549, -0.3412, -0.1451]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  0.2941,  ..., -0.0196, -0.4118, -0.2941],\n",
      "          [ 0.9373,  0.8902,  0.1451,  ..., -0.0745, -0.4275, -0.2941],\n",
      "          [ 0.6314,  0.6314,  0.3882,  ..., -0.1059, -0.4353, -0.3020],\n",
      "          ...,\n",
      "          [-0.3333, -0.4431, -0.2000,  ..., -0.5294, -0.6471, -0.5608],\n",
      "          [-0.4588, -0.5608, -0.2706,  ..., -0.6549, -0.5686, -0.3961],\n",
      "          [-0.4902, -0.6863, -0.4902,  ..., -0.7333, -0.4510, -0.3490]],\n",
      "\n",
      "         [[ 0.9608,  1.0000,  0.1686,  ..., -0.1608, -0.5059, -0.4510],\n",
      "          [ 0.8902,  0.8196,  0.0745,  ..., -0.2235, -0.5216, -0.4667],\n",
      "          [ 0.5451,  0.5686,  0.3176,  ..., -0.2627, -0.5059, -0.4588],\n",
      "          ...,\n",
      "          [-0.3647, -0.4902, -0.2706,  ..., -0.6235, -0.7490, -0.6784],\n",
      "          [-0.4824, -0.6078, -0.2941,  ..., -0.7333, -0.6706, -0.5843],\n",
      "          [-0.5373, -0.7098, -0.4980,  ..., -0.7882, -0.6392, -0.5451]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -0.8118,  ...,  0.8588,  0.8588,  0.8902],\n",
      "          [-1.0000, -1.0000, -0.9373,  ...,  0.5294,  0.5765,  0.6392],\n",
      "          [-1.0000, -1.0000, -0.9216,  ...,  0.6314,  0.7020,  0.7255],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -0.8588,  ...,  0.8353,  0.8118,  0.8431],\n",
      "          [-1.0000, -1.0000, -0.8275,  ...,  0.8824,  0.8745,  0.9216],\n",
      "          [-1.0000, -1.0000, -0.7647,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -0.8118,  ...,  0.8118,  0.8196,  0.8667],\n",
      "          [-1.0000, -1.0000, -0.9451,  ...,  0.4353,  0.4745,  0.5765],\n",
      "          [-1.0000, -1.0000, -0.9294,  ...,  0.5137,  0.5843,  0.6471],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -0.8588,  ...,  0.8510,  0.8275,  0.8196],\n",
      "          [-1.0000, -1.0000, -0.8275,  ...,  0.8902,  0.8824,  0.8980],\n",
      "          [-1.0000, -1.0000, -0.7647,  ...,  1.0000,  1.0000,  0.9922]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -0.8118,  ...,  0.8588,  0.8667,  0.8902],\n",
      "          [-1.0000, -1.0000, -0.9373,  ...,  0.5294,  0.5765,  0.6392],\n",
      "          [-1.0000, -1.0000, -0.9216,  ...,  0.5765,  0.6471,  0.6863],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -0.8667,  ...,  0.7412,  0.7333,  0.7882],\n",
      "          [-1.0000, -1.0000, -0.8353,  ...,  0.8118,  0.8118,  0.8745],\n",
      "          [-1.0000, -1.0000, -0.7647,  ...,  0.9843,  0.9843,  0.9922]]],\n",
      "\n",
      "\n",
      "        [[[-0.1529, -0.7569, -0.3490,  ..., -0.1529, -0.2078, -0.1529],\n",
      "          [-0.1529, -0.4902, -0.5451,  ...,  0.2314,  0.1294,  0.1451],\n",
      "          [-0.1686, -0.5373, -0.6863,  ...,  0.5451,  0.4824,  0.4353],\n",
      "          ...,\n",
      "          [-0.4667, -0.4980, -0.6157,  ..., -0.1137, -0.1059,  0.0275],\n",
      "          [-0.5608, -0.5922, -0.6157,  ...,  0.3176, -0.0431,  0.0275],\n",
      "          [-0.5373, -0.5843, -0.5843,  ..., -0.3176, -0.2549,  0.0353]],\n",
      "\n",
      "         [[-0.3255, -0.7804, -0.3882,  ..., -0.1686, -0.2784, -0.2627],\n",
      "          [-0.2941, -0.5294, -0.5843,  ...,  0.2000,  0.0431,  0.0431],\n",
      "          [-0.3020, -0.6235, -0.7647,  ...,  0.4275,  0.3725,  0.3412],\n",
      "          ...,\n",
      "          [-0.5922, -0.5922, -0.6392,  ..., -0.2000, -0.2235, -0.1059],\n",
      "          [-0.6784, -0.6706, -0.6549,  ...,  0.2000, -0.1843, -0.1373],\n",
      "          [-0.6706, -0.7098, -0.6706,  ..., -0.4510, -0.3804, -0.0824]],\n",
      "\n",
      "         [[-0.5216, -0.8510, -0.5216,  ..., -0.7412, -0.7647, -0.6706],\n",
      "          [-0.4745, -0.6235, -0.7333,  ..., -0.5216, -0.6549, -0.6000],\n",
      "          [-0.4745, -0.7255, -0.8902,  ..., -0.2706, -0.3961, -0.4353],\n",
      "          ...,\n",
      "          [-0.7725, -0.7569, -0.7804,  ..., -0.4510, -0.4667, -0.3490],\n",
      "          [-0.8353, -0.8353, -0.7961,  ..., -0.1137, -0.4902, -0.4667],\n",
      "          [-0.8275, -0.8667, -0.7882,  ..., -0.7020, -0.7020, -0.4353]]]]) tensor([2, 6, 1, 5, 8, 8, 5, 0, 0, 7, 1, 2, 8, 6, 3, 1, 7, 4, 7, 9, 7, 1, 2, 9,\n",
      "        4, 1, 1, 6, 5, 4, 6, 7, 0, 5, 0, 2, 0, 2, 8, 3, 5, 3, 4, 0, 8, 7, 8, 3,\n",
      "        7, 9, 6, 5, 6, 3, 0, 3, 6, 3, 4, 3, 4, 3, 3, 4])\n",
      "tensor([[[[-0.9294, -0.9529, -0.7647,  ..., -0.5294, -0.5608, -0.6000],\n",
      "          [-0.8980, -0.8588, -0.6706,  ..., -0.7333, -0.7098, -0.6706],\n",
      "          [-0.8510, -0.7804, -0.6157,  ..., -0.7961, -0.6392, -0.6627],\n",
      "          ...,\n",
      "          [ 0.2627,  0.3490,  0.6000,  ...,  0.5765,  0.3255,  0.1922],\n",
      "          [ 0.2941,  0.4431,  0.5373,  ...,  0.7098,  0.3725,  0.3804],\n",
      "          [ 0.5294,  0.5529,  0.6000,  ...,  0.3882,  0.3412,  0.7098]],\n",
      "\n",
      "         [[-0.9373, -0.9373, -0.7176,  ..., -0.3804, -0.3804, -0.3882],\n",
      "          [-0.9059, -0.8510, -0.6235,  ..., -0.6235, -0.5686, -0.5059],\n",
      "          [-0.8510, -0.7804, -0.5608,  ..., -0.7490, -0.5608, -0.5294],\n",
      "          ...,\n",
      "          [ 0.5137,  0.5216,  0.5451,  ...,  0.6392,  0.4980,  0.3412],\n",
      "          [ 0.4510,  0.5451,  0.4745,  ...,  0.6314,  0.4353,  0.4588],\n",
      "          [ 0.5373,  0.5451,  0.5686,  ...,  0.2706,  0.3098,  0.6784]],\n",
      "\n",
      "         [[-0.9294, -0.9451, -0.7333,  ..., -0.4275, -0.4431, -0.4588],\n",
      "          [-0.9059, -0.8510, -0.6314,  ..., -0.6627, -0.6157, -0.5608],\n",
      "          [-0.8588, -0.7882, -0.5922,  ..., -0.7490, -0.5686, -0.5608],\n",
      "          ...,\n",
      "          [-0.1216, -0.0275,  0.1765,  ...,  0.2235, -0.1451, -0.2078],\n",
      "          [-0.0824,  0.1373,  0.1608,  ...,  0.2392, -0.1294, -0.0667],\n",
      "          [ 0.1451,  0.2706,  0.3176,  ..., -0.1529, -0.1843,  0.2941]]],\n",
      "\n",
      "\n",
      "        [[[-0.7725, -0.7569, -0.8118,  ...,  0.0353,  0.0902,  0.0431],\n",
      "          [-0.7412, -0.7490, -0.8118,  ..., -0.2471, -0.0510,  0.2314],\n",
      "          [-0.6863, -0.6471, -0.6627,  ..., -0.3804, -0.2157,  0.1765],\n",
      "          ...,\n",
      "          [-0.0510, -0.0431, -0.0353,  ..., -0.0510,  0.1059, -0.0431],\n",
      "          [ 0.0196, -0.0824, -0.0196,  ..., -0.1373, -0.2235, -0.2235],\n",
      "          [-0.0275, -0.0588, -0.0588,  ..., -0.4118, -0.3412, -0.3725]],\n",
      "\n",
      "         [[-0.7412, -0.7333, -0.7882,  ...,  0.0588,  0.1373,  0.0667],\n",
      "          [-0.7098, -0.7176, -0.7725,  ..., -0.1843, -0.0353,  0.2000],\n",
      "          [-0.6314, -0.5765, -0.6078,  ..., -0.3255, -0.1922,  0.1294],\n",
      "          ...,\n",
      "          [-0.0039, -0.0275, -0.0353,  ...,  0.0118,  0.1137, -0.0275],\n",
      "          [ 0.0431, -0.0431,  0.0275,  ..., -0.0745, -0.2000, -0.2078],\n",
      "          [-0.0118, -0.0196, -0.0353,  ..., -0.3804, -0.2784, -0.3569]],\n",
      "\n",
      "         [[-0.6863, -0.6863, -0.7490,  ..., -0.1294, -0.1529, -0.2784],\n",
      "          [-0.6392, -0.6392, -0.7490,  ..., -0.4667, -0.2157, -0.0667],\n",
      "          [-0.6314, -0.6549, -0.6706,  ..., -0.6157, -0.3961, -0.1451],\n",
      "          ...,\n",
      "          [-0.3725, -0.4745, -0.4510,  ..., -0.3961, -0.3412, -0.5843],\n",
      "          [-0.3098, -0.4824, -0.4353,  ..., -0.5137, -0.6314, -0.6549],\n",
      "          [-0.3647, -0.4275, -0.4588,  ..., -0.7020, -0.5686, -0.6000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-0.9373, -0.8275, -0.8353,  ..., -0.8353, -0.8353, -0.8353],\n",
      "          [-0.1137, -0.0196, -0.0118,  ...,  0.0902,  0.0902,  0.0902],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-0.9373, -0.8275, -0.8353,  ..., -0.8353, -0.8431, -0.8353],\n",
      "          [-0.1137, -0.0196, -0.0118,  ...,  0.0667,  0.0588,  0.0510],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-0.9294, -0.8275, -0.8353,  ..., -0.8510, -0.8588, -0.8510],\n",
      "          [-0.1137, -0.0353, -0.0275,  ...,  0.0118,  0.0353,  0.0431],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3882, -0.3882, -0.3412,  ..., -0.3569, -0.3255, -0.3020],\n",
      "          [-0.3882, -0.3725, -0.3569,  ..., -0.2863, -0.3176, -0.3490],\n",
      "          [-0.2941, -0.2392, -0.3569,  ..., -0.3176, -0.3098, -0.3255],\n",
      "          ...,\n",
      "          [-0.2784, -0.3176, -0.3098,  ..., -0.2863, -0.3569, -0.3020],\n",
      "          [-0.2941, -0.2863, -0.2941,  ..., -0.3412, -0.3255, -0.3255],\n",
      "          [-0.2784, -0.3176, -0.3176,  ..., -0.3412, -0.3333, -0.3176]],\n",
      "\n",
      "         [[-0.2863, -0.2784, -0.2471,  ..., -0.3098, -0.2627, -0.2392],\n",
      "          [-0.2863, -0.2706, -0.2627,  ..., -0.2235, -0.2549, -0.2863],\n",
      "          [-0.1922, -0.1373, -0.2471,  ..., -0.2471, -0.2471, -0.2549],\n",
      "          ...,\n",
      "          [-0.2627, -0.3020, -0.2863,  ..., -0.2706, -0.3333, -0.2784],\n",
      "          [-0.2863, -0.2706, -0.2706,  ..., -0.3176, -0.3020, -0.3020],\n",
      "          [-0.2549, -0.2941, -0.2941,  ..., -0.3176, -0.3098, -0.2941]],\n",
      "\n",
      "         [[-0.4196, -0.4196, -0.4196,  ..., -0.3882, -0.4431, -0.4431],\n",
      "          [-0.4275, -0.4118, -0.4353,  ..., -0.3725, -0.4275, -0.4824],\n",
      "          [-0.3255, -0.2784, -0.3804,  ..., -0.4745, -0.4275, -0.4745],\n",
      "          ...,\n",
      "          [-0.3804, -0.4196, -0.4118,  ..., -0.3961, -0.4667, -0.4118],\n",
      "          [-0.3490, -0.3804, -0.4039,  ..., -0.4510, -0.4353, -0.4353],\n",
      "          [-0.3647, -0.4510, -0.4588,  ..., -0.4588, -0.4510, -0.4353]]],\n",
      "\n",
      "\n",
      "        [[[-0.6157, -0.6314, -0.6471,  ..., -0.6078, -0.6000, -0.6078],\n",
      "          [-0.6471, -0.6392, -0.6706,  ..., -0.5922, -0.5922, -0.6000],\n",
      "          [-0.6549, -0.6627, -0.6784,  ..., -0.6235, -0.6314, -0.6471],\n",
      "          ...,\n",
      "          [-0.8902, -0.9451, -0.9373,  ..., -0.9137, -0.9216, -0.9294],\n",
      "          [-0.8745, -0.9059, -0.9216,  ..., -0.9294, -0.9294, -0.9294],\n",
      "          [-0.8824, -0.8980, -0.8980,  ..., -0.9373, -0.9373, -0.9451]],\n",
      "\n",
      "         [[-0.6235, -0.6392, -0.6549,  ..., -0.6078, -0.6000, -0.6078],\n",
      "          [-0.6549, -0.6471, -0.6706,  ..., -0.6000, -0.5922, -0.6078],\n",
      "          [-0.6549, -0.6627, -0.6863,  ..., -0.6314, -0.6314, -0.6471],\n",
      "          ...,\n",
      "          [-0.8745, -0.9294, -0.9216,  ..., -0.8980, -0.9059, -0.9137],\n",
      "          [-0.8588, -0.8902, -0.9059,  ..., -0.9137, -0.9137, -0.9137],\n",
      "          [-0.8667, -0.8824, -0.8824,  ..., -0.9216, -0.9216, -0.9294]],\n",
      "\n",
      "         [[-0.6627, -0.6784, -0.6941,  ..., -0.6706, -0.6706, -0.6784],\n",
      "          [-0.6941, -0.6863, -0.7176,  ..., -0.6627, -0.6549, -0.6706],\n",
      "          [-0.7020, -0.7098, -0.7333,  ..., -0.6706, -0.6784, -0.6941],\n",
      "          ...,\n",
      "          [-0.8902, -0.9373, -0.9294,  ..., -0.9059, -0.9137, -0.9216],\n",
      "          [-0.8902, -0.9137, -0.9137,  ..., -0.9216, -0.9216, -0.9216],\n",
      "          [-0.8980, -0.9059, -0.9059,  ..., -0.9294, -0.9294, -0.9373]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5608,  0.5765,  0.4431,  ...,  0.3412,  0.3490,  0.3176],\n",
      "          [ 0.5922,  0.4039,  0.2784,  ...,  0.3490,  0.3098,  0.2863],\n",
      "          [ 0.4667,  0.2706,  0.2627,  ...,  0.3569,  0.3569,  0.2235],\n",
      "          ...,\n",
      "          [ 0.9529,  0.9294,  0.9059,  ..., -0.0431,  0.0275,  0.0431],\n",
      "          [ 0.9529,  0.9294,  0.8980,  ..., -0.1059,  0.0118,  0.0275],\n",
      "          [ 0.9451,  0.9373,  0.8745,  ...,  0.0431,  0.0196, -0.0824]],\n",
      "\n",
      "         [[ 0.5843,  0.5686,  0.4039,  ...,  0.3098,  0.3255,  0.2863],\n",
      "          [ 0.5451,  0.3255,  0.2471,  ...,  0.3333,  0.2706,  0.2549],\n",
      "          [ 0.4039,  0.2314,  0.2784,  ...,  0.3255,  0.3176,  0.1922],\n",
      "          ...,\n",
      "          [ 0.9529,  0.9216,  0.9059,  ...,  0.0118,  0.0667,  0.0824],\n",
      "          [ 0.9451,  0.9294,  0.9059,  ..., -0.1294,  0.0118,  0.0588],\n",
      "          [ 0.9451,  0.9294,  0.8588,  ...,  0.0353,  0.0745, -0.0431]],\n",
      "\n",
      "         [[ 0.4902,  0.5765,  0.4275,  ...,  0.2471,  0.2863,  0.2392],\n",
      "          [ 0.5294,  0.3725,  0.2549,  ...,  0.2784,  0.2000,  0.1843],\n",
      "          [ 0.3882,  0.2235,  0.2392,  ...,  0.2471,  0.2314,  0.0902],\n",
      "          ...,\n",
      "          [ 0.9529,  0.9216,  0.9137,  ..., -0.0275,  0.0275,  0.0118],\n",
      "          [ 0.9529,  0.9294,  0.9059,  ..., -0.1843, -0.0510, -0.0431],\n",
      "          [ 0.9451,  0.9373,  0.8745,  ..., -0.0588, -0.0510, -0.1373]]]]) tensor([1, 6, 2, 2, 1, 2, 8, 2, 5, 7, 4, 5, 2, 1, 8, 9, 6, 2, 1, 5, 3, 5, 3, 0,\n",
      "        3, 3, 4, 8, 1, 1, 4, 5, 0, 6, 3, 5, 9, 2, 0, 0, 2, 8, 6, 2, 8, 4, 9, 6,\n",
      "        0, 5, 0, 4, 1, 2, 1, 5, 5, 5, 9, 7, 4, 5, 5, 7])\n",
      "tensor([[[[ 0.9608,  0.9608,  0.9686,  ..., -0.5529, -0.5529, -0.5294],\n",
      "          [ 0.9608,  0.9686,  0.9686,  ..., -0.5686, -0.5922, -0.5686],\n",
      "          [ 0.9608,  0.9686,  0.9686,  ..., -0.5608, -0.6157, -0.6078],\n",
      "          ...,\n",
      "          [-0.4118, -0.2157, -0.3882,  ..., -0.8039, -0.6078, -0.5137],\n",
      "          [ 0.2235, -0.1137, -0.3647,  ..., -0.8118, -0.7412, -0.4667],\n",
      "          [-0.0353, -0.0353,  0.0353,  ..., -0.5294, -0.5373, -0.7569]],\n",
      "\n",
      "         [[ 0.9843,  0.9843,  0.9843,  ..., -0.5922, -0.6078, -0.5922],\n",
      "          [ 0.9843,  0.9843,  0.9843,  ..., -0.6157, -0.6471, -0.6078],\n",
      "          [ 0.9765,  0.9843,  0.9843,  ..., -0.6000, -0.6471, -0.6392],\n",
      "          ...,\n",
      "          [-0.4118, -0.2157, -0.3098,  ..., -0.7412, -0.5294, -0.3882],\n",
      "          [ 0.2314, -0.0824, -0.3176,  ..., -0.7647, -0.6706, -0.3333],\n",
      "          [-0.0039, -0.0275,  0.1137,  ..., -0.4118, -0.4275, -0.6784]],\n",
      "\n",
      "         [[ 0.9765,  0.9765,  0.9765,  ..., -0.7412, -0.7569, -0.7804],\n",
      "          [ 0.9686,  0.9765,  0.9686,  ..., -0.7725, -0.7882, -0.7804],\n",
      "          [ 0.9686,  0.9686,  0.9608,  ..., -0.7647, -0.7882, -0.8039],\n",
      "          ...,\n",
      "          [-0.7176, -0.5922, -0.6000,  ..., -0.8667, -0.8118, -0.8039],\n",
      "          [-0.2627, -0.5373, -0.6078,  ..., -0.8824, -0.8039, -0.6627],\n",
      "          [-0.5137, -0.4824, -0.2941,  ..., -0.6314, -0.6627, -0.8196]]],\n",
      "\n",
      "\n",
      "        [[[-0.0510, -0.0980, -0.0353,  ...,  0.8902,  0.9059,  0.5294],\n",
      "          [ 0.7490,  0.6784,  0.5608,  ...,  0.5686,  0.6784,  0.6392],\n",
      "          [ 0.6627,  0.7176,  0.7255,  ...,  0.5686,  0.5843,  0.7647],\n",
      "          ...,\n",
      "          [ 0.7882,  0.7804,  0.7725,  ...,  0.0667,  0.0118,  0.1686],\n",
      "          [ 0.7882,  0.7882,  0.8118,  ...,  0.5608,  0.1765,  0.0431],\n",
      "          [ 0.8039,  0.8118,  0.7804,  ...,  0.6549,  0.4667,  0.0431]],\n",
      "\n",
      "         [[-0.0196, -0.0824, -0.0510,  ...,  0.8745,  0.9216,  0.5608],\n",
      "          [ 0.7647,  0.6941,  0.5451,  ...,  0.5529,  0.6941,  0.6627],\n",
      "          [ 0.7098,  0.7647,  0.7569,  ...,  0.5765,  0.6000,  0.7961],\n",
      "          ...,\n",
      "          [ 0.8275,  0.8118,  0.8039,  ...,  0.0980,  0.0431,  0.1843],\n",
      "          [ 0.8196,  0.8118,  0.8353,  ...,  0.5922,  0.2078,  0.0667],\n",
      "          [ 0.8196,  0.8275,  0.7961,  ...,  0.7098,  0.5059,  0.0745]],\n",
      "\n",
      "         [[ 0.0353, -0.0275,  0.0196,  ...,  0.9765,  1.0000,  0.6314],\n",
      "          [ 0.8196,  0.7725,  0.6314,  ...,  0.6392,  0.7882,  0.7412],\n",
      "          [ 0.7647,  0.8510,  0.8588,  ...,  0.6549,  0.6784,  0.8824],\n",
      "          ...,\n",
      "          [ 0.9137,  0.8980,  0.8902,  ...,  0.1765,  0.1216,  0.2784],\n",
      "          [ 0.9059,  0.8980,  0.9216,  ...,  0.6706,  0.3020,  0.1529],\n",
      "          [ 0.9216,  0.9294,  0.8980,  ...,  0.7882,  0.5922,  0.1451]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4588,  0.2157,  0.0745,  ...,  0.3098,  0.3647,  0.3412],\n",
      "          [ 0.3098,  0.4902,  0.3569,  ...,  0.2235,  0.0118,  0.4196],\n",
      "          [ 0.2706,  0.3255,  0.4510,  ...,  0.8196,  0.7412,  0.5922],\n",
      "          ...,\n",
      "          [ 0.5608,  0.6235,  0.5451,  ...,  0.5843,  0.5529,  0.4824],\n",
      "          [ 0.4196,  0.4902,  0.5529,  ...,  0.5059,  0.4745,  0.4588],\n",
      "          [ 0.5137,  0.4275,  0.4588,  ...,  0.5059,  0.4980,  0.6784]],\n",
      "\n",
      "         [[ 0.8510,  0.7569,  0.6627,  ...,  0.4510,  0.5686,  0.6157],\n",
      "          [ 0.8902,  0.8745,  0.7725,  ...,  0.4824,  0.3490,  0.6706],\n",
      "          [ 0.8431,  0.8196,  0.8118,  ...,  0.9843,  0.9922,  0.9451],\n",
      "          ...,\n",
      "          [ 0.8588,  0.8275,  0.6392,  ...,  0.8510,  0.8824,  0.8824],\n",
      "          [ 0.8824,  0.8745,  0.7647,  ...,  0.7882,  0.8196,  0.8275],\n",
      "          [ 0.9059,  0.8588,  0.8353,  ...,  0.8196,  0.7961,  1.0000]],\n",
      "\n",
      "         [[ 0.0588,  0.1216,  0.0667,  ..., -0.0353, -0.0196, -0.0745],\n",
      "          [-0.1059,  0.1922,  0.0980,  ..., -0.2078, -0.4353, -0.0118],\n",
      "          [-0.1373,  0.1059,  0.1137,  ...,  0.4667,  0.2549,  0.0510],\n",
      "          ...,\n",
      "          [ 0.6235,  0.5608,  0.5686,  ...,  0.5373,  0.5529,  0.5529],\n",
      "          [ 0.4196,  0.3490,  0.6157,  ...,  0.4353,  0.4980,  0.5137],\n",
      "          [ 0.5294,  0.3020,  0.4353,  ...,  0.4667,  0.5137,  0.7176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.9922,  0.9922,  1.0000,  ..., -0.2078, -0.6471, -0.8745],\n",
      "          [ 0.9922,  0.9922,  1.0000,  ...,  0.2784,  0.1608, -0.3333],\n",
      "          [ 0.9608,  0.9765,  0.9843,  ...,  0.3020,  0.3569,  0.3020],\n",
      "          ...,\n",
      "          [ 0.3961, -0.0510, -0.1843,  ..., -0.8353, -0.8745, -0.7490],\n",
      "          [ 0.3176, -0.0667, -0.2078,  ..., -0.8824, -0.8667, -0.6392],\n",
      "          [ 0.2471,  0.0196, -0.2471,  ..., -0.8667, -0.8588, -0.7020]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  0.8902,  ..., -0.4118, -0.7490, -0.8745],\n",
      "          [ 0.9529,  0.9765,  0.8118,  ...,  0.0510, -0.0824, -0.5216],\n",
      "          [ 0.5922,  0.6471,  0.5451,  ...,  0.0902,  0.1451,  0.0510],\n",
      "          ...,\n",
      "          [ 0.3490, -0.0824, -0.2000,  ..., -0.6078, -0.7490, -0.6549],\n",
      "          [ 0.2706, -0.0980, -0.2157,  ..., -0.7098, -0.7333, -0.6157],\n",
      "          [ 0.2078, -0.0118, -0.2549,  ..., -0.6941, -0.7176, -0.6941]],\n",
      "\n",
      "         [[ 0.9922,  1.0000,  0.8588,  ..., -0.4431, -0.7569, -0.8980],\n",
      "          [ 0.9294,  0.9529,  0.7255,  ...,  0.0667, -0.1059, -0.5529],\n",
      "          [ 0.5294,  0.5843,  0.4510,  ...,  0.1765,  0.2314, -0.0118],\n",
      "          ...,\n",
      "          [ 0.2941, -0.1765, -0.3098,  ..., -0.5922, -0.6784, -0.6157],\n",
      "          [ 0.2157, -0.1922, -0.3176,  ..., -0.6392, -0.6627, -0.5922],\n",
      "          [ 0.1529, -0.1137, -0.3569,  ..., -0.6157, -0.6784, -0.6941]]],\n",
      "\n",
      "\n",
      "        [[[-0.0039, -0.0118, -0.0196,  ...,  0.0431,  0.0353,  0.0353],\n",
      "          [ 0.0039,  0.0039, -0.0118,  ...,  0.0431,  0.0431,  0.0353],\n",
      "          [ 0.0118,  0.0118, -0.0039,  ...,  0.0510,  0.0431,  0.0431],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 0.2235,  0.2235,  0.2314,  ...,  0.2941,  0.2863,  0.2863],\n",
      "          [ 0.2314,  0.2314,  0.2235,  ...,  0.2941,  0.3020,  0.2941],\n",
      "          [ 0.2392,  0.2392,  0.2392,  ...,  0.3020,  0.3020,  0.3098],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[ 0.5373,  0.5373,  0.5294,  ...,  0.6157,  0.6078,  0.6078],\n",
      "          [ 0.5294,  0.5373,  0.5373,  ...,  0.6157,  0.6078,  0.6078],\n",
      "          [ 0.5373,  0.5451,  0.5451,  ...,  0.6078,  0.6078,  0.6078],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -0.9922, -0.9922, -0.9922],\n",
      "          [-0.8275, -0.8431, -0.6314,  ..., -0.7882, -0.7882, -0.8196],\n",
      "          [-0.7412, -0.8039, -0.6784,  ..., -0.6471, -0.6706, -0.5529],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -0.9922, -0.9922],\n",
      "          [-0.8667, -0.8824, -0.6784,  ..., -0.8824, -0.8902, -0.8667],\n",
      "          [-0.7961, -0.8588, -0.7412,  ..., -0.3412, -0.3569, -0.6627],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -0.9922, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-0.8902, -0.8902, -0.6627,  ..., -0.8588, -0.8745, -0.8588],\n",
      "          [-0.8588, -0.9059, -0.7647,  ..., -0.6863, -0.6784, -0.6706],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]]) tensor([7, 5, 6, 1, 6, 9, 2, 7, 9, 8, 5, 5, 0, 3, 3, 8, 1, 1, 4, 7, 1, 0, 1, 6,\n",
      "        4, 3, 8, 9, 7, 7, 1, 6, 1, 8, 8, 8, 7, 4, 5, 3, 9, 7, 3, 5, 7, 1, 4, 5,\n",
      "        1, 1, 4, 4, 1, 6, 2, 2, 3, 5, 6, 7, 1, 3, 8, 2])\n",
      "tensor([[[[-0.1373,  0.0667,  0.1765,  ..., -0.6706, -0.7020, -0.3725],\n",
      "          [ 0.1059,  0.2157,  0.2392,  ..., -0.7882, -0.7569, -0.4667],\n",
      "          [ 0.1765,  0.2314,  0.1765,  ..., -0.8353, -0.8118, -0.7176],\n",
      "          ...,\n",
      "          [ 0.3725,  0.0902,  0.0745,  ...,  0.0039, -0.2235, -0.3569],\n",
      "          [ 0.0275, -0.1373, -0.1686,  ..., -0.0353, -0.0353, -0.1765],\n",
      "          [ 0.2078, -0.0510, -0.1922,  ...,  0.1137,  0.2627, -0.3569]],\n",
      "\n",
      "         [[-0.0196,  0.1294,  0.2392,  ..., -0.5373, -0.5451, -0.2157],\n",
      "          [ 0.1765,  0.2627,  0.3098,  ..., -0.6471, -0.5843, -0.2941],\n",
      "          [ 0.2471,  0.2706,  0.2471,  ..., -0.6941, -0.6627, -0.5373],\n",
      "          ...,\n",
      "          [ 0.3961,  0.1686,  0.0902,  ...,  0.0353, -0.1373, -0.2471],\n",
      "          [ 0.0588, -0.1059, -0.1843,  ...,  0.0275,  0.0196, -0.0824],\n",
      "          [ 0.1922, -0.0745, -0.2392,  ...,  0.1529,  0.2627, -0.3020]],\n",
      "\n",
      "         [[-0.2314, -0.0824,  0.0039,  ..., -0.5059, -0.5294, -0.3804],\n",
      "          [-0.0902,  0.0039,  0.0353,  ..., -0.5843, -0.5686, -0.4275],\n",
      "          [-0.0196,  0.0275, -0.0118,  ..., -0.6078, -0.6157, -0.5608],\n",
      "          ...,\n",
      "          [ 0.1137, -0.1216, -0.2078,  ..., -0.2157, -0.3412, -0.4745],\n",
      "          [-0.2392, -0.4275, -0.4275,  ..., -0.2706, -0.2157, -0.3333],\n",
      "          [-0.0588, -0.3255, -0.4588,  ..., -0.1373, -0.0510, -0.5294]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1059,  0.1451,  0.1843,  ..., -0.6000, -0.6157, -0.6706],\n",
      "          [ 0.3176,  0.2471,  0.1529,  ..., -0.5529, -0.6157, -0.7255],\n",
      "          [ 0.3176, -0.0118, -0.0431,  ..., -0.5608, -0.5451, -0.6863],\n",
      "          ...,\n",
      "          [ 0.5216,  0.2941,  0.1216,  ...,  0.2784,  0.3725,  0.3255],\n",
      "          [ 0.1529,  0.0353,  0.1529,  ...,  0.3882,  0.4353,  0.2627],\n",
      "          [ 0.0667,  0.2157,  0.1765,  ...,  0.3725,  0.3255,  0.2706]],\n",
      "\n",
      "         [[-0.0588, -0.0588, -0.0745,  ..., -0.6392, -0.6627, -0.7176],\n",
      "          [ 0.1216, -0.0510, -0.1059,  ..., -0.6000, -0.6627, -0.7333],\n",
      "          [ 0.0588, -0.2471, -0.2314,  ..., -0.5451, -0.5765, -0.6863],\n",
      "          ...,\n",
      "          [ 0.2392,  0.0196, -0.1529,  ...,  0.2863,  0.3804,  0.3333],\n",
      "          [-0.1059, -0.2235, -0.1216,  ...,  0.4039,  0.4510,  0.2627],\n",
      "          [-0.1608, -0.0431, -0.0824,  ...,  0.3961,  0.3333,  0.2784]],\n",
      "\n",
      "         [[-0.1294, -0.1922, -0.2235,  ..., -0.7412, -0.7333, -0.7725],\n",
      "          [ 0.0667, -0.1765, -0.2471,  ..., -0.6627, -0.7333, -0.7961],\n",
      "          [-0.0196, -0.3333, -0.3176,  ..., -0.6157, -0.6314, -0.7490],\n",
      "          ...,\n",
      "          [ 0.0118, -0.1686, -0.3255,  ...,  0.2157,  0.2941,  0.2784],\n",
      "          [-0.3020, -0.3647, -0.2941,  ...,  0.2863,  0.3569,  0.2235],\n",
      "          [-0.3255, -0.2078, -0.2706,  ...,  0.2941,  0.2784,  0.2157]]],\n",
      "\n",
      "\n",
      "        [[[-0.8980, -0.8196, -0.8824,  ..., -0.1216, -0.3569, -0.4431],\n",
      "          [-0.9373, -0.8980, -0.8353,  ..., -0.3020, -0.3490,  0.0039],\n",
      "          [-0.9373, -0.9137, -0.8510,  ...,  0.4588, -0.3255, -0.4902],\n",
      "          ...,\n",
      "          [ 0.4510,  0.4196,  0.4745,  ...,  0.5922,  0.6235,  0.6157],\n",
      "          [ 0.4039,  0.4275,  0.4431,  ...,  0.6157,  0.6000,  0.6235],\n",
      "          [ 0.4118,  0.4275,  0.4275,  ...,  0.6078,  0.5922,  0.5373]],\n",
      "\n",
      "         [[-0.7804, -0.7569, -0.8745,  ..., -0.2000, -0.2627, -0.3176],\n",
      "          [-0.8824, -0.8824, -0.8196,  ..., -0.5294, -0.3490, -0.0667],\n",
      "          [-0.8902, -0.8745, -0.8510,  ..., -0.0745, -0.3804, -0.4824],\n",
      "          ...,\n",
      "          [ 0.3255,  0.3255,  0.3647,  ...,  0.4902,  0.5216,  0.5137],\n",
      "          [ 0.2941,  0.3255,  0.3412,  ...,  0.5059,  0.4902,  0.5137],\n",
      "          [ 0.3176,  0.3333,  0.3412,  ...,  0.4980,  0.4902,  0.4431]],\n",
      "\n",
      "         [[-0.9294, -0.8588, -0.9216,  ..., -0.2941, -0.4510, -0.5608],\n",
      "          [-0.9216, -0.9137, -0.8980,  ..., -0.5922, -0.4510, -0.2471],\n",
      "          [-0.9294, -0.9216, -0.8980,  ..., -0.2157, -0.3647, -0.4275],\n",
      "          ...,\n",
      "          [ 0.2000,  0.1922,  0.2314,  ...,  0.3647,  0.4039,  0.4039],\n",
      "          [ 0.1765,  0.2000,  0.2235,  ...,  0.4039,  0.3882,  0.4196],\n",
      "          [ 0.2000,  0.1922,  0.2157,  ...,  0.3961,  0.3804,  0.3255]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3569, -0.3725, -0.3647,  ...,  0.0667, -0.1059, -0.2706],\n",
      "          [-0.3412, -0.3490, -0.3804,  ...,  0.0039,  0.0039, -0.1529],\n",
      "          [-0.3020, -0.3098, -0.3804,  ..., -0.0353, -0.0275, -0.1451],\n",
      "          ...,\n",
      "          [-0.6471, -0.5922, -0.6471,  ..., -0.5451, -0.4118, -0.3961],\n",
      "          [-0.5529, -0.5843, -0.5686,  ..., -0.4745, -0.4431, -0.4824],\n",
      "          [-0.4588, -0.5137, -0.4980,  ..., -0.4980, -0.4431, -0.4745]],\n",
      "\n",
      "         [[ 0.0824,  0.0745,  0.0510,  ...,  0.1922,  0.1608,  0.1216],\n",
      "          [ 0.0980,  0.0667,  0.0353,  ...,  0.2157,  0.2235,  0.1529],\n",
      "          [ 0.0824,  0.0745,  0.0118,  ...,  0.2235,  0.2314,  0.1843],\n",
      "          ...,\n",
      "          [-0.2863, -0.2863, -0.4431,  ..., -0.0824,  0.0353, -0.0588],\n",
      "          [-0.2078, -0.2078, -0.2235,  ...,  0.0196, -0.0588, -0.1686],\n",
      "          [-0.1373, -0.1451, -0.1059,  ..., -0.0745, -0.0118, -0.0431]],\n",
      "\n",
      "         [[-0.2784, -0.2784, -0.3020,  ..., -0.0745, -0.1922, -0.2863],\n",
      "          [-0.2314, -0.2549, -0.3490,  ..., -0.0275, -0.0196, -0.2000],\n",
      "          [-0.2314, -0.2863, -0.3725,  ..., -0.0588, -0.0510, -0.1686],\n",
      "          ...,\n",
      "          [-0.8510, -0.5451, -0.6706,  ..., -0.6000, -0.2627, -0.3020],\n",
      "          [-0.6078, -0.6784, -0.4588,  ..., -0.4196, -0.3098, -0.4275],\n",
      "          [-0.4353, -0.5373, -0.4039,  ..., -0.4431, -0.3176, -0.3804]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          ...,\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.2706, -0.2863, -0.2392,  ..., -0.2941, -0.1451, -0.0824],\n",
      "          [-0.2706, -0.3098, -0.2863,  ..., -0.0118, -0.1137, -0.1608],\n",
      "          [-0.2549, -0.3176, -0.3098,  ..., -0.1216, -0.2863, -0.2235],\n",
      "          ...,\n",
      "          [ 0.0353, -0.0824, -0.1608,  ..., -0.1843, -0.2157, -0.3412],\n",
      "          [-0.0824,  0.0275, -0.0980,  ..., -0.0039,  0.0118, -0.0745],\n",
      "          [-0.0902, -0.0196, -0.0196,  ..., -0.1451, -0.3333, -0.4902]],\n",
      "\n",
      "         [[-0.6706, -0.6863, -0.6706,  ..., -0.5608, -0.5843, -0.6471],\n",
      "          [-0.6863, -0.7098, -0.7098,  ..., -0.5451, -0.5843, -0.6392],\n",
      "          [-0.6863, -0.7176, -0.6941,  ..., -0.6078, -0.6392, -0.5922],\n",
      "          ...,\n",
      "          [ 0.0510, -0.0667, -0.1373,  ..., -0.0980, -0.1529, -0.4118],\n",
      "          [ 0.1373,  0.1451, -0.0510,  ..., -0.0353,  0.0667, -0.1137],\n",
      "          [ 0.1137,  0.1765,  0.1686,  ..., -0.2392, -0.4118, -0.4431]],\n",
      "\n",
      "         [[-0.6314, -0.6471, -0.6157,  ..., -0.5608, -0.5451, -0.5843],\n",
      "          [-0.6392, -0.6706, -0.6627,  ..., -0.4980, -0.5294, -0.5765],\n",
      "          [-0.6392, -0.6784, -0.6627,  ..., -0.6157, -0.6392, -0.5765],\n",
      "          ...,\n",
      "          [-0.1765, -0.2706, -0.3961,  ..., -0.3176, -0.2392, -0.4667],\n",
      "          [-0.3176, -0.1765, -0.2549,  ..., -0.2471, -0.0510, -0.1922],\n",
      "          [-0.2549, -0.2078, -0.1608,  ..., -0.4118, -0.4824, -0.5922]]]]) tensor([6, 7, 6, 5, 5, 5, 5, 5, 0, 4, 4, 3, 8, 2, 6, 2, 4, 0, 7, 9, 7, 7, 3, 4,\n",
      "        3, 2, 4, 8, 1, 5, 0, 5, 3, 8, 2, 1, 5, 3, 8, 3, 7, 2, 4, 4, 3, 5, 6, 5,\n",
      "        8, 4, 2, 4, 4, 4, 9, 3, 7, 7, 8, 0, 4, 5, 8, 5])\n"
     ]
    }
   ],
   "source": [
    "for num, batch in enumerate(testloader):\n",
    "    if num > 10:\n",
    "        break\n",
    "    images, labels = batch\n",
    "    print(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22aaac41",
   "metadata": {
    "id": "22aaac41"
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, stride=1, num_block=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.num_block = num_block\n",
    "        self.layers = nn.ModuleList([])\n",
    "        \n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride)\n",
    "        ))\n",
    "        self.layers.append(nn.Sequential  (\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, stride=stride),\n",
    "#             nn.GroupNorm(out_channel//4, out_channel),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1, stride=1),\n",
    "            nn.GroupNorm(out_channel//4, out_channel),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ))\n",
    "        \n",
    "        for _ in range(1, num_block):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(out_channel, out_channel, kernel_size=1, stride=1)\n",
    "            ))\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1, stride=1),\n",
    "#                 nn.GroupNorm(out_channel//4, out_channel),\n",
    "                nn.BatchNorm2d(out_channel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1, stride=1),\n",
    "#                 nn.GroupNorm(out_channel//4, out_channel),\n",
    "                nn.BatchNorm2d(out_channel),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_block):\n",
    "            x_identity = self.layers[2*i](x)\n",
    "            x = self.layers[2*i+1](x)\n",
    "            x = F.relu(x + x_identity, inplace=True) \n",
    "        \n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=1, padding=1)\n",
    "#         self.gn1 = nn.GroupNorm(4, 16)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.layers1 = ResBlock(32, 32, num_block=2)\n",
    "        self.layers2 = ResBlock(32, 64, stride=2, num_block=2)\n",
    "        self.layers3 = ResBlock(64, 128, stride=2, num_block=2)\n",
    "        self.layers4 = ResBlock(128, 256, stride=2, num_block=2)\n",
    "        \n",
    "        self.avgpool1 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(256, 10)\n",
    "          \n",
    "    def forward(self, x, theta = None):\n",
    "        x = self.conv1(x)\n",
    "#         x = self.gn1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.layers1(x)\n",
    "        x = self.layers2(x)\n",
    "        \n",
    "        x1 = self.layers3(x)\n",
    "        x1 = self.layers4(x1)\n",
    "        x1 = self.avgpool1(x1)\n",
    "        x1 = x1.view(-1, 256)\n",
    "        x1 = self.fc1(x1)\n",
    "        \n",
    "        return x1\n",
    "\n",
    "\n",
    "class JointResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JointResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "#         self.gn1 = nn.GroupNorm(4, 16)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layers1 = ResBlock(64, 64, num_block=2)\n",
    "        self.layers2 = ResBlock(64, 128, stride=2, num_block=2)\n",
    "        self.layers3 = ResBlock(128, 256, stride=2, num_block=2)\n",
    "        self.layers4_1 = ResBlock(256, 512, stride=2, num_block=2)\n",
    "        self.layers4_2 = ResBlock(256, 512, stride=2, num_block=2)\n",
    "        \n",
    "        self.avgpool1 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512, 10)\n",
    "        \n",
    "        self.avgpool2 = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc2 = nn.Linear(512, 4)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, theta = None):\n",
    "        x = self.conv1(x)\n",
    "#         x = self.gn1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.layers1(x)\n",
    "        x = self.layers2(x)\n",
    "        x = self.layers3(x)\n",
    "        \n",
    "        x1 = self.layers4_1(x)\n",
    "        x1 = self.avgpool1(x1)\n",
    "        x1 = x1.view(-1, 512)\n",
    "        x1 = self.fc1(x1)\n",
    "        \n",
    "        x2 = self.layers4_2(x)\n",
    "        x2 = self.avgpool2(x2)\n",
    "        x2 = x2.view(-1, 512)\n",
    "        x2 = self.fc2(x2)\n",
    "        return x1, x2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dVDc-s2ToUOS",
   "metadata": {
    "id": "dVDc-s2ToUOS"
   },
   "outputs": [],
   "source": [
    "def check_accuracy_resnet(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    model.train() # set model back to train mode\n",
    "\n",
    "def check_accuracy_jointresnet(loader, model):\n",
    "    num_correct = 0\n",
    "    rot_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)  # move to device, e.g. GPU\n",
    "            label = y[0].to(device=device)\n",
    "            rot = y[1].to(device=device)\n",
    "            out1, out2 = model(x)\n",
    "            \n",
    "            _, preds = out1.max(1)\n",
    "            num_correct += (preds == label).sum()\n",
    "            _, preds_rot = out2.max(1)\n",
    "            rot_correct += (preds_rot == rot).sum()   \n",
    "            num_samples += preds.size(0)\n",
    "            \n",
    "        acc = float(num_correct) / num_samples\n",
    "        acc_rot = float(rot_correct) / num_samples\n",
    "        print('classification acc: {:.3f}, rotation pred acc: {:.3f}'.format(acc, acc_rot))\n",
    "    model.train() # set model back to train mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c6c75",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb4a7f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss functions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize the model and define optimizer\n",
    "model_resnet = ResNet().to(device)\n",
    "optimizer = optim.SGD(model_resnet.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd579559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Conv2d: 1-1                            [-1, 32, 96, 96]          896\n",
      "BatchNorm2d: 1-2                       [-1, 32, 96, 96]          64\n",
      "ResBlock: 1-3                          [-1, 32, 96, 96]          --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-1              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-2              [-1, 32, 96, 96]          18,624\n",
      "|    |    Sequential: 3-3              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-4              [-1, 32, 96, 96]          18,624\n",
      "|    |    Sequential: 3-5              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-6              [-1, 32, 96, 96]          18,624\n",
      "|    |    Sequential: 3-7              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-8              [-1, 32, 96, 96]          18,624\n",
      "ResBlock: 1-4                          [-1, 64, 48, 48]          --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-9              [-1, 64, 48, 48]          2,112\n",
      "|    |    Sequential: 3-10             [-1, 64, 48, 48]          55,680\n",
      "|    |    Sequential: 3-11             [-1, 64, 48, 48]          4,160\n",
      "|    |    Sequential: 3-12             [-1, 64, 48, 48]          74,112\n",
      "ResBlock: 1-5                          [-1, 128, 24, 24]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-13             [-1, 128, 24, 24]         8,320\n",
      "|    |    Sequential: 3-14             [-1, 128, 24, 24]         221,952\n",
      "|    |    Sequential: 3-15             [-1, 128, 24, 24]         16,512\n",
      "|    |    Sequential: 3-16             [-1, 128, 24, 24]         295,680\n",
      "ResBlock: 1-6                          [-1, 256, 12, 12]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-17             [-1, 256, 12, 12]         33,024\n",
      "|    |    Sequential: 3-18             [-1, 256, 12, 12]         886,272\n",
      "|    |    Sequential: 3-19             [-1, 256, 12, 12]         65,792\n",
      "|    |    Sequential: 3-20             [-1, 256, 12, 12]         1,181,184\n",
      "AdaptiveAvgPool2d: 1-7                 [-1, 256, 1, 1]           --\n",
      "Linear: 1-8                            [-1, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 2,927,050\n",
      "Trainable params: 2,927,050\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.67\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 69.19\n",
      "Params size (MB): 11.17\n",
      "Estimated Total Size (MB): 80.46\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Conv2d: 1-1                            [-1, 32, 96, 96]          896\n",
      "BatchNorm2d: 1-2                       [-1, 32, 96, 96]          64\n",
      "ResBlock: 1-3                          [-1, 32, 96, 96]          --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-1              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-2              [-1, 32, 96, 96]          18,624\n",
      "|    |    Sequential: 3-3              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-4              [-1, 32, 96, 96]          18,624\n",
      "|    |    Sequential: 3-5              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-6              [-1, 32, 96, 96]          18,624\n",
      "|    |    Sequential: 3-7              [-1, 32, 96, 96]          1,056\n",
      "|    |    Sequential: 3-8              [-1, 32, 96, 96]          18,624\n",
      "ResBlock: 1-4                          [-1, 64, 48, 48]          --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-9              [-1, 64, 48, 48]          2,112\n",
      "|    |    Sequential: 3-10             [-1, 64, 48, 48]          55,680\n",
      "|    |    Sequential: 3-11             [-1, 64, 48, 48]          4,160\n",
      "|    |    Sequential: 3-12             [-1, 64, 48, 48]          74,112\n",
      "ResBlock: 1-5                          [-1, 128, 24, 24]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-13             [-1, 128, 24, 24]         8,320\n",
      "|    |    Sequential: 3-14             [-1, 128, 24, 24]         221,952\n",
      "|    |    Sequential: 3-15             [-1, 128, 24, 24]         16,512\n",
      "|    |    Sequential: 3-16             [-1, 128, 24, 24]         295,680\n",
      "ResBlock: 1-6                          [-1, 256, 12, 12]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-17             [-1, 256, 12, 12]         33,024\n",
      "|    |    Sequential: 3-18             [-1, 256, 12, 12]         886,272\n",
      "|    |    Sequential: 3-19             [-1, 256, 12, 12]         65,792\n",
      "|    |    Sequential: 3-20             [-1, 256, 12, 12]         1,181,184\n",
      "AdaptiveAvgPool2d: 1-7                 [-1, 256, 1, 1]           --\n",
      "Linear: 1-8                            [-1, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 2,927,050\n",
      "Trainable params: 2,927,050\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 1.67\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 69.19\n",
      "Params size (MB): 11.17\n",
      "Estimated Total Size (MB): 80.46\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model_resnet, (3, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e7c6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=128, num_workers=2, \n",
    "                                          sampler=sampler.SubsetRandomSampler(range(4000)))\n",
    "\n",
    "valloader = DataLoader(valset, batch_size=128, num_workers=2, \n",
    "                                          sampler=sampler.SubsetRandomSampler(range(4000, 5000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bb1e3b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/32], Loss: 2.3263\n",
      "Epoch [1/100], Step [20/32], Loss: 1.9546\n",
      "Epoch [1/100], Step [30/32], Loss: 1.7929\n",
      "Epoch [2/100], Step [10/32], Loss: 1.7931\n",
      "Epoch [2/100], Step [20/32], Loss: 1.8740\n",
      "Epoch [2/100], Step [30/32], Loss: 1.7692\n",
      "Epoch [3/100], Step [10/32], Loss: 1.6283\n",
      "Epoch [3/100], Step [20/32], Loss: 1.5758\n",
      "Epoch [3/100], Step [30/32], Loss: 1.6563\n",
      "Epoch [4/100], Step [10/32], Loss: 1.5602\n",
      "Epoch [4/100], Step [20/32], Loss: 1.4731\n",
      "Epoch [4/100], Step [30/32], Loss: 1.7134\n",
      "Epoch [5/100], Step [10/32], Loss: 1.6197\n",
      "Epoch [5/100], Step [20/32], Loss: 1.4012\n",
      "Epoch [5/100], Step [30/32], Loss: 1.4689\n",
      "Training:\n",
      "Got 1226 / 4000 correct (30.65)\n",
      "Validation:\n",
      "Got 295 / 1000 correct (29.50)\n",
      "Epoch [6/100], Step [10/32], Loss: 1.5026\n",
      "Epoch [6/100], Step [20/32], Loss: 1.3184\n",
      "Epoch [6/100], Step [30/32], Loss: 1.4938\n",
      "Epoch [7/100], Step [10/32], Loss: 1.4121\n",
      "Epoch [7/100], Step [20/32], Loss: 1.4078\n",
      "Epoch [7/100], Step [30/32], Loss: 1.3104\n",
      "Epoch [8/100], Step [10/32], Loss: 1.3935\n",
      "Epoch [8/100], Step [20/32], Loss: 1.2820\n",
      "Epoch [8/100], Step [30/32], Loss: 1.3199\n",
      "Epoch [9/100], Step [10/32], Loss: 1.4068\n",
      "Epoch [9/100], Step [20/32], Loss: 1.1564\n",
      "Epoch [9/100], Step [30/32], Loss: 1.3769\n",
      "Epoch [10/100], Step [10/32], Loss: 1.2101\n",
      "Epoch [10/100], Step [20/32], Loss: 1.1468\n",
      "Epoch [10/100], Step [30/32], Loss: 1.1394\n",
      "Training:\n",
      "Got 1865 / 4000 correct (46.62)\n",
      "Validation:\n",
      "Got 437 / 1000 correct (43.70)\n",
      "Epoch [11/100], Step [10/32], Loss: 1.1524\n",
      "Epoch [11/100], Step [20/32], Loss: 1.2713\n",
      "Epoch [11/100], Step [30/32], Loss: 1.0716\n",
      "Epoch [12/100], Step [10/32], Loss: 1.0531\n",
      "Epoch [12/100], Step [20/32], Loss: 1.0627\n",
      "Epoch [12/100], Step [30/32], Loss: 0.9698\n",
      "Epoch [13/100], Step [10/32], Loss: 1.1558\n",
      "Epoch [13/100], Step [20/32], Loss: 1.0725\n",
      "Epoch [13/100], Step [30/32], Loss: 1.0638\n",
      "Epoch [14/100], Step [10/32], Loss: 0.9416\n",
      "Epoch [14/100], Step [20/32], Loss: 0.9819\n",
      "Epoch [14/100], Step [30/32], Loss: 0.9738\n",
      "Epoch [15/100], Step [10/32], Loss: 0.8139\n",
      "Epoch [15/100], Step [20/32], Loss: 0.8176\n",
      "Epoch [15/100], Step [30/32], Loss: 0.9247\n",
      "Training:\n",
      "Got 2024 / 4000 correct (50.60)\n",
      "Validation:\n",
      "Got 473 / 1000 correct (47.30)\n",
      "Epoch [16/100], Step [10/32], Loss: 1.0765\n",
      "Epoch [16/100], Step [20/32], Loss: 0.9487\n",
      "Epoch [16/100], Step [30/32], Loss: 0.9780\n",
      "Epoch [17/100], Step [10/32], Loss: 0.9136\n",
      "Epoch [17/100], Step [20/32], Loss: 0.8221\n",
      "Epoch [17/100], Step [30/32], Loss: 0.8034\n",
      "Epoch [18/100], Step [10/32], Loss: 0.8122\n",
      "Epoch [18/100], Step [20/32], Loss: 0.8358\n",
      "Epoch [18/100], Step [30/32], Loss: 0.9041\n",
      "Epoch [19/100], Step [10/32], Loss: 0.7655\n",
      "Epoch [19/100], Step [20/32], Loss: 0.7280\n",
      "Epoch [19/100], Step [30/32], Loss: 0.8554\n",
      "Epoch [20/100], Step [10/32], Loss: 0.8043\n",
      "Epoch [20/100], Step [20/32], Loss: 0.8677\n",
      "Epoch [20/100], Step [30/32], Loss: 0.6863\n",
      "Training:\n",
      "Got 2844 / 4000 correct (71.10)\n",
      "Validation:\n",
      "Got 650 / 1000 correct (65.00)\n",
      "Epoch [21/100], Step [10/32], Loss: 0.7781\n",
      "Epoch [21/100], Step [20/32], Loss: 0.5715\n",
      "Epoch [21/100], Step [30/32], Loss: 0.7655\n",
      "Epoch [22/100], Step [10/32], Loss: 0.6072\n",
      "Epoch [22/100], Step [20/32], Loss: 0.6951\n",
      "Epoch [22/100], Step [30/32], Loss: 0.6955\n",
      "Epoch [23/100], Step [10/32], Loss: 0.7023\n",
      "Epoch [23/100], Step [20/32], Loss: 0.7621\n",
      "Epoch [23/100], Step [30/32], Loss: 0.6634\n",
      "Epoch [24/100], Step [10/32], Loss: 0.6451\n",
      "Epoch [24/100], Step [20/32], Loss: 0.6632\n",
      "Epoch [24/100], Step [30/32], Loss: 0.6683\n",
      "Epoch [25/100], Step [10/32], Loss: 0.6466\n",
      "Epoch [25/100], Step [20/32], Loss: 0.4903\n",
      "Epoch [25/100], Step [30/32], Loss: 0.6437\n",
      "Training:\n",
      "Got 2936 / 4000 correct (73.40)\n",
      "Validation:\n",
      "Got 652 / 1000 correct (65.20)\n",
      "Epoch [26/100], Step [10/32], Loss: 0.6820\n",
      "Epoch [26/100], Step [20/32], Loss: 0.5211\n",
      "Epoch [26/100], Step [30/32], Loss: 0.6938\n",
      "Epoch [27/100], Step [10/32], Loss: 0.4938\n",
      "Epoch [27/100], Step [20/32], Loss: 0.4351\n",
      "Epoch [27/100], Step [30/32], Loss: 0.5452\n",
      "Epoch [28/100], Step [10/32], Loss: 0.4809\n",
      "Epoch [28/100], Step [20/32], Loss: 0.4005\n",
      "Epoch [28/100], Step [30/32], Loss: 0.4642\n",
      "Epoch [29/100], Step [10/32], Loss: 0.4355\n",
      "Epoch [29/100], Step [20/32], Loss: 0.5619\n",
      "Epoch [29/100], Step [30/32], Loss: 0.5408\n",
      "Epoch [30/100], Step [10/32], Loss: 0.5277\n",
      "Epoch [30/100], Step [20/32], Loss: 0.3382\n",
      "Epoch [30/100], Step [30/32], Loss: 0.4570\n",
      "Training:\n",
      "Got 2576 / 4000 correct (64.40)\n",
      "Validation:\n",
      "Got 540 / 1000 correct (54.00)\n",
      "Epoch [31/100], Step [10/32], Loss: 0.2754\n",
      "Epoch [31/100], Step [20/32], Loss: 0.2902\n",
      "Epoch [31/100], Step [30/32], Loss: 0.2606\n",
      "Epoch [32/100], Step [10/32], Loss: 0.3029\n",
      "Epoch [32/100], Step [20/32], Loss: 0.2494\n",
      "Epoch [32/100], Step [30/32], Loss: 0.3843\n",
      "Epoch [33/100], Step [10/32], Loss: 0.2628\n",
      "Epoch [33/100], Step [20/32], Loss: 0.2171\n",
      "Epoch [33/100], Step [30/32], Loss: 0.2023\n",
      "Epoch [34/100], Step [10/32], Loss: 0.2474\n",
      "Epoch [34/100], Step [20/32], Loss: 0.2165\n",
      "Epoch [34/100], Step [30/32], Loss: 0.2028\n",
      "Epoch [35/100], Step [10/32], Loss: 0.1920\n",
      "Epoch [35/100], Step [20/32], Loss: 0.1927\n",
      "Epoch [35/100], Step [30/32], Loss: 0.1889\n",
      "Training:\n",
      "Got 3798 / 4000 correct (94.95)\n",
      "Validation:\n",
      "Got 737 / 1000 correct (73.70)\n",
      "Epoch [36/100], Step [10/32], Loss: 0.1401\n",
      "Epoch [36/100], Step [20/32], Loss: 0.1824\n",
      "Epoch [36/100], Step [30/32], Loss: 0.2135\n",
      "Epoch [37/100], Step [10/32], Loss: 0.1526\n",
      "Epoch [37/100], Step [20/32], Loss: 0.2074\n",
      "Epoch [37/100], Step [30/32], Loss: 0.1734\n",
      "Epoch [38/100], Step [10/32], Loss: 0.1732\n",
      "Epoch [38/100], Step [20/32], Loss: 0.1528\n",
      "Epoch [38/100], Step [30/32], Loss: 0.1716\n",
      "Epoch [39/100], Step [10/32], Loss: 0.1766\n",
      "Epoch [39/100], Step [20/32], Loss: 0.1372\n",
      "Epoch [39/100], Step [30/32], Loss: 0.1671\n",
      "Epoch [40/100], Step [10/32], Loss: 0.1742\n",
      "Epoch [40/100], Step [20/32], Loss: 0.1543\n",
      "Epoch [40/100], Step [30/32], Loss: 0.1884\n",
      "Training:\n",
      "Got 3874 / 4000 correct (96.85)\n",
      "Validation:\n",
      "Got 745 / 1000 correct (74.50)\n",
      "Epoch [41/100], Step [10/32], Loss: 0.1147\n",
      "Epoch [41/100], Step [20/32], Loss: 0.1398\n",
      "Epoch [41/100], Step [30/32], Loss: 0.1395\n",
      "Epoch [42/100], Step [10/32], Loss: 0.0948\n",
      "Epoch [42/100], Step [20/32], Loss: 0.1303\n",
      "Epoch [42/100], Step [30/32], Loss: 0.1803\n",
      "Epoch [43/100], Step [10/32], Loss: 0.1151\n",
      "Epoch [43/100], Step [20/32], Loss: 0.1117\n",
      "Epoch [43/100], Step [30/32], Loss: 0.1801\n",
      "Epoch [44/100], Step [10/32], Loss: 0.0807\n",
      "Epoch [44/100], Step [20/32], Loss: 0.1513\n",
      "Epoch [44/100], Step [30/32], Loss: 0.1129\n",
      "Epoch [45/100], Step [10/32], Loss: 0.1579\n",
      "Epoch [45/100], Step [20/32], Loss: 0.1103\n",
      "Epoch [45/100], Step [30/32], Loss: 0.0902\n",
      "Training:\n",
      "Got 3931 / 4000 correct (98.28)\n",
      "Validation:\n",
      "Got 732 / 1000 correct (73.20)\n",
      "Epoch [46/100], Step [10/32], Loss: 0.1233\n",
      "Epoch [46/100], Step [20/32], Loss: 0.0936\n",
      "Epoch [46/100], Step [30/32], Loss: 0.1116\n",
      "Epoch [47/100], Step [10/32], Loss: 0.1196\n",
      "Epoch [47/100], Step [20/32], Loss: 0.0806\n",
      "Epoch [47/100], Step [30/32], Loss: 0.0806\n",
      "Epoch [48/100], Step [10/32], Loss: 0.0805\n",
      "Epoch [48/100], Step [20/32], Loss: 0.1197\n",
      "Epoch [48/100], Step [30/32], Loss: 0.0979\n",
      "Epoch [49/100], Step [10/32], Loss: 0.0947\n",
      "Epoch [49/100], Step [20/32], Loss: 0.1387\n",
      "Epoch [49/100], Step [30/32], Loss: 0.1031\n",
      "Epoch [50/100], Step [10/32], Loss: 0.0678\n",
      "Epoch [50/100], Step [20/32], Loss: 0.0629\n",
      "Epoch [50/100], Step [30/32], Loss: 0.1433\n",
      "Training:\n",
      "Got 3965 / 4000 correct (99.12)\n",
      "Validation:\n",
      "Got 735 / 1000 correct (73.50)\n",
      "Epoch [51/100], Step [10/32], Loss: 0.0665\n",
      "Epoch [51/100], Step [20/32], Loss: 0.0457\n",
      "Epoch [51/100], Step [30/32], Loss: 0.1170\n",
      "Epoch [52/100], Step [10/32], Loss: 0.0716\n",
      "Epoch [52/100], Step [20/32], Loss: 0.0749\n",
      "Epoch [52/100], Step [30/32], Loss: 0.0761\n",
      "Epoch [53/100], Step [10/32], Loss: 0.0796\n",
      "Epoch [53/100], Step [20/32], Loss: 0.1008\n",
      "Epoch [53/100], Step [30/32], Loss: 0.0947\n",
      "Epoch [54/100], Step [10/32], Loss: 0.1087\n",
      "Epoch [54/100], Step [20/32], Loss: 0.0737\n",
      "Epoch [54/100], Step [30/32], Loss: 0.0561\n",
      "Epoch [55/100], Step [10/32], Loss: 0.0755\n",
      "Epoch [55/100], Step [20/32], Loss: 0.0776\n",
      "Epoch [55/100], Step [30/32], Loss: 0.0713\n",
      "Training:\n",
      "Got 3966 / 4000 correct (99.15)\n",
      "Validation:\n",
      "Got 734 / 1000 correct (73.40)\n",
      "Epoch [56/100], Step [10/32], Loss: 0.0525\n",
      "Epoch [56/100], Step [20/32], Loss: 0.0636\n",
      "Epoch [56/100], Step [30/32], Loss: 0.0458\n",
      "Epoch [57/100], Step [10/32], Loss: 0.0599\n",
      "Epoch [57/100], Step [20/32], Loss: 0.0562\n",
      "Epoch [57/100], Step [30/32], Loss: 0.0530\n",
      "Epoch [58/100], Step [10/32], Loss: 0.0562\n",
      "Epoch [58/100], Step [20/32], Loss: 0.0518\n",
      "Epoch [58/100], Step [30/32], Loss: 0.0691\n",
      "Epoch [59/100], Step [10/32], Loss: 0.0454\n",
      "Epoch [59/100], Step [20/32], Loss: 0.0549\n",
      "Epoch [59/100], Step [30/32], Loss: 0.0463\n",
      "Epoch [60/100], Step [10/32], Loss: 0.0884\n",
      "Epoch [60/100], Step [20/32], Loss: 0.0483\n",
      "Epoch [60/100], Step [30/32], Loss: 0.0518\n",
      "Training:\n",
      "Got 3984 / 4000 correct (99.60)\n",
      "Validation:\n",
      "Got 747 / 1000 correct (74.70)\n",
      "Epoch [61/100], Step [10/32], Loss: 0.0599\n",
      "Epoch [61/100], Step [20/32], Loss: 0.0486\n",
      "Epoch [61/100], Step [30/32], Loss: 0.0352\n",
      "Epoch [62/100], Step [10/32], Loss: 0.0529\n",
      "Epoch [62/100], Step [20/32], Loss: 0.0488\n",
      "Epoch [62/100], Step [30/32], Loss: 0.0399\n",
      "Epoch [63/100], Step [10/32], Loss: 0.0495\n",
      "Epoch [63/100], Step [20/32], Loss: 0.0339\n",
      "Epoch [63/100], Step [30/32], Loss: 0.0476\n",
      "Epoch [64/100], Step [10/32], Loss: 0.0336\n",
      "Epoch [64/100], Step [20/32], Loss: 0.0703\n",
      "Epoch [64/100], Step [30/32], Loss: 0.0515\n",
      "Epoch [65/100], Step [10/32], Loss: 0.0466\n",
      "Epoch [65/100], Step [20/32], Loss: 0.0387\n",
      "Epoch [65/100], Step [30/32], Loss: 0.0319\n",
      "Training:\n",
      "Got 3994 / 4000 correct (99.85)\n",
      "Validation:\n",
      "Got 750 / 1000 correct (75.00)\n",
      "Epoch [66/100], Step [10/32], Loss: 0.0288\n",
      "Epoch [66/100], Step [20/32], Loss: 0.0452\n",
      "Epoch [66/100], Step [30/32], Loss: 0.0446\n",
      "Epoch [67/100], Step [10/32], Loss: 0.0428\n",
      "Epoch [67/100], Step [20/32], Loss: 0.0337\n",
      "Epoch [67/100], Step [30/32], Loss: 0.0386\n",
      "Epoch [68/100], Step [10/32], Loss: 0.0347\n",
      "Epoch [68/100], Step [20/32], Loss: 0.0209\n",
      "Epoch [68/100], Step [30/32], Loss: 0.0366\n",
      "Epoch [69/100], Step [10/32], Loss: 0.0429\n",
      "Epoch [69/100], Step [20/32], Loss: 0.0327\n",
      "Epoch [69/100], Step [30/32], Loss: 0.0483\n",
      "Epoch [70/100], Step [10/32], Loss: 0.0844\n",
      "Epoch [70/100], Step [20/32], Loss: 0.0495\n",
      "Epoch [70/100], Step [30/32], Loss: 0.0335\n",
      "Training:\n",
      "Got 3992 / 4000 correct (99.80)\n",
      "Validation:\n",
      "Got 751 / 1000 correct (75.10)\n",
      "Epoch [71/100], Step [10/32], Loss: 0.0318\n",
      "Epoch [71/100], Step [20/32], Loss: 0.0630\n",
      "Epoch [71/100], Step [30/32], Loss: 0.0398\n",
      "Epoch [72/100], Step [10/32], Loss: 0.0509\n",
      "Epoch [72/100], Step [20/32], Loss: 0.0522\n",
      "Epoch [72/100], Step [30/32], Loss: 0.0364\n",
      "Epoch [73/100], Step [10/32], Loss: 0.0530\n",
      "Epoch [73/100], Step [20/32], Loss: 0.0350\n",
      "Epoch [73/100], Step [30/32], Loss: 0.0526\n",
      "Epoch [74/100], Step [10/32], Loss: 0.0411\n",
      "Epoch [74/100], Step [20/32], Loss: 0.0356\n",
      "Epoch [74/100], Step [30/32], Loss: 0.0470\n",
      "Epoch [75/100], Step [10/32], Loss: 0.0460\n",
      "Epoch [75/100], Step [20/32], Loss: 0.0411\n",
      "Epoch [75/100], Step [30/32], Loss: 0.0332\n",
      "Training:\n",
      "Got 3997 / 4000 correct (99.92)\n",
      "Validation:\n",
      "Got 747 / 1000 correct (74.70)\n",
      "Epoch [76/100], Step [10/32], Loss: 0.0378\n",
      "Epoch [76/100], Step [20/32], Loss: 0.0299\n",
      "Epoch [76/100], Step [30/32], Loss: 0.0395\n",
      "Epoch [77/100], Step [10/32], Loss: 0.0413\n",
      "Epoch [77/100], Step [20/32], Loss: 0.0233\n",
      "Epoch [77/100], Step [30/32], Loss: 0.0346\n",
      "Epoch [78/100], Step [10/32], Loss: 0.0215\n",
      "Epoch [78/100], Step [20/32], Loss: 0.0341\n",
      "Epoch [78/100], Step [30/32], Loss: 0.0546\n",
      "Epoch [79/100], Step [10/32], Loss: 0.0315\n",
      "Epoch [79/100], Step [20/32], Loss: 0.0318\n",
      "Epoch [79/100], Step [30/32], Loss: 0.0343\n",
      "Epoch [80/100], Step [10/32], Loss: 0.0340\n",
      "Epoch [80/100], Step [20/32], Loss: 0.0354\n",
      "Epoch [80/100], Step [30/32], Loss: 0.0435\n",
      "Training:\n",
      "Got 3995 / 4000 correct (99.88)\n",
      "Validation:\n",
      "Got 750 / 1000 correct (75.00)\n",
      "Epoch [81/100], Step [10/32], Loss: 0.0406\n",
      "Epoch [81/100], Step [20/32], Loss: 0.0199\n",
      "Epoch [81/100], Step [30/32], Loss: 0.0507\n",
      "Epoch [82/100], Step [10/32], Loss: 0.0303\n",
      "Epoch [82/100], Step [20/32], Loss: 0.0293\n",
      "Epoch [82/100], Step [30/32], Loss: 0.0603\n",
      "Epoch [83/100], Step [10/32], Loss: 0.0365\n",
      "Epoch [83/100], Step [20/32], Loss: 0.0324\n",
      "Epoch [83/100], Step [30/32], Loss: 0.0305\n",
      "Epoch [84/100], Step [10/32], Loss: 0.0364\n",
      "Epoch [84/100], Step [20/32], Loss: 0.0342\n",
      "Epoch [84/100], Step [30/32], Loss: 0.0407\n",
      "Epoch [85/100], Step [10/32], Loss: 0.0397\n",
      "Epoch [85/100], Step [20/32], Loss: 0.0292\n",
      "Epoch [85/100], Step [30/32], Loss: 0.0331\n",
      "Training:\n",
      "Got 3993 / 4000 correct (99.83)\n",
      "Validation:\n",
      "Got 754 / 1000 correct (75.40)\n",
      "Epoch [86/100], Step [10/32], Loss: 0.0344\n",
      "Epoch [86/100], Step [20/32], Loss: 0.0432\n",
      "Epoch [86/100], Step [30/32], Loss: 0.0425\n",
      "Epoch [87/100], Step [10/32], Loss: 0.0338\n",
      "Epoch [87/100], Step [20/32], Loss: 0.0350\n",
      "Epoch [87/100], Step [30/32], Loss: 0.0372\n",
      "Epoch [88/100], Step [10/32], Loss: 0.0496\n",
      "Epoch [88/100], Step [20/32], Loss: 0.0228\n",
      "Epoch [88/100], Step [30/32], Loss: 0.0395\n",
      "Epoch [89/100], Step [10/32], Loss: 0.0341\n",
      "Epoch [89/100], Step [20/32], Loss: 0.0313\n",
      "Epoch [89/100], Step [30/32], Loss: 0.0329\n",
      "Epoch [90/100], Step [10/32], Loss: 0.0285\n",
      "Epoch [90/100], Step [20/32], Loss: 0.0390\n",
      "Epoch [90/100], Step [30/32], Loss: 0.0312\n",
      "Training:\n",
      "Got 3997 / 4000 correct (99.92)\n",
      "Validation:\n",
      "Got 752 / 1000 correct (75.20)\n",
      "Epoch [91/100], Step [10/32], Loss: 0.0458\n",
      "Epoch [91/100], Step [20/32], Loss: 0.0262\n",
      "Epoch [91/100], Step [30/32], Loss: 0.0379\n",
      "Epoch [92/100], Step [10/32], Loss: 0.0292\n",
      "Epoch [92/100], Step [20/32], Loss: 0.0429\n",
      "Epoch [92/100], Step [30/32], Loss: 0.0194\n",
      "Epoch [93/100], Step [10/32], Loss: 0.0344\n",
      "Epoch [93/100], Step [20/32], Loss: 0.0330\n",
      "Epoch [93/100], Step [30/32], Loss: 0.0472\n",
      "Epoch [94/100], Step [10/32], Loss: 0.0230\n",
      "Epoch [94/100], Step [20/32], Loss: 0.0372\n",
      "Epoch [94/100], Step [30/32], Loss: 0.0325\n",
      "Epoch [95/100], Step [10/32], Loss: 0.0309\n",
      "Epoch [95/100], Step [20/32], Loss: 0.0301\n",
      "Epoch [95/100], Step [30/32], Loss: 0.0328\n",
      "Training:\n",
      "Got 3997 / 4000 correct (99.92)\n",
      "Validation:\n",
      "Got 754 / 1000 correct (75.40)\n",
      "Epoch [96/100], Step [10/32], Loss: 0.0419\n",
      "Epoch [96/100], Step [20/32], Loss: 0.0353\n",
      "Epoch [96/100], Step [30/32], Loss: 0.0785\n",
      "Epoch [97/100], Step [10/32], Loss: 0.0291\n",
      "Epoch [97/100], Step [20/32], Loss: 0.0272\n",
      "Epoch [97/100], Step [30/32], Loss: 0.0411\n",
      "Epoch [98/100], Step [10/32], Loss: 0.0601\n",
      "Epoch [98/100], Step [20/32], Loss: 0.0307\n",
      "Epoch [98/100], Step [30/32], Loss: 0.0348\n",
      "Epoch [99/100], Step [10/32], Loss: 0.0582\n",
      "Epoch [99/100], Step [20/32], Loss: 0.0471\n",
      "Epoch [99/100], Step [30/32], Loss: 0.0348\n",
      "Epoch [100/100], Step [10/32], Loss: 0.0261\n",
      "Epoch [100/100], Step [20/32], Loss: 0.0247\n",
      "Epoch [100/100], Step [30/32], Loss: 0.0283\n",
      "Training:\n",
      "Got 3999 / 4000 correct (99.98)\n",
      "Validation:\n",
      "Got 747 / 1000 correct (74.70)\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        out = model_resnet(images)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(out, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "#         # Update the scheduler\n",
    "#         scheduler.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Update the scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print('Training:')        \n",
    "        check_accuracy_resnet(trainloader, model_resnet)    \n",
    "\n",
    "        print('Validation:')        \n",
    "        check_accuracy_resnet(valloader, model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "420f8e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for image classification: 72.86 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        labels = labels.to(torch.int64)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        out = model_resnet(images)\n",
    "\n",
    "        # Compute the accuracy for branch\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print('Accuracy for image classification: {:.2f} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bc3a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save({\n",
    "            'model_state_dict': model_resnet.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, 'models/stl_resnet.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d840f",
   "metadata": {
    "id": "fb3d840f"
   },
   "source": [
    "## Joint Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6353a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 7, 8, 5, 4, 1, 0, 9, 1, 4, 1, 4, 8, 5, 9, 3, 3, 2, 2, 1, 2, 4, 7, 7,\n",
      "        8, 7, 9, 7, 7, 2, 0, 0, 7, 3, 8, 9, 5, 5, 5, 3, 6, 2, 3, 7, 6, 7, 1, 1,\n",
      "        0, 9, 6, 1, 0, 3, 2, 1, 5, 8, 1, 6, 4, 0, 0, 2, 9, 0, 5, 1, 5, 9, 4, 5,\n",
      "        6, 6, 3, 5, 4, 4, 4, 6, 2, 6, 5, 4, 3, 8, 2, 0, 9, 3, 3, 9, 0, 8, 2, 9,\n",
      "        9, 5, 0, 5, 0, 9, 4, 0, 4, 6, 2, 5, 0, 8, 8, 5, 9, 6, 7, 5, 2, 8, 3, 5,\n",
      "        6, 3, 4, 7, 7, 7, 4, 2]), tensor([2, 0, 1, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0,\n",
      "        0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 3, 1, 0, 0, 0, 2, 3, 2, 0,\n",
      "        2, 2, 0, 3, 0, 0, 1, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 2, 0, 3, 3, 0, 0, 1, 0, 2, 0,\n",
      "        3, 0, 3, 0, 0, 0, 2, 3, 2, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0,\n",
      "        2, 2, 0, 1, 0, 0, 0, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 2, 7, 3, 4, 5, 2, 7, 6, 0, 9, 8, 6, 3, 4, 8, 0, 6, 4, 2, 5, 7, 3, 5,\n",
      "        3, 6, 6, 9, 4, 1, 7, 1, 2, 4, 1, 2, 2, 8, 3, 6, 2, 2, 7, 4, 8, 2, 5, 4,\n",
      "        7, 0, 0, 3, 2, 2, 1, 2, 1, 7, 5, 8, 0, 3, 2, 0, 4, 3, 6, 7, 5, 0, 8, 4,\n",
      "        6, 0, 8, 8, 6, 4, 1, 5, 2, 8, 0, 9, 3, 3, 2, 1, 1, 2, 9, 2, 1, 1, 4, 6,\n",
      "        8, 7, 3, 1, 7, 0, 6, 8, 4, 0, 9, 8, 4, 6, 7, 1, 4, 6, 8, 0, 3, 5, 2, 8,\n",
      "        3, 2, 1, 2, 4, 7, 7, 7]), tensor([2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 2, 2, 0, 3, 3, 1, 3, 1, 3, 0,\n",
      "        0, 0, 0, 0, 3, 3, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 1, 3, 1, 2,\n",
      "        0, 0, 0, 0, 2, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
      "        3, 1, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 2, 2, 0, 1, 3, 2, 0,\n",
      "        1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 2, 2, 1, 3, 0, 0, 0, 3, 3, 3, 0,\n",
      "        0, 0, 0, 3, 0, 1, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([1, 6, 0, 6, 5, 9, 5, 0, 9, 3, 1, 9, 1, 5, 4, 0, 8, 9, 4, 7, 6, 5, 9, 4,\n",
      "        5, 8, 5, 7, 2, 2, 7, 5, 7, 3, 3, 6, 0, 8, 2, 1, 9, 1, 5, 5, 1, 8, 7, 9,\n",
      "        5, 4, 7, 5, 9, 1, 1, 9, 9, 3, 6, 4, 7, 5, 4, 3, 3, 6, 6, 7, 5, 8, 1, 0,\n",
      "        6, 1, 0, 5, 2, 1, 8, 1, 2, 0, 6, 5, 0, 5, 2, 5, 8, 9, 0, 1, 7, 0, 9, 6,\n",
      "        4, 5, 4, 2, 2, 0, 6, 8, 4, 8, 4, 5, 6, 8, 3, 6, 4, 9, 0, 0, 6, 1, 0, 0,\n",
      "        8, 6, 3, 6, 5, 6, 2, 4]), tensor([0, 0, 2, 3, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 0, 0,\n",
      "        0, 3, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0,\n",
      "        0, 2, 2, 3, 2, 1, 2, 3, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 0,\n",
      "        2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 0, 0, 2, 0, 0, 3,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 3, 0, 1, 2, 0, 0, 3, 3, 0, 2, 1, 1, 0, 2,\n",
      "        0, 2, 0, 0, 1, 0, 0, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 3, 9, 4, 1, 4, 2, 6, 2, 4, 3, 4, 0, 4, 8, 3, 5, 2, 2, 6, 7, 9, 8, 2,\n",
      "        2, 1, 4, 3, 2, 3, 8, 8, 4, 0, 5, 7, 2, 9, 6, 1, 7, 6, 1, 3, 2, 1, 3, 3,\n",
      "        7, 7, 2, 7, 6, 5, 5, 7, 0, 7, 8, 9, 9, 2, 2, 3, 8, 8, 1, 0, 3, 6, 2, 1,\n",
      "        8, 0, 5, 7, 8, 4, 0, 9, 7, 3, 7, 8, 2, 8, 3, 2, 0, 4, 1, 9, 4, 6, 6, 0,\n",
      "        7, 2, 2, 6, 4, 4, 2, 0, 7, 9, 7, 5, 3, 3, 2, 1, 8, 1, 0, 5, 6, 7, 6, 8,\n",
      "        8, 1, 9, 5, 9, 5, 0, 4]), tensor([0, 3, 0, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 3, 0, 3, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0,\n",
      "        3, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 1, 0, 3, 3, 0, 0, 3, 0, 2, 2,\n",
      "        0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 2, 0, 1, 3, 0, 0, 3, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
      "        0, 0, 0, 0, 2, 2, 2, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([9, 4, 6, 9, 9, 4, 9, 9, 4, 5, 9, 0, 6, 8, 5, 1, 0, 9, 0, 2, 4, 4, 5, 5,\n",
      "        2, 1, 2, 2, 6, 2, 9, 1, 0, 5, 6, 8, 4, 5, 2, 7, 7, 8, 7, 8, 2, 8, 4, 5,\n",
      "        6, 4, 6, 6, 7, 4, 3, 7, 5, 2, 8, 4, 5, 5, 2, 0, 3, 7, 4, 7, 9, 2, 0, 4,\n",
      "        8, 1, 2, 1, 8, 9, 1, 8, 5, 3, 7, 3, 0, 8, 7, 2, 4, 4, 7, 3, 0, 1, 8, 5,\n",
      "        6, 3, 2, 6, 9, 1, 3, 7, 3, 8, 6, 1, 5, 2, 5, 5, 0, 6, 5, 0, 6, 1, 0, 0,\n",
      "        6, 6, 3, 7, 7, 0, 2, 6]), tensor([1, 1, 2, 0, 0, 0, 1, 0, 0, 0, 3, 0, 3, 1, 1, 0, 3, 0, 0, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 2, 1, 2, 0, 0, 0, 0, 3, 0, 3, 0,\n",
      "        0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 3, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 3, 2,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 3, 0, 0, 0, 3, 0, 0, 0, 2, 1, 1, 0, 0, 0,\n",
      "        2, 0, 1, 0, 2, 0, 3, 0, 3, 0, 0, 3, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 3, 3,\n",
      "        0, 1, 2, 0, 0, 2, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 5, 4, 4, 0, 8, 6, 5, 3, 9, 3, 7, 5, 9, 9, 5, 0, 2, 1, 2, 5, 9, 1, 8,\n",
      "        5, 3, 3, 1, 4, 1, 6, 0, 7, 3, 4, 4, 1, 3, 6, 5, 4, 3, 9, 4, 1, 8, 2, 3,\n",
      "        5, 7, 2, 1, 7, 8, 3, 8, 5, 0, 8, 2, 4, 5, 7, 4, 7, 6, 4, 4, 1, 9, 4, 4,\n",
      "        4, 5, 1, 7, 4, 7, 9, 1, 7, 5, 7, 1, 3, 7, 6, 4, 8, 3, 8, 8, 9, 3, 2, 7,\n",
      "        6, 8, 9, 3, 6, 9, 9, 6, 3, 3, 9, 1, 7, 7, 2, 2, 6, 3, 8, 3, 6, 9, 5, 1,\n",
      "        8, 1, 2, 7, 5, 0, 2, 5]), tensor([1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 3, 0, 3, 3, 3, 0, 0, 0, 0,\n",
      "        0, 0, 3, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 3, 0, 1, 0, 1, 1, 2, 0, 3, 2, 0,\n",
      "        0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 3, 0, 0, 3, 2, 0, 0,\n",
      "        0, 3, 0, 0, 0, 0, 3, 0, 0, 1, 0, 1, 1, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 2, 0, 0, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([9, 5, 9, 7, 9, 8, 6, 7, 5, 5, 0, 0, 4, 6, 9, 8, 5, 0, 7, 5, 9, 9, 7, 5,\n",
      "        1, 2, 8, 9, 4, 1, 2, 6, 5, 7, 2, 4, 0, 7, 0, 0, 6, 3, 9, 3, 9, 7, 2, 1,\n",
      "        1, 5, 3, 9, 3, 8, 7, 8, 6, 9, 4, 0, 5, 7, 7, 6, 6, 6, 3, 9, 1, 7, 6, 1,\n",
      "        6, 5, 9, 5, 4, 0, 2, 8, 8, 9, 9, 9, 8, 6, 6, 4, 4, 6, 0, 3, 5, 5, 4, 3,\n",
      "        6, 8, 3, 4, 6, 9, 0, 1, 9, 8, 3, 6, 5, 5, 5, 5, 4, 4, 6, 4, 9, 2, 1, 8,\n",
      "        8, 1, 7, 3, 9, 4, 5, 5]), tensor([0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 3, 0, 1, 0, 0, 0, 1, 3,\n",
      "        0, 2, 0, 1, 1, 2, 3, 0, 2, 1, 0, 3, 0, 0, 0, 0, 1, 0, 0, 3, 1, 0, 0, 2,\n",
      "        2, 0, 2, 0, 3, 1, 0, 2, 0, 2, 0, 3, 3, 1, 0, 0, 0, 0, 3, 2, 1, 0, 0, 0,\n",
      "        3, 3, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 3, 0, 0, 1,\n",
      "        0, 3, 0, 3, 0, 0, 0, 0, 2, 0, 1, 0, 3, 2, 3, 2, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 3, 0, 0, 0, 3, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([4, 1, 0, 8, 4, 3, 0, 3, 3, 4, 8, 0, 6, 4, 8, 6, 6, 2, 3, 7, 1, 6, 9, 3,\n",
      "        4, 5, 1, 7, 1, 6, 0, 1, 6, 5, 4, 5, 8, 6, 2, 3, 4, 5, 8, 7, 2, 6, 7, 9,\n",
      "        9, 7, 7, 0, 4, 5, 8, 6, 6, 8, 0, 9, 4, 9, 6, 6, 3, 9, 6, 1, 7, 8, 2, 9,\n",
      "        4, 6, 1, 1, 2, 3, 9, 2, 7, 1, 5, 6, 4, 5, 9, 3, 5, 3, 3, 7, 9, 1, 1, 3,\n",
      "        1, 5, 5, 5, 3, 7, 2, 6, 5, 4, 0, 8, 3, 5, 0, 4, 3, 2, 5, 8, 9, 2, 8, 8,\n",
      "        7, 8, 0, 9, 7, 9, 7, 4]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1,\n",
      "        3, 0, 2, 1, 0, 2, 0, 0, 0, 2, 0, 3, 0, 0, 2, 0, 0, 3, 0, 0, 2, 3, 0, 0,\n",
      "        2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 2, 0, 0, 2, 0, 0, 3, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 3, 1, 3, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 2, 1, 0, 3, 2, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3,\n",
      "        3, 0, 0, 2, 0, 0, 0, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([4, 6, 9, 3, 7, 0, 2, 5, 0, 4, 7, 3, 2, 1, 2, 9, 8, 8, 3, 6, 2, 6, 4, 5,\n",
      "        1, 9, 8, 3, 0, 6, 2, 2, 3, 8, 0, 1, 0, 7, 6, 8, 5, 7, 5, 3, 1, 4, 5, 9,\n",
      "        2, 6, 4, 1, 3, 9, 2, 5, 7, 3, 9, 1, 8, 7, 9, 0, 4, 9, 2, 2, 2, 0, 3, 8,\n",
      "        9, 7, 8, 7, 6, 9, 5, 8, 0, 0, 7, 3, 6, 0, 7, 9, 4, 6, 8, 6, 7, 6, 8, 9,\n",
      "        5, 9, 9, 6, 0, 3, 5, 9, 8, 4, 2, 3, 9, 2, 2, 5, 8, 5, 9, 0, 5, 9, 3, 2,\n",
      "        0, 4, 4, 3, 8, 6, 7, 6]), tensor([0, 0, 2, 0, 0, 3, 1, 0, 0, 0, 1, 2, 3, 0, 0, 2, 0, 2, 3, 0, 0, 0, 0, 0,\n",
      "        2, 0, 0, 1, 2, 0, 0, 3, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 1, 1,\n",
      "        0, 0, 3, 0, 3, 3, 0, 0, 1, 0, 1, 3, 0, 1, 0, 0, 0, 3, 2, 0, 0, 0, 3, 3,\n",
      "        0, 0, 3, 0, 0, 0, 0, 1, 1, 1, 0, 0, 2, 0, 2, 0, 2, 3, 0, 1, 0, 0, 0, 2,\n",
      "        1, 2, 0, 0, 0, 1, 0, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([9, 5, 1, 3, 8, 5, 2, 1, 3, 5, 0, 4, 7, 7, 6, 1, 5, 4, 2, 5, 8, 6, 9, 1,\n",
      "        7, 3, 4, 2, 8, 3, 2, 1, 5, 9, 6, 9, 1, 2, 1, 8, 2, 2, 4, 7, 7, 6, 2, 8,\n",
      "        2, 9, 7, 2, 0, 9, 6, 8, 6, 7, 8, 8, 1, 2, 0, 5, 6, 9, 2, 7, 9, 0, 9, 1,\n",
      "        6, 6, 1, 1, 9, 1, 7, 2, 9, 9, 4, 1, 5, 2, 0, 4, 9, 4, 6, 6, 3, 8, 5, 7,\n",
      "        2, 4, 4, 5, 4, 0, 0, 5, 0, 5, 9, 6, 2, 5, 7, 5, 8, 6, 0, 0, 6, 1, 3, 1,\n",
      "        9, 4, 9, 0, 7, 6, 1, 3]), tensor([0, 2, 1, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 3, 0, 0, 0,\n",
      "        2, 0, 1, 0, 2, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 1, 3, 0, 0, 3, 3, 0, 1, 0,\n",
      "        0, 0, 0, 0, 2, 0, 1, 0, 3, 0, 0, 1, 2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1,\n",
      "        2, 2, 0, 1, 1, 0, 3, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 2, 0,\n",
      "        0, 0, 3, 1, 0, 3, 0, 0, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0,\n",
      "        0, 2, 1, 1, 0, 0, 3, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 1, 1, 3, 5, 0, 4, 0, 0, 3, 4, 3, 2, 3, 2, 8, 3, 7, 9, 2, 5, 8, 4, 6,\n",
      "        6, 8, 7, 2, 2, 7, 9, 3, 8, 4, 9, 3, 5, 3, 5, 1, 9, 9, 9, 2, 4, 5, 9, 0,\n",
      "        4, 6, 7, 7, 5, 6, 2, 4, 7, 8, 4, 2, 3, 8, 8, 8, 0, 6, 8, 2, 6, 5, 6, 6,\n",
      "        4, 3, 2, 3, 5, 2, 3, 9, 6, 7, 1, 1, 9, 1, 8, 0, 7, 0, 0, 5, 1, 0, 5, 6,\n",
      "        9, 9, 3, 2, 0, 8, 3, 4, 6, 1, 6, 5, 3, 9, 4, 5, 9, 6, 5, 1, 1, 1, 6, 3,\n",
      "        5, 9, 1, 9, 1, 6, 8, 2]), tensor([3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 3, 3, 1, 0, 3, 1, 0, 1, 0, 0, 3, 3, 0,\n",
      "        0, 0, 1, 0, 0, 1, 3, 0, 0, 1, 1, 0, 0, 0, 0, 2, 3, 1, 0, 2, 2, 3, 2, 0,\n",
      "        0, 2, 0, 0, 0, 0, 2, 3, 0, 2, 0, 0, 0, 1, 3, 0, 0, 0, 2, 2, 0, 2, 1, 2,\n",
      "        0, 2, 0, 2, 3, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 3, 0, 3, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 3, 2, 2, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 2, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([4, 5, 5, 9, 5, 1, 7, 6, 8, 4, 7, 6, 2, 2, 9, 5, 4, 4, 1, 5, 2, 9, 4, 8,\n",
      "        1, 1, 4, 1, 7, 3, 9, 8, 1, 4, 7, 8, 1, 4, 9, 1, 2, 5, 2, 4, 0, 9, 8, 8,\n",
      "        6, 6, 6, 3, 5, 5, 0, 5, 2, 6, 8, 9, 6, 2, 2, 2, 9, 1, 0, 6, 3, 2, 3, 7,\n",
      "        5, 5, 6, 3, 3, 8, 2, 1, 5, 2, 6, 4, 0, 7, 4, 3, 2, 3, 5, 5, 1, 2, 6, 2,\n",
      "        3, 8, 3, 4, 5, 8, 8, 2, 5, 1, 5, 3, 7, 4, 9, 2, 1, 4, 1, 9, 6, 1, 1, 0,\n",
      "        3, 1, 5, 0, 2, 1, 7, 5]), tensor([0, 1, 0, 0, 1, 2, 1, 0, 3, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 3,\n",
      "        1, 0, 0, 1, 0, 0, 1, 2, 1, 1, 0, 2, 0, 0, 3, 0, 0, 0, 2, 0, 3, 3, 0, 2,\n",
      "        0, 0, 0, 0, 1, 0, 0, 2, 0, 3, 2, 0, 0, 3, 0, 1, 2, 2, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 3, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 1, 0,\n",
      "        0, 1, 3, 0, 1, 1, 1, 0, 2, 0, 0, 0, 2, 0, 0, 3, 0, 0, 2, 2, 1, 0, 0, 0,\n",
      "        0, 0, 2, 3, 3, 2, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([4, 6, 7, 6, 7, 0, 2, 4, 8, 2, 3, 1, 5, 3, 1, 0, 1, 4, 8, 2, 4, 6, 4, 7,\n",
      "        4, 8, 7, 4, 7, 3, 5, 0, 5, 3, 6, 1, 6, 2, 9, 4, 4, 3, 7, 3, 6, 1, 3, 7,\n",
      "        9, 7, 6, 4, 9, 8, 5, 8, 3, 3, 7, 3, 0, 4, 9, 2, 3, 0, 0, 6, 2, 3, 7, 1,\n",
      "        4, 4, 6, 6, 2, 7, 6, 0, 2, 4, 9, 2, 7, 6, 3, 4, 2, 0, 3, 4, 9, 7, 3, 2,\n",
      "        1, 7, 3, 3, 2, 4, 3, 1, 3, 4, 4, 7, 7, 2, 9, 6, 7, 3, 9, 6, 7, 2, 5, 6,\n",
      "        8, 6, 2, 8, 0, 9, 4, 2]), tensor([3, 1, 3, 1, 0, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 2, 3, 3, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 3, 2, 0, 0, 0,\n",
      "        0, 0, 3, 3, 1, 0, 0, 3, 3, 0, 0, 0, 0, 2, 1, 3, 0, 0, 2, 0, 0, 0, 0, 0,\n",
      "        0, 2, 0, 0, 1, 0, 2, 2, 2, 2, 2, 3, 0, 3, 3, 0, 0, 0, 1, 2, 0, 0, 3, 2,\n",
      "        0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 3, 0, 0, 0, 1, 2, 0, 2, 0, 0, 0,\n",
      "        1, 0, 3, 1, 0, 3, 0, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 6, 9, 7, 0, 5, 9, 9, 5, 3, 6, 1, 8, 2, 0, 0, 1, 7, 4, 4, 7, 1, 3, 7,\n",
      "        6, 3, 2, 2, 9, 3, 7, 0, 4, 6, 4, 0, 3, 2, 0, 3, 7, 5, 5, 8, 8, 9, 0, 4,\n",
      "        6, 3, 5, 1, 4, 3, 8, 8, 5, 5, 9, 5, 7, 6, 7, 5, 3, 0, 7, 1, 9, 6, 4, 5,\n",
      "        8, 8, 0, 0, 1, 4, 4, 3, 9, 9, 4, 7, 8, 0, 9, 8, 3, 2, 1, 8, 4, 0, 6, 6,\n",
      "        6, 8, 8, 6, 0, 3, 1, 7, 5, 4, 2, 1, 3, 5, 6, 3, 2, 9, 6, 3, 4, 4, 5, 0,\n",
      "        5, 7, 4, 5, 6, 5, 5, 8]), tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 1, 1, 3, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        2, 0, 3, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 3, 0, 0,\n",
      "        0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 3, 0,\n",
      "        0, 3, 0, 0, 3, 0, 2, 0, 2, 0, 2, 0, 2, 0, 0, 1, 1, 1, 0, 0, 1, 0, 3, 0,\n",
      "        0, 2, 0, 3, 0, 0, 0, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 3, 9, 2, 3, 5, 2, 1, 5, 1, 6, 1, 8, 6, 1, 2, 0, 0, 9, 7, 7, 9, 0, 1,\n",
      "        6, 8, 3, 3, 2, 0, 3, 6, 1, 7, 8, 0, 0, 1, 8, 1, 5, 8, 7, 1, 6, 0, 1, 7,\n",
      "        1, 1, 9, 8, 9, 0, 8, 4, 2, 5, 2, 4, 0, 1, 5, 5, 8, 1, 6, 2, 2, 4, 7, 1,\n",
      "        5, 6, 9, 7, 4, 9, 0, 7, 9, 8, 1, 2, 2, 4, 2, 1, 1, 4, 9, 9, 4, 8, 5, 6,\n",
      "        6, 3, 8, 6, 1, 1, 9, 3, 3, 9, 4, 0, 5, 0, 0, 9, 0, 5, 6, 5, 3, 6, 9, 7,\n",
      "        6, 9, 5, 4, 6, 4, 4, 5]), tensor([2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 3,\n",
      "        3, 0, 1, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 1, 0, 3, 2, 0, 0, 0, 2, 3, 1,\n",
      "        2, 1, 2, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 3,\n",
      "        0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 2, 1,\n",
      "        3, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0,\n",
      "        0, 0, 0, 1, 3, 0, 2, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([6, 0, 6, 7, 8, 6, 5, 7, 8, 2, 5, 3, 2, 4, 5, 4, 1, 0, 0, 2, 7, 2, 1, 4,\n",
      "        8, 6, 7, 0, 1, 9, 1, 4, 1, 4, 0, 2, 3, 0, 8, 7, 2, 0, 3, 5, 3, 1, 1, 4,\n",
      "        7, 5, 0, 1, 9, 1, 1, 5, 7, 4, 8, 5, 6, 0, 8, 1, 6, 4, 1, 8, 4, 7, 7, 5,\n",
      "        2, 9, 3, 7, 9, 3, 6, 7, 8, 8, 5, 3, 8, 5, 6, 5, 5, 5, 3, 8, 3, 6, 0, 5,\n",
      "        8, 4, 2, 6, 9, 4, 0, 8, 7, 7, 4, 5, 3, 8, 5, 5, 5, 9, 9, 8, 9, 3, 7, 9,\n",
      "        0, 4, 2, 1, 5, 0, 2, 7]), tensor([0, 1, 0, 0, 0, 0, 1, 1, 3, 2, 2, 1, 1, 0, 0, 2, 0, 0, 2, 3, 2, 1, 0, 0,\n",
      "        0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 3, 0, 0, 2, 2, 0, 3, 0, 3, 2, 0, 1,\n",
      "        0, 0, 3, 2, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 1, 0, 2, 0,\n",
      "        0, 1, 0, 3, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 0, 3, 0, 1, 2, 0, 2, 3, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 3, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([6, 0, 3, 8, 7, 1, 7, 6, 6, 7, 1, 1, 8, 3, 0, 2, 5, 5, 8, 3, 9, 6, 6, 7,\n",
      "        6, 4, 0, 7, 0, 6, 5, 4, 2, 7, 3, 1, 7, 0, 1, 3, 1, 4, 6, 4, 7, 2, 1, 9,\n",
      "        7, 7, 8, 4, 2, 3, 6, 1, 0, 4, 7, 1, 2, 7, 9, 4, 3, 5, 0, 6, 2, 5, 4, 5,\n",
      "        8, 8, 3, 4, 1, 7, 3, 1, 8, 0, 2, 8, 9, 6, 7, 5, 3, 0, 6, 7, 8, 3, 1, 4,\n",
      "        5, 7, 5, 1, 4, 7, 5, 2, 9, 8, 9, 3, 3, 1, 3, 4, 8, 3, 4, 6, 2, 9, 0, 5,\n",
      "        8, 3, 5, 8, 1, 7, 0, 3]), tensor([0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 2, 0, 1, 3, 3, 3, 0, 2, 0, 0, 0, 3, 0, 2,\n",
      "        0, 2, 3, 0, 0, 0, 1, 0, 0, 1, 3, 0, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0,\n",
      "        0, 0, 3, 0, 0, 1, 2, 3, 1, 3, 3, 3, 2, 2, 0, 0, 3, 1, 3, 2, 0, 0, 1, 0,\n",
      "        2, 0, 0, 2, 0, 0, 0, 1, 3, 0, 2, 0, 2, 0, 2, 3, 3, 0, 0, 0, 3, 0, 1, 0,\n",
      "        0, 3, 1, 0, 0, 0, 3, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([0, 2, 9, 6, 5, 7, 2, 7, 8, 9, 2, 4, 8, 2, 7, 4, 0, 1, 3, 2, 2, 4, 0, 5,\n",
      "        2, 4, 5, 6, 6, 2, 3, 4, 3, 7, 2, 9, 9, 1, 7, 5, 3, 5, 6, 9, 2, 6, 9, 6,\n",
      "        6, 4, 8, 2, 8, 9, 3, 6, 6, 1, 1, 9, 6, 3, 5, 4, 6, 8, 6, 8, 9, 0, 2, 4,\n",
      "        4, 7, 9, 1, 6, 7, 6, 9, 9, 2, 6, 6, 1, 1, 7, 9, 0, 9, 3, 8, 6, 7, 0, 3,\n",
      "        2, 8, 5, 6, 1, 0, 6, 5, 6, 1, 6, 5, 1, 9, 6, 5, 9, 7, 4, 1, 8, 6, 2, 3,\n",
      "        4, 9, 4, 7, 5, 7, 2, 5]), tensor([2, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 3, 0, 0, 0, 1, 2,\n",
      "        0, 0, 3, 0, 0, 1, 0, 1, 0, 0, 2, 3, 1, 0, 0, 0, 2, 3, 0, 0, 0, 3, 3, 0,\n",
      "        3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 2, 1, 2, 0, 0, 1, 0,\n",
      "        0, 0, 3, 0, 3, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 1,\n",
      "        0, 3, 0, 2, 0, 2, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 1,\n",
      "        3, 0, 0, 0, 3, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 1, 2, 1, 0, 5, 9, 8, 4, 7, 6, 5, 8, 2, 8, 3, 6, 1, 4, 5, 0, 3, 3, 4,\n",
      "        2, 4, 0, 2, 7, 0, 9, 6, 1, 9, 3, 4, 1, 1, 0, 6, 2, 4, 0, 1, 2, 8, 9, 0,\n",
      "        6, 1, 4, 0, 2, 8, 9, 0, 7, 2, 2, 1, 6, 3, 7, 4, 7, 1, 8, 0, 2, 8, 4, 9,\n",
      "        3, 0, 9, 6, 2, 0, 9, 6, 4, 5, 8, 2, 4, 8, 1, 2, 7, 3, 8, 4, 5, 2, 3, 0,\n",
      "        1, 2, 6, 9, 2, 5, 3, 5, 9, 8, 3, 0, 8, 3, 5, 8, 5, 8, 9, 3, 2, 6, 4, 3,\n",
      "        3, 2, 8, 9, 5, 6, 8, 6]), tensor([0, 2, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 2, 1, 0, 1, 0, 2, 0, 2, 0, 0, 1, 3,\n",
      "        0, 0, 3, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 3, 1, 2, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "        2, 0, 0, 0, 3, 3, 1, 0, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 6, 2, 3, 8, 1, 8, 9, 7, 8, 3, 1, 8, 6, 4, 6, 2, 9, 1, 8, 4, 9, 7, 3,\n",
      "        9, 6, 7, 5, 7, 6, 2, 7, 2, 5, 3, 6, 4, 3, 3, 5, 4, 3, 0, 8, 6, 8, 1, 3,\n",
      "        9, 3, 6, 8, 5, 9, 2, 0, 1, 4, 1, 2, 3, 9, 2, 4, 5, 3, 8, 4, 2, 4, 2, 0,\n",
      "        1, 7, 8, 2, 2, 3, 2, 8, 7, 2, 9, 8, 2, 4, 3, 1, 5, 1, 0, 6, 2, 0, 6, 6,\n",
      "        1, 8, 0, 1, 3, 5, 3, 7, 2, 8, 3, 2, 8, 0, 3, 8, 7, 9, 0, 0, 7, 3, 7, 4,\n",
      "        3, 3, 2, 2, 1, 8, 0, 6]), tensor([2, 0, 0, 3, 0, 1, 3, 3, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        3, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 3, 2, 0, 0,\n",
      "        0, 0, 0, 3, 1, 0, 0, 0, 2, 3, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 3, 1, 0, 2, 3, 0, 0, 0, 3, 0, 0, 3, 3, 0, 0, 0, 1, 2, 0, 3,\n",
      "        0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
      "        0, 3, 3, 0, 1, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([6, 5, 2, 3, 1, 4, 8, 6, 3, 1, 2, 8, 7, 0, 7, 6, 3, 1, 5, 4, 4, 4, 9, 7,\n",
      "        2, 8, 0, 1, 1, 5, 9, 1, 7, 4, 1, 0, 1, 2, 7, 7, 5, 2, 9, 6, 1, 0, 8, 4,\n",
      "        2, 9, 3, 2, 1, 4, 0, 3, 3, 8, 1, 9, 8, 7, 2, 0, 8, 1, 0, 1, 5, 1, 0, 7,\n",
      "        0, 0, 3, 9, 3, 7, 3, 3, 5, 4, 3, 8, 6, 0, 6, 4, 5, 2, 7, 2, 8, 5, 4, 0,\n",
      "        8, 2, 3, 8, 6, 5, 5, 2, 4, 6, 1, 2, 1, 0, 1, 8, 7, 1, 7, 8, 9, 4, 1, 4,\n",
      "        2, 2, 7, 4, 0, 5, 9, 0]), tensor([1, 0, 3, 3, 0, 0, 0, 3, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2,\n",
      "        0, 0, 0, 3, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 2, 0, 0, 3, 1, 2, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 3,\n",
      "        0, 0, 3, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 2, 3, 0, 3, 0, 3, 3, 3, 3, 0,\n",
      "        0, 0, 2, 0, 0, 0, 1, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 2, 8, 7, 3, 3, 8, 4, 5, 4, 0, 4, 6, 1, 5, 3, 9, 1, 4, 4, 0, 9, 1, 4,\n",
      "        5, 1, 9, 6, 8, 2, 3, 7, 1, 8, 5, 2, 4, 4, 7, 7, 3, 3, 7, 3, 9, 8, 0, 5,\n",
      "        1, 4, 0, 6, 3, 1, 6, 0, 8, 2, 6, 0, 6, 2, 3, 9, 6, 2, 4, 2, 3, 9, 5, 3,\n",
      "        7, 7, 8, 3, 3, 4, 9, 1, 1, 8, 8, 5, 1, 1, 5, 8, 2, 3, 8, 8, 1, 9, 0, 4,\n",
      "        5, 9, 1, 0, 1, 6, 9, 5, 5, 0, 1, 0, 5, 5, 7, 5, 9, 3, 3, 6, 4, 5, 8, 4,\n",
      "        9, 3, 3, 2, 9, 8, 4, 1]), tensor([0, 0, 3, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 1, 3, 1, 1, 0, 1, 0, 0, 3, 0, 0, 0, 0, 3,\n",
      "        0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 3, 2, 3, 0, 3,\n",
      "        0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 3, 1, 0, 0, 0, 0, 3, 1, 1, 0, 0, 0, 0, 0,\n",
      "        3, 0, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 0, 3, 0, 2, 0, 0, 0, 3, 0, 2,\n",
      "        0, 0, 0, 1, 2, 3, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 8, 9, 0, 0, 2, 0, 4, 9, 9, 7, 4, 3, 2, 1, 8, 1, 5, 0, 2, 8, 8, 5, 3,\n",
      "        0, 3, 0, 6, 4, 4, 5, 9, 7, 6, 3, 8, 1, 1, 1, 3, 0, 2, 4, 5, 3, 1, 9, 1,\n",
      "        8, 8, 0, 1, 8, 3, 4, 2, 1, 1, 4, 1, 5, 8, 8, 6, 1, 1, 2, 4, 2, 3, 4, 1,\n",
      "        7, 6, 3, 6, 7, 4, 9, 9, 6, 0, 7, 0, 2, 6, 7, 0, 4, 8, 2, 5, 6, 6, 9, 9,\n",
      "        1, 3, 0, 5, 1, 7, 6, 1, 5, 8, 5, 1, 3, 2, 8, 3, 9, 7, 5, 9, 9, 5, 4, 1,\n",
      "        5, 4, 8, 1, 1, 6, 4, 4]), tensor([0, 0, 1, 0, 0, 0, 0, 3, 2, 0, 0, 0, 2, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0,\n",
      "        0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
      "        0, 1, 0, 0, 3, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0,\n",
      "        2, 1, 0, 0, 2, 2, 0, 0, 2, 0, 3, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 2, 0, 0, 0, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 0, 2, 6, 6, 5, 1, 2, 9, 6, 4, 4, 2, 4, 0, 1, 3, 4, 2, 2, 1, 3, 9, 2,\n",
      "        3, 4, 1, 9, 0, 3, 8, 5, 5, 9, 1, 7, 9, 8, 7, 6, 2, 6, 4, 0, 2, 4, 2, 2,\n",
      "        0, 3, 8, 9, 9, 1, 3, 5, 5, 6, 3, 4, 3, 8, 5, 0, 2, 3, 5, 5, 2, 9, 6, 8,\n",
      "        8, 1, 5, 6, 1, 4, 9, 3, 2, 5, 7, 2, 1, 5, 8, 9, 7, 2, 7, 0, 8, 4, 1, 0,\n",
      "        7, 0, 3, 2, 0, 0, 9, 0, 5, 5, 4, 2, 7, 6, 4, 1, 5, 3, 6, 8, 3, 6, 3, 5,\n",
      "        9, 3, 7, 5, 2, 5, 2, 3]), tensor([0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 3, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 3, 0,\n",
      "        0, 0, 2, 0, 2, 2, 0, 3, 0, 3, 0, 2, 3, 1, 0, 0, 2, 0, 0, 0, 2, 0, 1, 0,\n",
      "        2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 3, 2, 3, 0, 2,\n",
      "        1, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 3, 0, 1, 0, 0, 0,\n",
      "        0, 2, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 3, 2, 0, 3, 3, 0, 0, 0, 1, 2, 1,\n",
      "        3, 1, 0, 0, 0, 0, 1, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([9, 1, 3, 1, 0, 0, 5, 7, 0, 0, 6, 7, 7, 7, 5, 5, 4, 7, 5, 8, 7, 3, 5, 4,\n",
      "        2, 5, 9, 9, 9, 0, 5, 0, 4, 2, 2, 1, 9, 5, 5, 2, 3, 5, 3, 2, 3, 3, 8, 4,\n",
      "        2, 4, 5, 0, 4, 2, 3, 1, 6, 6, 6, 6, 9, 4, 7, 9, 4, 7, 3, 6, 8, 6, 8, 3,\n",
      "        4, 4, 6, 8, 5, 2, 1, 4, 5, 6, 8, 7, 7, 3, 3, 0, 8, 6, 5, 8, 4, 2, 9, 7,\n",
      "        9, 4, 7, 2, 5, 2, 5, 0, 9, 5, 8, 7, 8, 2, 1, 2, 6, 7, 8, 4, 2, 7, 9, 5,\n",
      "        9, 2, 9, 8, 5, 4, 3, 8]), tensor([0, 1, 0, 1, 0, 2, 0, 3, 0, 0, 0, 1, 2, 0, 0, 0, 1, 3, 2, 0, 0, 1, 0, 1,\n",
      "        3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 2, 1, 3, 1, 2, 1, 0, 0, 2, 1, 3, 0, 0, 3, 0, 0, 1, 0, 1, 2,\n",
      "        0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 3, 3, 0, 3,\n",
      "        0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 1, 3, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        3, 2, 0, 0, 1, 0, 0, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 1, 7, 4, 0, 0, 7, 9, 3, 2, 0, 7, 4, 0, 2, 6, 6, 8, 5, 8, 5, 8, 5, 4,\n",
      "        6, 4, 0, 3, 8, 9, 6, 5, 4, 0, 9, 3, 7, 7, 4, 0, 8, 9, 6, 2, 3, 5, 6, 9,\n",
      "        9, 4, 4, 5, 2, 7, 9, 2, 7, 2, 4, 5, 7, 0, 9, 8, 5, 5, 7, 2, 6, 0, 5, 4,\n",
      "        1, 1, 2, 2, 1, 9, 7, 8, 4, 8, 8, 3, 0, 6, 7, 4, 1, 2, 9, 8, 2, 9, 6, 9,\n",
      "        8, 6, 4, 0, 1, 3, 8, 6, 0, 3, 5, 1, 6, 6, 9, 6, 9, 5, 3, 3, 9, 4, 7, 1,\n",
      "        2, 0, 9, 0, 7, 4, 3, 8]), tensor([0, 0, 1, 1, 0, 0, 0, 2, 3, 3, 0, 1, 1, 0, 0, 1, 2, 1, 1, 3, 0, 0, 0, 3,\n",
      "        0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 2,\n",
      "        0, 0, 1, 1, 0, 3, 2, 2, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 0,\n",
      "        0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        3, 0, 1, 3, 0, 1, 0, 0, 0, 0, 3, 0, 2, 0, 1, 0, 2, 3, 0, 0, 2, 3, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 5, 1, 1, 7, 1, 7, 4, 7, 7, 6, 4, 0, 5, 6, 9, 6, 8, 5, 0, 2, 5, 2, 7,\n",
      "        2, 0, 3, 3, 4, 4, 8, 7, 2, 9, 9, 2, 1, 9, 8, 9, 0, 4, 7, 0, 9, 8, 3, 7,\n",
      "        1, 9, 4, 5, 5, 0, 9, 8, 9, 9, 9, 9, 7, 9, 5, 2, 0, 1, 8, 9, 6, 2, 0, 9,\n",
      "        7, 2, 1, 1, 7, 8, 0, 6, 0, 3, 0, 7, 7, 1, 3, 6, 3, 1, 6, 9, 2, 4, 0, 6,\n",
      "        1, 5, 2, 5, 8, 8, 2, 6, 7, 6, 6, 2, 7, 1, 7, 6, 4, 2, 1, 2, 7, 8, 9, 4,\n",
      "        1, 8, 4, 9, 7, 8, 6, 6]), tensor([2, 0, 2, 3, 1, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 3, 2, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 3, 0, 3, 0, 3, 0, 0, 3, 1, 0, 0, 3, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,\n",
      "        3, 0, 1, 0, 1, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 1,\n",
      "        2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 2, 1, 1, 2, 0, 0, 1, 2, 0,\n",
      "        0, 0, 2, 2, 1, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 1, 8, 1, 1, 9, 7, 2, 0, 5, 1, 6, 9, 9, 7, 6, 6, 0, 8, 5, 4, 9, 2, 0,\n",
      "        8, 6, 3, 2, 8, 6, 4, 9, 5, 7, 1, 9, 8, 3, 5, 5, 3, 3, 0, 1, 7, 7, 6, 4,\n",
      "        9, 6, 6, 1, 7, 9, 0, 6, 8, 6, 7, 3, 3, 0, 0, 6, 4, 5, 2, 8, 4, 8, 0, 4,\n",
      "        0, 6, 8, 9, 6, 4, 0, 3, 3, 4, 2, 8, 9, 5, 5, 5, 2, 3, 2, 5, 0, 4, 9, 5,\n",
      "        4, 7, 7, 6, 8, 7, 1, 5, 5, 9, 6, 1, 6, 2, 3, 3, 8, 2, 9, 7, 6, 0, 7, 1,\n",
      "        6, 9, 3, 6, 5, 6, 0, 1]), tensor([0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 2, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 3, 0, 3, 0, 1, 2, 0, 2, 2, 1, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 2,\n",
      "        0, 0, 0, 0, 2, 0, 0, 2, 3, 0, 2, 0, 0, 0, 0, 0, 3, 0, 3, 0, 1, 3, 0, 2,\n",
      "        0, 1, 0, 0, 0, 0, 1, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 6, 1, 7, 3, 1, 5, 0, 1, 3, 3, 9, 2, 3, 8, 0, 6, 3, 7, 2, 4, 6, 5, 3,\n",
      "        1, 8, 4, 6, 0, 3, 0, 6, 0, 1, 7, 4, 2, 2, 9, 4, 1, 1, 9, 2, 0, 2, 1, 3,\n",
      "        1, 4, 1, 4, 7, 3, 8, 6, 6, 3, 3, 3, 8, 1, 7, 8, 2, 8, 9, 4, 4, 3, 9, 4,\n",
      "        5, 0, 4, 0, 0, 0, 1, 2, 9, 1, 5, 3, 2, 3, 4, 3, 6, 7, 2, 9, 4, 2, 5, 8,\n",
      "        4, 3, 9, 4, 8, 1, 2, 4, 8, 0, 8, 3, 2, 1, 9, 9, 0, 7, 7, 3, 7, 2, 9, 4,\n",
      "        4, 3, 1, 3, 4, 7, 4, 2]), tensor([0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 3, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0,\n",
      "        2, 0, 0, 3, 3, 2, 0, 0, 0, 2, 2, 3, 2, 1, 0, 2, 0, 1, 0, 0, 2, 3, 0, 0,\n",
      "        0, 1, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 3, 0, 0, 3, 1, 0,\n",
      "        0, 0, 3, 3, 0, 1, 1, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 6, 1, 4, 8, 9, 3, 3, 7, 5, 3, 1, 8, 0, 3, 7, 3, 7, 0, 6, 0, 2, 3, 6,\n",
      "        4, 0, 6, 1, 5, 8, 6, 0, 7, 3, 5, 6, 3, 7, 8, 2, 0, 8, 2, 9, 0, 6, 5, 6,\n",
      "        7, 0, 1, 2, 8, 1, 7, 6, 0, 7, 1, 6, 9, 7, 2, 7, 9, 0, 8, 4, 6, 6, 9, 5,\n",
      "        0, 0, 2, 9, 7, 2, 3, 8, 5, 0, 6, 5, 9, 1, 9, 2, 3, 8, 8, 1, 9, 0, 5, 2,\n",
      "        7, 6, 3, 0, 2, 4, 9, 8, 8, 6, 2, 5, 9, 9, 7, 7, 7, 7, 0, 0, 3, 3, 2, 2,\n",
      "        9, 2, 0, 5, 0, 3, 0, 6]), tensor([0, 0, 3, 0, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 2, 0, 2,\n",
      "        0, 0, 0, 3, 0, 3, 0, 3, 2, 0, 0, 0, 3, 0, 2, 3, 0, 2, 1, 0, 2, 2, 0, 0,\n",
      "        0, 0, 0, 1, 0, 2, 3, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0,\n",
      "        0, 0, 0, 3, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 2, 0, 3, 0, 2, 0, 0, 3, 2, 2, 3, 0, 3, 0, 0, 0, 0, 0, 2, 0, 2,\n",
      "        3, 0, 3, 0, 0, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 1, 7, 9, 3, 2, 9, 4, 8, 5, 5, 6, 8, 7, 7, 6, 2, 0, 4, 4, 3, 7, 1, 3,\n",
      "        3, 4, 8, 8, 1, 8, 3, 0, 6, 9, 6, 2, 0, 4, 8, 3, 7, 2, 2, 6, 7, 7, 8, 5,\n",
      "        5, 9, 4, 2, 0, 8, 6, 6, 4, 7, 5, 0, 8, 1, 0, 9, 9, 2, 7, 8, 5, 7, 2, 4,\n",
      "        3, 9, 7, 0, 7, 1, 7, 9, 7, 8, 0, 1, 4, 3, 8, 8, 0, 3, 9, 8, 6, 1, 1, 7,\n",
      "        8, 4, 9, 4, 9, 1, 1, 0, 3, 7, 8, 9, 5, 0, 0, 4, 1, 6, 9, 9, 6, 7, 1, 4,\n",
      "        6, 3, 7, 7, 3, 2, 2, 7]), tensor([1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        3, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 2, 0,\n",
      "        0, 0, 3, 3, 3, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 3, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 3, 3, 0, 3, 0,\n",
      "        0, 2, 1, 0, 0, 0, 2, 3, 0, 0, 0, 0, 2, 0, 2, 2, 1, 2, 0, 1, 3, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 3, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([3, 0, 1, 8, 9, 2, 2, 5, 9, 4, 1, 8, 2, 1, 4, 8, 0, 2, 9, 7, 0, 9, 5, 7,\n",
      "        1, 4, 8, 0, 8, 7, 1, 8, 7, 5, 3, 0, 7, 1, 1, 7, 0, 7, 0, 5, 9, 1, 6, 9,\n",
      "        6, 8, 0, 6, 2, 8, 2, 7, 0, 0, 4, 7, 6, 6, 9, 6, 1, 5, 0, 6, 5, 4, 1, 8,\n",
      "        6, 1, 4, 8, 6, 7, 9, 9, 4, 9, 6, 0, 8, 9, 3, 2, 8, 3, 1, 3, 4, 3, 8, 3,\n",
      "        6, 1, 7, 3, 8, 3, 1, 2, 4, 0, 9, 1, 5, 5, 7, 5, 4, 8, 6, 3, 0, 0, 0, 1,\n",
      "        9, 0, 0, 3, 7, 0, 8, 7]), tensor([1, 3, 0, 0, 0, 1, 2, 0, 0, 3, 0, 2, 0, 3, 2, 3, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        2, 0, 1, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 2, 0, 2, 0, 1, 1, 2,\n",
      "        0, 1, 1, 0, 0, 0, 3, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0,\n",
      "        0, 3, 0, 0, 2, 2, 0, 0, 3, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0,\n",
      "        1, 3, 0, 0, 2, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0,\n",
      "        1, 2, 2, 0, 0, 0, 3, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 6, 8, 9, 9, 0, 5, 1, 2, 4, 3, 7, 5, 7, 6, 0, 4, 1, 9, 6, 6, 9, 9, 4,\n",
      "        0, 8, 1, 6, 9, 7, 9, 3, 2, 0, 6, 5, 8, 9, 1, 0, 7, 0, 3, 1, 6, 8, 9, 6,\n",
      "        5, 6, 3, 1, 2, 1, 1, 7, 3, 0, 2, 7, 8, 3, 1, 2, 2, 4, 9, 7, 5, 6, 5, 6,\n",
      "        5, 3, 8, 8, 1, 4, 9, 4, 0, 3, 0, 2, 1, 4, 2, 5, 2, 7, 7, 5, 9, 1, 5, 5,\n",
      "        3, 3, 2, 1, 9, 3, 2, 5, 4, 3, 5, 9, 8, 9, 9, 6, 0, 0, 8, 5, 9, 7, 7, 8,\n",
      "        8, 7, 8, 6, 2, 5, 0, 8]), tensor([0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0,\n",
      "        3, 0, 2, 0, 1, 1, 2, 0, 1, 0, 2, 0, 2, 0, 0, 0, 3, 0, 3, 0, 0, 3, 0, 3,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 2, 0,\n",
      "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3,\n",
      "        0, 2, 0, 0, 1, 2, 0, 0, 0, 2, 0, 0, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 3, 0,\n",
      "        0, 0, 0, 0, 2, 0, 1, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([3, 5, 6, 1, 9, 8, 5, 2, 9, 9, 7, 8, 5, 3, 4, 3, 8, 5, 5, 9, 5, 7, 0, 1,\n",
      "        0, 0, 4, 4, 3, 2, 1, 7, 8, 8, 4, 0, 3, 1, 7, 3, 0, 3, 3, 7, 4, 5, 8, 9,\n",
      "        1, 5, 3, 7, 4, 5, 8, 2, 9, 8, 0, 1, 8, 0, 9, 4, 2, 0, 1, 8, 4, 6, 1, 7,\n",
      "        5, 8, 9, 0, 2, 5, 1, 2, 1, 6, 6, 9, 5, 6, 4, 9, 3, 8, 6, 2, 9, 1, 9, 8,\n",
      "        6, 3, 7, 7, 6, 9, 1, 6, 5, 6, 3, 6, 0, 2, 5, 7, 5, 4, 3, 0, 9, 5, 9, 5,\n",
      "        6, 7, 6, 7, 5, 5, 4, 8]), tensor([0, 1, 0, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 1, 2, 1, 0, 0, 0, 0, 1, 1, 2, 2, 3, 0,\n",
      "        1, 3, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
      "        0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,\n",
      "        2, 3, 1, 3, 2, 2, 1, 0, 1, 0, 1, 1, 0, 2, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 3, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([9, 2, 9, 7, 8, 6, 1, 6, 8, 3, 5, 4, 2, 9, 2, 4, 1, 7, 0, 5, 8, 7, 6, 4,\n",
      "        7, 9, 9, 1, 9, 5, 5, 3, 1, 8, 4, 5, 6, 3, 8, 5, 9, 5, 7, 0, 9, 5, 2, 3,\n",
      "        2, 8, 0, 1, 3, 0, 8, 1, 5, 5, 9, 9, 4, 0, 1, 0, 7, 9, 5, 8, 6, 4, 1, 5,\n",
      "        8, 1, 8, 0, 1, 0, 5, 0, 5, 4, 8, 2, 0, 6, 6, 4, 8, 2, 7, 1, 2, 7, 3, 9,\n",
      "        0, 8, 3, 7, 4, 3, 9, 6, 6, 9, 7, 2, 6, 7, 4, 9, 8, 7, 7, 8, 6, 9, 0, 6,\n",
      "        3, 8, 1, 0, 7, 4, 7, 7]), tensor([0, 0, 2, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 2, 1, 3, 0, 2,\n",
      "        0, 0, 1, 0, 0, 2, 1, 3, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 3, 0, 0, 0,\n",
      "        3, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 3, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 2, 0, 3, 0, 0, 1, 0, 0, 0, 0, 3,\n",
      "        0, 0, 0, 3, 0, 0, 2, 0, 3, 0, 3, 0, 0, 0, 0, 3, 1, 2, 3, 0, 0, 1, 0, 2,\n",
      "        0, 0, 0, 3, 0, 2, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([3, 2, 3, 1, 6, 6, 0, 4, 1, 3, 1, 1, 9, 8, 0, 0, 2, 8, 3, 6, 3, 1, 9, 0,\n",
      "        8, 8, 7, 9, 0, 7, 7, 4, 0, 6, 8, 6, 9, 8, 5, 0, 7, 4, 2, 6, 9, 4, 4, 9,\n",
      "        8, 4, 3, 9, 1, 9, 2, 8, 5, 3, 6, 3, 2, 0, 2, 7, 7, 4, 2, 1, 2, 7, 2, 3,\n",
      "        1, 4, 0, 6, 0, 8, 1, 3, 5, 3, 2, 7, 2, 1, 7, 2, 8, 2, 9, 9, 4, 9, 6, 1,\n",
      "        2, 8, 5, 1, 7, 9, 2, 9, 1, 7, 8, 9, 4, 1, 7, 1, 4, 8, 4, 2, 3, 6, 8, 9,\n",
      "        7, 2, 2, 3, 3, 4, 3, 3]), tensor([0, 3, 0, 0, 0, 0, 2, 0, 0, 3, 2, 3, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 3, 0, 0, 0, 0,\n",
      "        0, 2, 0, 1, 2, 1, 0, 0, 3, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1,\n",
      "        0, 2, 3, 0, 0, 0, 3, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0,\n",
      "        3, 0, 0, 0, 3, 1, 2, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([6, 4, 4, 6, 4, 8, 7, 4, 1, 9, 6, 7, 8, 7, 9, 8, 9, 5, 5, 7, 4, 2, 1, 7,\n",
      "        3, 8, 7, 6, 1, 6, 6, 7, 8, 9, 7, 6, 5, 7, 6, 5, 5, 9, 6, 2, 6, 3, 5, 1,\n",
      "        8, 5, 0, 1, 1, 7, 5, 7, 0, 2, 5, 2, 9, 8, 2, 8, 0, 4, 9, 8, 6, 9, 4, 8,\n",
      "        9, 4, 5, 7, 0, 0, 1, 5, 2, 4, 6, 3, 4, 2, 2, 6, 3, 5, 3, 0, 9, 9, 4, 9,\n",
      "        0, 7, 5, 3, 6, 0, 3, 1, 9, 9, 8, 0, 8, 4, 8, 0, 9, 7, 8, 0, 5, 0, 0, 6,\n",
      "        8, 6, 6, 1, 9, 0, 8, 5]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 3, 0,\n",
      "        2, 0, 0, 0, 3, 3, 0, 3, 0, 2, 0, 0, 0, 0, 1, 3, 3, 0, 0, 0, 0, 3, 1, 3,\n",
      "        0, 2, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 3, 1, 3, 0, 0, 0, 0, 0, 3, 1, 0,\n",
      "        0, 1, 0, 3, 3, 3, 0, 0, 0, 3, 1, 3, 0, 0, 0, 3, 0, 0, 0, 3, 1, 0, 0, 2,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 3, 0, 0, 0, 2, 0, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([6, 6, 4, 5, 6, 4, 9, 5, 3, 4, 5, 6, 8, 3, 3, 6, 9, 8, 8, 5, 4, 9, 8, 0,\n",
      "        8, 9, 5, 8, 2, 2, 4, 7, 1, 0, 1, 1, 0, 7, 6, 4, 9, 5, 9, 2, 1, 0, 8, 6,\n",
      "        1, 3, 6, 8, 6, 4, 3, 3, 9, 6, 1, 3, 8, 7, 8, 1, 9, 3, 0, 8, 8, 7, 3, 6,\n",
      "        5, 8, 1, 2, 4, 2, 3, 2, 6, 1, 8, 7, 9, 3, 4, 9, 2, 2, 0, 8, 1, 6, 3, 1,\n",
      "        1, 2, 3, 0, 9, 8, 4, 8, 8, 4, 1, 2, 4, 5, 6, 2, 4, 9, 7, 9, 9, 1, 0, 4,\n",
      "        4, 1, 4, 3, 0, 0, 0, 5]), tensor([0, 1, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 3, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 3, 2, 2, 2, 2, 0, 3, 1, 3,\n",
      "        0, 0, 0, 0, 1, 3, 3, 3, 2, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 1, 3, 2, 1, 0,\n",
      "        0, 0, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 2, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0,\n",
      "        2, 0, 0, 1, 0, 0, 0, 3, 0, 0, 3, 0, 0, 2, 0, 3, 1, 2, 3, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 3, 1, 0, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([0, 1, 2, 0, 8, 4, 3, 6, 0, 0, 7, 4, 9, 2, 9, 5, 1, 8, 1, 8, 4, 7, 8, 6,\n",
      "        1, 7, 8, 3, 5, 9, 6, 4, 5, 4, 8, 2, 3, 4, 0, 1, 4, 6, 1, 0, 4, 5, 7, 0,\n",
      "        3, 6, 7, 0, 5, 9, 6, 9, 4, 5, 9, 7, 3, 0, 1, 6, 9, 8, 2, 2, 7, 4, 6, 3,\n",
      "        9, 7, 3, 6, 7, 0, 7, 6, 6, 5, 2, 6, 0, 2, 1, 6, 7, 8, 6, 4, 5, 1, 4, 1,\n",
      "        7, 4, 1, 3, 5, 0, 3, 7, 2, 9, 3, 6, 8, 0, 6, 1, 3, 2, 2, 8, 2, 7, 4, 7,\n",
      "        8, 0, 2, 0, 0, 0, 9, 9]), tensor([0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 3, 1, 0, 3, 0, 3,\n",
      "        1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 0, 0, 0, 2, 0, 1, 0, 2, 3, 3, 2, 0, 0, 0, 3, 0, 0, 0, 0, 1,\n",
      "        3, 0, 0, 2, 0, 3, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
      "        0, 1, 0, 2, 3, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 3, 0, 0, 3, 3, 0, 0,\n",
      "        0, 0, 2, 0, 2, 0, 0, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 0, 9, 0, 5, 0, 8, 6, 3, 2, 2, 8, 7, 1, 0, 0, 4, 7, 0, 4, 4, 4, 7, 8,\n",
      "        7, 6, 7, 6, 0, 7, 6, 6, 4, 1, 5, 9, 6, 7, 8, 8, 1, 1, 7, 3, 7, 5, 2, 6,\n",
      "        6, 7, 1, 4, 7, 2, 8, 0, 1, 3, 1, 4, 5, 0, 2, 4, 8, 6, 7, 8, 6, 6, 2, 7,\n",
      "        5, 2, 5, 5, 1, 0, 4, 4, 2, 6, 0, 8, 0, 7, 9, 4, 9, 6, 6, 8, 4, 1, 3, 2,\n",
      "        1, 0, 5, 9, 4, 0, 0, 5, 3, 9, 8, 1, 2, 5, 8, 4, 3, 0, 8, 6, 9, 1, 5, 8,\n",
      "        4, 7, 9, 3, 7, 4, 6, 3]), tensor([3, 0, 0, 0, 1, 3, 2, 0, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 0, 3, 1, 3, 2, 0,\n",
      "        0, 3, 3, 0, 3, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 2, 0, 1, 0, 3, 0, 0, 1, 0, 0, 2, 3, 0, 0, 1, 0, 2,\n",
      "        2, 0, 2, 1, 3, 2, 3, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 3, 0, 2, 2, 2, 3, 1, 0, 1, 0, 2, 0,\n",
      "        2, 0, 0, 0, 0, 0, 3, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 7, 5, 9, 7, 9, 9, 8, 6, 1, 1, 2, 5, 0, 3, 4, 7, 0, 2, 7, 0, 1, 0, 6,\n",
      "        2, 5, 1, 9, 0, 6, 8, 5, 3, 6, 4, 2, 9, 2, 5, 0, 5, 8, 9, 0, 3, 5, 7, 3,\n",
      "        5, 0, 9, 9, 1, 5, 3, 7, 2, 6, 2, 9, 0, 8, 4, 4, 1, 2, 0, 8, 8, 2, 3, 8,\n",
      "        7, 9, 8, 0, 0, 5, 2, 4, 1, 7, 4, 3, 3, 4, 5, 5, 4, 9, 2, 4, 1, 7, 4, 4,\n",
      "        1, 6, 7, 2, 6, 1, 6, 6, 6, 2, 3, 0, 8, 0, 4, 5, 1, 4, 3, 8, 1, 6, 5, 4,\n",
      "        7, 0, 1, 5, 9, 1, 4, 1]), tensor([2, 2, 0, 0, 3, 0, 3, 3, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        3, 2, 0, 0, 0, 0, 0, 0, 3, 0, 2, 2, 0, 0, 3, 0, 0, 0, 3, 0, 0, 1, 0, 0,\n",
      "        3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 3, 0, 1, 1, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 2, 3, 0,\n",
      "        0, 0, 0, 2, 0, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 1, 2, 4, 0, 8, 6, 0, 9, 0, 2, 6, 0, 8, 9, 6, 1, 6, 0, 9, 8, 8, 5, 8,\n",
      "        9, 8, 0, 1, 6, 5, 8, 2, 4, 4, 4, 8, 0, 8, 4, 9, 0, 3, 2, 1, 8, 3, 0, 0,\n",
      "        8, 4, 2, 5, 1, 3, 7, 6, 7, 3, 7, 5, 1, 5, 0, 7, 3, 1, 3, 0, 2, 0, 2, 7,\n",
      "        3, 7, 8, 7, 2, 7, 6, 1, 0, 8, 7, 0, 5, 4, 4, 4, 9, 9, 5, 0, 0, 3, 3, 7,\n",
      "        5, 9, 2, 7, 8, 7, 6, 7, 7, 5, 7, 6, 3, 5, 1, 5, 4, 0, 3, 6, 9, 8, 0, 8,\n",
      "        5, 2, 3, 5, 4, 5, 6, 8]), tensor([2, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 3, 3, 0, 3, 0, 1, 0, 1, 0, 0, 3, 1, 0,\n",
      "        3, 2, 2, 1, 0, 0, 3, 0, 2, 0, 0, 0, 2, 0, 3, 0, 2, 0, 2, 0, 2, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 3, 3,\n",
      "        0, 2, 0, 2, 1, 0, 1, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 2, 3, 3, 1, 0, 2, 1,\n",
      "        0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 3, 0, 0, 1, 2, 0, 0, 0,\n",
      "        2, 2, 0, 0, 1, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 8, 5, 1, 7, 8, 3, 9, 1, 9, 3, 5, 2, 5, 8, 9, 6, 3, 9, 0, 8, 4, 2, 5,\n",
      "        5, 7, 6, 1, 9, 6, 1, 6, 9, 3, 7, 0, 8, 4, 8, 6, 8, 8, 9, 4, 0, 9, 8, 8,\n",
      "        9, 0, 1, 6, 0, 7, 7, 0, 4, 3, 6, 9, 2, 3, 9, 5, 9, 6, 9, 7, 8, 6, 7, 4,\n",
      "        0, 9, 9, 1, 5, 0, 4, 6, 3, 7, 6, 9, 9, 2, 2, 2, 9, 4, 6, 1, 7, 4, 6, 3,\n",
      "        0, 8, 6, 2, 4, 7, 2, 4, 9, 7, 5, 5, 5, 7, 1, 6, 7, 5, 4, 4, 1, 8, 3, 7,\n",
      "        2, 0, 4, 4, 1, 0, 4, 9]), tensor([0, 0, 2, 3, 0, 3, 0, 3, 0, 0, 2, 1, 3, 3, 0, 1, 3, 0, 0, 0, 2, 1, 0, 0,\n",
      "        0, 3, 0, 2, 2, 1, 2, 0, 2, 0, 0, 2, 0, 0, 1, 0, 1, 0, 1, 3, 3, 0, 0, 0,\n",
      "        1, 3, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 3, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0,\n",
      "        0, 2, 2, 2, 3, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 2, 0, 1, 3, 0, 2, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 9, 7, 2, 3, 2, 1, 2, 6, 0, 3, 5, 2, 3, 7, 3, 8, 4, 1, 9, 7, 6, 8, 9,\n",
      "        3, 4, 8, 6, 1, 7, 3, 4, 7, 0, 4, 1, 9, 0, 2, 3, 7, 9, 2, 9, 0, 4, 8, 4,\n",
      "        9, 9, 2, 3, 3, 9, 0, 8, 4, 5, 0, 1, 9, 9, 9, 2, 8, 0, 4, 9, 8, 9, 1, 2,\n",
      "        4, 5, 2, 5, 0, 2, 3, 3, 7, 4, 9, 2, 2, 3, 4, 0, 0, 8, 7, 0, 5, 7, 3, 0,\n",
      "        8, 5, 0, 0, 0, 2, 8, 4, 7, 9, 5, 2, 6, 2, 1, 6, 6, 2, 9, 7, 5, 4, 7, 5,\n",
      "        5, 7, 5, 7, 8, 6, 8, 4]), tensor([0, 1, 3, 0, 0, 2, 0, 0, 1, 2, 0, 0, 3, 0, 0, 3, 1, 0, 3, 2, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 3, 2, 0, 1, 3, 3, 0, 0, 0, 3, 2, 3, 0, 0, 2, 0, 0, 1, 0, 0,\n",
      "        0, 0, 3, 3, 0, 0, 0, 2, 3, 1, 0, 0, 0, 2, 0, 0, 0, 3, 0, 1, 0, 0, 3, 0,\n",
      "        0, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 2, 0, 0, 2, 0, 3,\n",
      "        1, 3, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0,\n",
      "        1, 1, 0, 1, 0, 2, 0, 2])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([0, 3, 8, 9, 5, 4, 8, 8, 3, 2, 6, 6, 1, 4, 4, 2, 9, 5, 0, 8, 1, 0, 7, 9,\n",
      "        3, 5, 9, 8, 7, 1, 9, 1, 2, 5, 6, 2, 3, 5, 5, 5, 4, 2, 4, 9, 2, 5, 0, 2,\n",
      "        7, 8, 7, 0, 0, 2, 9, 3, 3, 6, 2, 9, 5, 8, 3, 7, 9, 8, 3, 4, 3, 4, 4, 6,\n",
      "        6, 5, 5, 2, 3, 0, 7, 3, 8, 4, 0, 0, 8, 8, 9, 4, 9, 1, 1, 2, 3, 7, 7, 8,\n",
      "        1, 2, 5, 1, 6, 9, 0, 7, 9, 9, 2, 7, 8, 0, 3, 2, 6, 2, 5, 2, 9, 5, 3, 3,\n",
      "        5, 5, 3, 1, 8, 9, 0, 3]), tensor([0, 3, 0, 0, 1, 3, 2, 0, 2, 2, 2, 3, 0, 3, 2, 0, 0, 0, 2, 2, 0, 1, 0, 1,\n",
      "        3, 2, 2, 0, 2, 3, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 2, 1, 2, 1, 0, 0, 3, 2, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 3, 3,\n",
      "        0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 1, 3, 3, 2,\n",
      "        0, 0, 0, 2, 3, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 1, 6, 1, 8, 6, 9, 9, 2, 6, 8, 7, 8, 1, 9, 6, 6, 6, 6, 6, 2, 6, 0, 2,\n",
      "        3, 6, 5, 3, 7, 1, 7, 1, 8, 4, 9, 5, 4, 2, 6, 5, 9, 5, 6, 5, 9, 5, 1, 7,\n",
      "        3, 3, 1, 5, 1, 6, 5, 3, 0, 9, 6, 4, 2, 6, 7, 1, 5, 4, 8, 5, 4, 4, 3, 6,\n",
      "        1, 7, 3, 9, 4, 6, 5, 8, 5, 1, 4, 3, 3, 6, 6, 3, 3, 6, 4, 0, 7, 4, 4, 6,\n",
      "        8, 9, 8, 0, 0, 3, 0, 8, 9, 1, 6, 6, 3, 5, 6, 1, 5, 0, 2, 0, 8, 1, 6, 1,\n",
      "        9, 8, 3, 6, 4, 6, 1, 3]), tensor([1, 0, 0, 0, 0, 0, 1, 0, 2, 2, 1, 0, 0, 1, 3, 2, 0, 1, 0, 2, 1, 0, 0, 1,\n",
      "        2, 0, 0, 0, 1, 0, 1, 0, 0, 3, 3, 3, 0, 0, 1, 0, 1, 0, 0, 0, 3, 0, 3, 0,\n",
      "        1, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 3, 0,\n",
      "        3, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 3, 2, 3, 0, 0, 1, 0, 2, 0, 3, 0, 0, 0,\n",
      "        3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 0, 2, 3, 3, 0, 3, 0, 1, 2,\n",
      "        0, 3, 0, 0, 3, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 3, 7, 0, 5, 0, 9, 3, 8, 7, 7, 4, 8, 7, 2, 3, 6, 1, 3, 7, 3, 9, 7, 5,\n",
      "        5, 2, 1, 7, 1, 5, 7, 4, 5, 0, 4, 2, 4, 8, 9, 8, 5, 5, 2, 9, 0, 5, 0, 6,\n",
      "        6, 9, 4, 9, 9, 7, 2, 0, 2, 1, 4, 8, 5, 5, 7, 7, 7, 0, 6, 3, 7, 1, 6, 3,\n",
      "        8, 3, 0, 7, 2, 6, 8, 8, 6, 3, 8, 5, 7, 0, 1, 0, 7, 7, 4, 8, 4, 0, 2, 9,\n",
      "        5, 7, 5, 5, 1, 1, 5, 1, 3, 9, 8, 8, 1, 1, 0, 3, 8, 5, 5, 3, 1, 8, 2, 1,\n",
      "        8, 9, 9, 2, 9, 1, 5, 6]), tensor([0, 0, 0, 3, 2, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 2, 0, 0, 0, 1,\n",
      "        2, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0,\n",
      "        0, 0, 0, 2, 2, 2, 1, 2, 3, 0, 0, 0, 1, 0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 1,\n",
      "        3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        3, 0, 3, 1, 1, 0, 1, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([4, 7, 3, 1, 0, 1, 4, 3, 0, 1, 2, 1, 6, 9, 3, 0, 0, 4, 0, 8, 5, 9, 0, 2,\n",
      "        2, 5, 1, 5, 9, 6, 9, 9, 4, 2, 9, 3, 9, 1, 0, 7, 0, 0, 6, 6, 1, 6, 7, 5,\n",
      "        6, 8, 1, 9, 5, 9, 5, 5, 3, 9, 2, 0, 6, 2, 6, 0, 7, 6, 3, 2, 0, 4, 3, 8,\n",
      "        9, 8, 8, 4, 3, 6, 7, 4, 6, 3, 1, 1, 8, 9, 7, 5, 6, 5, 6, 7, 0, 6, 9, 3,\n",
      "        9, 8, 6, 6, 0, 1, 2, 0, 8, 8, 2, 4, 0, 5, 1, 8, 3, 5, 0, 6, 0, 6, 5, 4,\n",
      "        7, 2, 7, 1, 1, 7, 6, 2]), tensor([0, 2, 2, 3, 0, 0, 3, 0, 0, 1, 0, 2, 0, 3, 2, 2, 0, 2, 0, 1, 0, 0, 2, 0,\n",
      "        0, 3, 0, 0, 1, 3, 2, 1, 0, 0, 0, 2, 2, 0, 1, 2, 0, 0, 2, 0, 1, 2, 0, 1,\n",
      "        0, 0, 0, 3, 3, 3, 1, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 2,\n",
      "        0, 3, 0, 0, 0, 3, 0, 0, 3, 0, 0, 3, 0, 3, 3, 0, 2, 0, 0, 2, 0, 3, 2, 2,\n",
      "        0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 0, 3, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1,\n",
      "        0, 0, 2, 0, 2, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 2, 9, 1, 1, 6, 3, 9, 2, 6, 0, 1, 2, 8, 5, 1, 7, 9, 7, 9, 0, 9, 9, 5,\n",
      "        5, 8, 3, 0, 0, 1, 0, 8, 9, 3, 8, 5, 3, 6, 4, 6, 0, 6, 9, 2, 3, 0, 0, 6,\n",
      "        4, 6, 7, 2, 7, 5, 7, 5, 3, 9, 1, 1, 7, 4, 0, 4, 5, 9, 0, 2, 8, 0, 2, 1,\n",
      "        3, 7, 8, 8, 2, 4, 5, 4, 0, 3, 6, 2, 2, 5, 3, 5, 0, 3, 1, 7, 7, 0, 7, 2,\n",
      "        3, 4, 1, 2, 2, 1, 0, 5, 7, 2, 0, 7, 4, 8, 6, 5, 7, 8, 3, 9, 9, 7, 8, 3,\n",
      "        9, 6, 4, 7, 2, 5, 6, 5]), tensor([3, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 1, 2, 0, 2, 3, 0, 0, 2, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0,\n",
      "        1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 0,\n",
      "        0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0,\n",
      "        0, 0, 2, 1, 1, 3, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "        2, 0, 1, 0, 3, 3, 1, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([6, 8, 4, 1, 2, 3, 7, 3, 1, 9, 8, 3, 8, 4, 1, 8, 3, 0, 8, 7, 4, 2, 2, 9,\n",
      "        8, 1, 8, 3, 9, 5, 3, 7, 5, 2, 0, 0, 0, 1, 9, 2, 9, 3, 1, 4, 2, 9, 7, 3,\n",
      "        0, 5, 3, 0, 8, 8, 1, 1, 2, 1, 6, 7, 3, 6, 3, 7, 7, 6, 5, 6, 8, 5, 6, 7,\n",
      "        6, 5, 0, 9, 0, 0, 1, 0, 8, 8, 7, 6, 7, 1, 0, 4, 9, 2, 3, 2, 4, 1, 7, 2,\n",
      "        3, 2, 9, 8, 2, 7, 7, 3, 3, 4, 6, 1, 2, 1, 0, 3, 5, 1, 4, 1, 0, 6, 8, 3,\n",
      "        1, 9, 7, 7, 3, 9, 6, 0]), tensor([0, 0, 0, 1, 0, 0, 3, 2, 0, 0, 0, 0, 2, 0, 3, 1, 0, 0, 0, 0, 3, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 3, 0, 0, 1, 0, 1, 1, 3, 3, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 0, 3, 3, 3, 1, 3, 1, 0, 2, 1, 1, 0, 1, 0, 0, 2,\n",
      "        2, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0,\n",
      "        3, 3, 0, 1, 0, 0, 1, 2, 0, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 2, 2, 3, 0,\n",
      "        0, 0, 0, 2, 1, 1, 2, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 3, 1, 3, 8, 1, 0, 9, 7, 2, 6, 4, 6, 7, 7, 4, 1, 8, 8, 8, 3, 0, 9, 1,\n",
      "        4, 7, 6, 6, 7, 8, 5, 0, 1, 7, 8, 7, 9, 5, 8, 5, 6, 5, 0, 3, 3, 0, 9, 5,\n",
      "        5, 0, 4, 0, 8, 2, 8, 9, 7, 2, 7, 4, 0, 5, 0, 7, 1, 4, 5, 0, 7, 1, 0, 0,\n",
      "        5, 7, 3, 6, 2, 6, 2, 4, 0, 6, 0, 0, 9, 0, 4, 5, 5, 5, 7, 1, 6, 7, 2, 5,\n",
      "        1, 3, 0, 6, 5, 3, 9, 7, 1, 6, 1, 9, 3, 7, 8, 9, 7, 9, 8, 5, 3, 0, 4, 9,\n",
      "        9, 9, 0, 2, 5, 3, 3, 7]), tensor([0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 2, 3, 0, 0, 0, 0, 2, 1, 0, 0,\n",
      "        0, 0, 2, 0, 1, 2, 0, 1, 3, 0, 0, 0, 0, 3, 0, 2, 0, 1, 2, 0, 0, 1, 1, 3,\n",
      "        0, 0, 1, 3, 0, 0, 0, 0, 0, 3, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 3, 0,\n",
      "        2, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 3, 1, 0, 0, 2, 2, 0, 3, 0, 0, 3,\n",
      "        0, 0, 1, 0, 0, 3, 2, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 9, 0, 2, 2, 6, 4, 5, 9, 9, 4, 5, 0, 1, 0, 1, 5, 8, 5, 6, 2, 3, 3, 1,\n",
      "        9, 3, 8, 8, 6, 3, 6, 6, 7, 7, 0, 6, 6, 8, 1, 2, 6, 9, 5, 9, 1, 6, 2, 8,\n",
      "        3, 4, 6, 3, 4, 0, 1, 5, 0, 5, 6, 5, 3, 2, 7, 9, 4, 7, 2, 0, 5, 5, 4, 3,\n",
      "        6, 5, 8, 1, 5, 2, 8, 0, 8, 8, 9, 3, 4, 3, 4, 8, 8, 7, 7, 3, 0, 3, 8, 1,\n",
      "        3, 6, 5, 3, 5, 8, 1, 6, 0, 2, 7, 5, 7, 8, 7, 6, 9, 7, 9, 0, 2, 0, 7, 5,\n",
      "        4, 8, 6, 0, 1, 3, 5, 1]), tensor([0, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 3, 2, 0,\n",
      "        0, 3, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 1, 0, 3, 0, 3, 0, 3, 0, 1,\n",
      "        0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 3, 0, 1, 1, 0, 1, 0, 2, 0, 1, 3, 0,\n",
      "        0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 2, 3, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 3,\n",
      "        0, 0, 0, 3, 2, 0, 2, 2, 0, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 3, 3, 1, 3, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([1, 1, 8, 1, 7, 8, 7, 7, 1, 0, 7, 4, 7, 5, 5, 5, 7, 0, 0, 8, 9, 4, 5, 2,\n",
      "        3, 1, 1, 3, 8, 5, 9, 1, 9, 9, 7, 9, 0, 0, 7, 5, 6, 8, 8, 6, 1, 7, 3, 4,\n",
      "        9, 1, 9, 5, 4, 7, 2, 9, 4, 0, 5, 4, 8, 9, 2, 5, 9, 3, 2, 7, 4, 4, 9, 8,\n",
      "        3, 4, 7, 4, 3, 5, 3, 8, 1, 4, 1, 0, 0, 5, 5, 0, 4, 2, 8, 8, 9, 4, 7, 2,\n",
      "        3, 0, 0, 9, 6, 0, 5, 2, 7, 6, 6, 6, 6, 8, 4, 4, 0, 3, 4, 5, 2, 3, 7, 8,\n",
      "        4, 5, 1, 0, 7, 7, 2, 9]), tensor([1, 1, 3, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 1,\n",
      "        0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 3, 0, 0, 0, 0, 0, 1, 0, 2,\n",
      "        0, 2, 0, 0, 0, 3, 1, 2, 2, 0, 0, 1, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 2, 2, 0, 0, 0, 0, 2, 2, 0, 3, 0, 0, 3, 3, 0, 0, 0, 0, 1, 0,\n",
      "        2, 1, 2, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 1, 3, 1, 0, 0, 0, 0, 3, 0, 1,\n",
      "        0, 3, 2, 2, 0, 0, 2, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([5, 6, 2, 1, 5, 5, 2, 0, 6, 8, 0, 7, 3, 2, 0, 8, 0, 9, 6, 3, 7, 7, 8, 8,\n",
      "        7, 1, 0, 0, 8, 6, 0, 4, 1, 2, 5, 1, 1, 0, 2, 0, 6, 8, 4, 8, 1, 2, 1, 8,\n",
      "        2, 2, 0, 4, 3, 0, 6, 4, 1, 2, 6, 5, 3, 2, 1, 8, 6, 5, 1, 9, 8, 8, 5, 1,\n",
      "        4, 4, 0, 9, 3, 7, 4, 6, 2, 8, 0, 7, 3, 1, 5, 7, 3, 0, 1, 6, 2, 2, 7, 3,\n",
      "        5, 7, 9, 5, 4, 3, 4, 5, 0, 1, 0, 1, 6, 1, 3, 0, 5, 2, 6, 7, 0, 6, 2, 6,\n",
      "        3, 4, 5, 2, 0, 3, 4, 3]), tensor([0, 3, 0, 3, 2, 1, 3, 2, 0, 0, 0, 0, 2, 3, 0, 0, 3, 0, 0, 0, 3, 3, 2, 0,\n",
      "        0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 3, 0, 2,\n",
      "        3, 2, 1, 0, 1, 0, 1, 3, 0, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 2, 2,\n",
      "        0, 2, 3, 0, 2, 0, 0, 0, 3, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 2, 0, 0, 0, 3, 0, 0, 2, 1, 3, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
      "        0, 0, 0, 0, 1, 3, 0, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 8, 8, 3, 5, 6, 8, 4, 3, 5, 6, 5, 7, 6, 5, 4, 5, 2, 8, 4, 8, 8, 8, 9,\n",
      "        0, 1, 1, 6, 3, 7, 8, 3, 0, 5, 0, 4, 5, 9, 8, 5, 4, 1, 8, 2, 3, 5, 7, 3,\n",
      "        2, 2, 5, 8, 3, 4, 9, 8, 9, 8, 3, 6, 7, 6, 8, 2, 8, 6, 8, 3, 8, 3, 3, 8,\n",
      "        1, 3, 7, 3, 1, 6, 2, 7, 0, 7, 2, 6, 5, 8, 4, 0, 4, 0, 2, 3, 6, 5, 8, 3,\n",
      "        0, 5, 6, 1, 1, 8, 8, 2, 2, 5, 4, 9, 9, 6, 4, 9, 1, 2, 9, 0, 4, 6, 1, 0,\n",
      "        0, 5, 1, 7, 5, 6, 0, 4]), tensor([0, 3, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, 2, 0, 3, 3, 1, 0, 0, 3, 0,\n",
      "        1, 0, 0, 0, 0, 3, 1, 0, 0, 2, 0, 3, 2, 2, 0, 3, 0, 3, 0, 0, 0, 0, 3, 1,\n",
      "        0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 3, 2, 0, 2, 0, 3, 3, 0, 0, 0, 0,\n",
      "        2, 0, 0, 0, 1, 3, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
      "        2, 3, 0, 2, 0, 1, 0, 1])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([7, 3, 5, 1, 5, 2, 0, 4, 1, 8, 5, 3, 3, 5, 1, 8, 7, 4, 5, 4, 9, 4, 7, 3,\n",
      "        0, 5, 7, 1, 0, 5, 3, 0, 7, 3, 5, 2, 7, 8, 7, 6, 8, 0, 9, 8, 3, 8, 7, 4,\n",
      "        3, 3, 9, 8, 1, 7, 1, 4, 2, 9, 0, 2, 8, 0, 4, 0, 5, 9, 1, 1, 6, 8, 3, 6,\n",
      "        4, 7, 6, 1, 8, 3, 8, 1, 9, 4, 1, 9, 8, 8, 2, 7, 7, 4, 3, 0, 0, 4, 3, 8,\n",
      "        5, 5, 1, 0, 3, 4, 3, 2, 8, 9, 3, 7, 5, 0, 2, 8, 6, 4, 6, 4, 5, 6, 1, 0,\n",
      "        9, 4, 3, 0, 5, 6, 7, 1]), tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 3,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0,\n",
      "        0, 2, 0, 0, 1, 3, 0, 1, 2, 1, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 3, 3, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 3, 2, 0, 0, 3, 1, 3, 3, 0, 1,\n",
      "        2, 0, 3, 1, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 2,\n",
      "        0, 3, 3, 0, 0, 3, 0, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([6, 7, 1, 4, 8, 9, 6, 0, 5, 6, 2, 1, 2, 7, 4, 6, 7, 4, 5, 5, 3, 8, 2, 3,\n",
      "        6, 3, 2, 4, 2, 6, 9, 5, 8, 3, 7, 4, 2, 7, 9, 6, 4, 7, 9, 8, 9, 2, 2, 5,\n",
      "        4, 9, 4, 4, 1, 7, 3, 7, 5, 6, 5, 1, 6, 9, 1, 3, 6, 6, 2, 2, 3, 0, 6, 0,\n",
      "        8, 6, 3, 4, 7, 4, 4, 0, 2, 8, 7, 5, 6, 0, 6, 3, 7, 7, 8, 8, 1, 0, 8, 2,\n",
      "        7, 0, 4, 5, 6, 6, 7, 3, 0, 0, 8, 9, 3, 5, 5, 3, 3, 3, 0, 4, 6, 2, 6, 2,\n",
      "        1, 9, 9, 2, 2, 1, 2, 2]), tensor([1, 3, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 1, 0, 2, 0,\n",
      "        0, 2, 0, 0, 0, 0, 0, 0, 3, 2, 0, 3, 2, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 3,\n",
      "        1, 3, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 3, 0, 3, 0, 3, 0, 0, 2, 0, 1, 0,\n",
      "        2, 0, 2, 1, 0, 0, 2, 3, 0, 3, 0, 2, 0, 1, 2, 3, 0, 2, 0, 3, 2, 0, 1, 1,\n",
      "        0, 0, 2, 0, 0, 1, 1, 0, 0, 3, 2, 0, 0, 2, 0, 0, 3, 0, 0, 1, 3, 0, 2, 2,\n",
      "        0, 3, 0, 3, 1, 0, 3, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 4, 9, 2, 2, 3, 9, 3, 2, 5, 3, 2, 7, 5, 4, 4, 2, 5, 8, 3, 1, 0, 4, 1,\n",
      "        9, 6, 7, 3, 8, 1, 4, 8, 6, 4, 0, 7, 8, 5, 6, 5, 9, 0, 6, 5, 2, 6, 9, 2,\n",
      "        1, 8, 5, 6, 7, 0, 9, 0, 6, 8, 1, 6, 9, 0, 2, 3, 4, 9, 0, 9, 4, 1, 1, 4,\n",
      "        6, 1, 4, 3, 7, 0, 3, 2, 7, 4, 8, 1, 2, 7, 4, 9, 4, 8, 8, 4, 2, 1, 2, 2,\n",
      "        4, 9, 5, 9, 9, 2, 7, 0, 8, 3, 5, 2, 6, 3, 3, 5, 1, 2, 2, 0, 2, 5, 3, 8,\n",
      "        5, 7, 9, 1, 5, 4, 0, 4]), tensor([0, 0, 0, 1, 0, 2, 0, 2, 3, 0, 2, 3, 1, 0, 0, 0, 3, 2, 2, 0, 1, 0, 2, 1,\n",
      "        0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 1, 0, 0, 3,\n",
      "        3, 0, 2, 0, 3, 1, 0, 1, 0, 3, 0, 2, 3, 3, 1, 1, 0, 3, 0, 1, 0, 0, 0, 0,\n",
      "        0, 2, 2, 1, 3, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 2, 0, 3,\n",
      "        0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 3, 0, 2, 1, 0, 3, 2, 3, 0, 0, 1, 0, 0, 0,\n",
      "        3, 0, 0, 3, 0, 2, 2, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([2, 4, 6, 2, 9, 5, 6, 3, 8, 0, 9, 4, 1, 5, 5, 2, 3, 3, 7, 0, 1, 3, 0, 5,\n",
      "        4, 0, 2, 6, 1, 8, 1, 3, 8, 2, 9, 1, 3, 4, 3, 7, 4, 3, 6, 7, 2, 6, 8, 6,\n",
      "        8, 0, 7, 7, 5, 8, 1, 6, 0, 4, 0, 5, 8, 6, 9, 9, 9, 2, 2, 2, 6, 9, 4, 0,\n",
      "        5, 4, 7, 7, 2, 1, 8, 1, 1, 4, 4, 9, 0, 5, 9, 7, 9, 1, 4, 7, 9, 9, 4, 4,\n",
      "        7, 6, 2, 8, 6, 1, 9, 5, 5, 4, 0, 0, 0, 9, 0, 7, 7, 4, 0, 7, 7, 4, 0, 1,\n",
      "        0, 5, 6, 0, 4, 4, 6, 9]), tensor([0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 3, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 2, 0, 0, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 2, 0, 3, 0, 3, 0, 0, 0, 0, 0,\n",
      "        0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 1, 0, 0, 1, 3, 2, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 3, 0, 3, 0, 2, 3, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 3,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 9, 6, 8, 1, 8, 0, 1, 4, 7, 5, 9, 1, 6, 0, 5, 9, 7, 0, 5, 7, 1, 9, 0,\n",
      "        9, 4, 4, 8, 5, 1, 1, 3, 8, 6, 4, 6, 6, 5, 1, 3, 9, 3, 7, 1, 2, 0, 8, 8,\n",
      "        1, 7, 1, 6, 9, 2, 9, 5, 2, 2, 5, 1, 8, 7, 5, 4, 6, 4, 7, 8, 5, 1, 8, 4,\n",
      "        3, 2, 4, 9, 9, 5, 4, 2, 2, 0, 0, 6, 1, 7, 3, 0, 1, 4, 2, 5, 2, 6, 2, 9,\n",
      "        4, 5, 6, 6, 7, 9, 3, 2, 6, 1, 8, 3, 3, 7, 4, 8, 1, 2, 7, 6, 8, 4, 0, 2,\n",
      "        0, 8, 2, 4, 9, 4, 0, 0]), tensor([3, 2, 0, 0, 0, 1, 3, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 3, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 3, 3, 3, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 2, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([8, 8, 6, 0, 3, 1, 9, 6, 5, 2, 7, 4, 0, 3, 6, 2, 5, 6, 8, 8, 9, 3, 5, 3,\n",
      "        8, 7, 6, 8, 2, 4, 0, 4, 0, 0, 6, 8, 4, 8, 3, 2, 5, 8, 3, 3, 9, 2, 0, 2,\n",
      "        6, 2, 8, 2, 0, 7, 6, 9, 0, 5, 1, 9, 5, 0, 7, 3, 1, 2, 7, 8, 5, 4, 0, 1,\n",
      "        3, 1, 7, 6, 7, 4, 4, 8, 4, 0, 6, 4, 6, 7, 7, 3, 1, 2, 3, 0, 5, 1, 6, 3,\n",
      "        7, 2, 9, 6, 4, 8, 0, 2, 3, 1, 2, 6, 4, 7, 0, 5, 8, 0, 2, 5, 6, 9, 7, 6,\n",
      "        2, 4, 2, 7, 1, 8, 2, 1]), tensor([0, 3, 3, 1, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 0, 2, 1,\n",
      "        0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 2, 0, 1, 1, 0, 2, 3, 0, 3, 3, 0, 0, 0, 2,\n",
      "        3, 1, 1, 1, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 2, 3, 0, 3, 0, 3, 0, 0, 2, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 2, 2, 0, 0, 0, 3])]\n",
      "torch.Size([128, 3, 96, 96])\n",
      "[tensor([3, 6, 2, 3, 4, 6, 4, 8, 1, 6, 6, 2, 4, 7, 9, 3, 8, 7, 8, 7, 5, 3, 9, 0,\n",
      "        0, 6, 0, 8, 2, 5, 7, 9, 3, 4, 0, 0, 8, 5, 3, 1, 3, 6, 3, 7, 0, 6, 5, 9,\n",
      "        4, 1, 0, 6, 6, 1, 9, 9, 9, 4, 7, 1, 3, 1, 0, 7, 0, 9, 9, 4, 0, 3, 4, 5,\n",
      "        9, 6, 0, 1, 7, 7, 0, 2, 2, 6, 1, 2, 4, 8, 3, 3, 7, 3, 4, 9, 2, 1, 7, 7,\n",
      "        5, 0, 8, 1, 3, 6, 0, 0, 4, 3, 7, 6, 4, 5, 9, 7, 1, 5, 0, 0, 8, 3, 4, 5,\n",
      "        2, 6, 3, 3, 7, 7, 3, 0]), tensor([0, 3, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 1, 1, 0, 2, 0, 3, 0, 2, 0, 0, 3, 0,\n",
      "        0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 2, 3, 1, 0, 1, 3,\n",
      "        0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 3, 1, 0, 0, 3, 1, 3, 0, 1, 0, 1, 0,\n",
      "        2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1, 0, 3, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2, 0,\n",
      "        2, 0, 2, 2, 3, 0, 0, 1])]\n",
      "torch.Size([64, 3, 96, 96])\n",
      "[tensor([7, 2, 7, 7, 9, 5, 6, 0, 7, 8, 2, 8, 3, 6, 0, 3, 9, 9, 2, 5, 7, 3, 2, 6,\n",
      "        0, 3, 9, 6, 4, 1, 1, 8, 5, 5, 4, 0, 5, 7, 1, 5, 2, 4, 8, 9, 7, 3, 6, 0,\n",
      "        3, 3, 5, 9, 1, 9, 3, 9, 1, 0, 9, 9, 4, 9, 2, 7]), tensor([0, 3, 0, 1, 0, 0, 3, 0, 0, 0, 0, 2, 0, 3, 3, 2, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 3, 0, 3, 0, 0, 2, 1, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 0, 0, 0, 3,\n",
      "        2, 0, 2, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_all_loader:\n",
    "    # Unpack the batch into images and labels\n",
    "    images, labels = batch\n",
    "\n",
    "    # Do something with the batch\n",
    "    print(images.shape)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f8c6ec2",
   "metadata": {
    "id": "7f8c6ec2"
   },
   "outputs": [],
   "source": [
    "# Define the loss functions\n",
    "criterion1 = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# Initialize the model and define optimizer\n",
    "model1 = JointResNet().to(device)\n",
    "optimizer1 = optim.SGD(model1.parameters(), lr=0.1, momentum=0.9, weight_decay=2e-4)\n",
    "scheduler = StepLR(optimizer1, step_size=30, gamma=0.1)\n",
    "# optimizer1 = optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "GdTPljpArftz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdTPljpArftz",
    "outputId": "6b946b3a-90ae-4fb8-e402-b4302502a2da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Conv2d: 1-1                            [-1, 64, 96, 96]          1,792\n",
      "BatchNorm2d: 1-2                       [-1, 64, 96, 96]          128\n",
      "ResBlock: 1-3                          [-1, 64, 96, 96]          --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-1              [-1, 64, 96, 96]          4,160\n",
      "|    |    Sequential: 3-2              [-1, 64, 96, 96]          74,112\n",
      "|    |    Sequential: 3-3              [-1, 64, 96, 96]          4,160\n",
      "|    |    Sequential: 3-4              [-1, 64, 96, 96]          74,112\n",
      "ResBlock: 1-4                          [-1, 128, 48, 48]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-5              [-1, 128, 48, 48]         8,320\n",
      "|    |    Sequential: 3-6              [-1, 128, 48, 48]         221,952\n",
      "|    |    Sequential: 3-7              [-1, 128, 48, 48]         16,512\n",
      "|    |    Sequential: 3-8              [-1, 128, 48, 48]         295,680\n",
      "ResBlock: 1-5                          [-1, 256, 24, 24]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-9              [-1, 256, 24, 24]         33,024\n",
      "|    |    Sequential: 3-10             [-1, 256, 24, 24]         886,272\n",
      "|    |    Sequential: 3-11             [-1, 256, 24, 24]         65,792\n",
      "|    |    Sequential: 3-12             [-1, 256, 24, 24]         1,181,184\n",
      "ResBlock: 1-6                          [-1, 512, 12, 12]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-13             [-1, 512, 12, 12]         131,584\n",
      "|    |    Sequential: 3-14             [-1, 512, 12, 12]         3,542,016\n",
      "|    |    Sequential: 3-15             [-1, 512, 12, 12]         262,656\n",
      "|    |    Sequential: 3-16             [-1, 512, 12, 12]         4,721,664\n",
      "AdaptiveAvgPool2d: 1-7                 [-1, 512, 1, 1]           --\n",
      "Linear: 1-8                            [-1, 10]                  5,130\n",
      "ResBlock: 1-9                          [-1, 512, 12, 12]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-17             [-1, 512, 12, 12]         131,584\n",
      "|    |    Sequential: 3-18             [-1, 512, 12, 12]         3,542,016\n",
      "|    |    Sequential: 3-19             [-1, 512, 12, 12]         262,656\n",
      "|    |    Sequential: 3-20             [-1, 512, 12, 12]         4,721,664\n",
      "AdaptiveAvgPool2d: 1-10                [-1, 512, 1, 1]           --\n",
      "Linear: 1-11                           [-1, 4]                   2,052\n",
      "==========================================================================================\n",
      "Total params: 20,190,222\n",
      "Trainable params: 20,190,222\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 6.47\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 99.00\n",
      "Params size (MB): 77.02\n",
      "Estimated Total Size (MB): 176.13\n",
      "==========================================================================================\n",
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Conv2d: 1-1                            [-1, 64, 96, 96]          1,792\n",
      "BatchNorm2d: 1-2                       [-1, 64, 96, 96]          128\n",
      "ResBlock: 1-3                          [-1, 64, 96, 96]          --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-1              [-1, 64, 96, 96]          4,160\n",
      "|    |    Sequential: 3-2              [-1, 64, 96, 96]          74,112\n",
      "|    |    Sequential: 3-3              [-1, 64, 96, 96]          4,160\n",
      "|    |    Sequential: 3-4              [-1, 64, 96, 96]          74,112\n",
      "ResBlock: 1-4                          [-1, 128, 48, 48]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-5              [-1, 128, 48, 48]         8,320\n",
      "|    |    Sequential: 3-6              [-1, 128, 48, 48]         221,952\n",
      "|    |    Sequential: 3-7              [-1, 128, 48, 48]         16,512\n",
      "|    |    Sequential: 3-8              [-1, 128, 48, 48]         295,680\n",
      "ResBlock: 1-5                          [-1, 256, 24, 24]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-9              [-1, 256, 24, 24]         33,024\n",
      "|    |    Sequential: 3-10             [-1, 256, 24, 24]         886,272\n",
      "|    |    Sequential: 3-11             [-1, 256, 24, 24]         65,792\n",
      "|    |    Sequential: 3-12             [-1, 256, 24, 24]         1,181,184\n",
      "ResBlock: 1-6                          [-1, 512, 12, 12]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-13             [-1, 512, 12, 12]         131,584\n",
      "|    |    Sequential: 3-14             [-1, 512, 12, 12]         3,542,016\n",
      "|    |    Sequential: 3-15             [-1, 512, 12, 12]         262,656\n",
      "|    |    Sequential: 3-16             [-1, 512, 12, 12]         4,721,664\n",
      "AdaptiveAvgPool2d: 1-7                 [-1, 512, 1, 1]           --\n",
      "Linear: 1-8                            [-1, 10]                  5,130\n",
      "ResBlock: 1-9                          [-1, 512, 12, 12]         --\n",
      "|    ModuleList: 2                     []                        --\n",
      "|    |    Sequential: 3-17             [-1, 512, 12, 12]         131,584\n",
      "|    |    Sequential: 3-18             [-1, 512, 12, 12]         3,542,016\n",
      "|    |    Sequential: 3-19             [-1, 512, 12, 12]         262,656\n",
      "|    |    Sequential: 3-20             [-1, 512, 12, 12]         4,721,664\n",
      "AdaptiveAvgPool2d: 1-10                [-1, 512, 1, 1]           --\n",
      "Linear: 1-11                           [-1, 4]                   2,052\n",
      "==========================================================================================\n",
      "Total params: 20,190,222\n",
      "Trainable params: 20,190,222\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 6.47\n",
      "==========================================================================================\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 99.00\n",
      "Params size (MB): 77.02\n",
      "Estimated Total Size (MB): 176.13\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model1, (3, 96, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ea78aa1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ea78aa1",
    "outputId": "ed21d065-d9d1-4fd4-957b-e46084e30bd3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/65], Step [10/63], Loss: 3.2488\n",
      "Epoch [1/65], Step [20/63], Loss: 2.8534\n",
      "Epoch [1/65], Step [30/63], Loss: 2.9884\n",
      "Epoch [1/65], Step [40/63], Loss: 2.6029\n",
      "Epoch [1/65], Step [50/63], Loss: 2.7730\n",
      "Epoch [1/65], Step [60/63], Loss: 2.7685\n",
      "Epoch [2/65], Step [10/63], Loss: 2.8888\n",
      "Epoch [2/65], Step [20/63], Loss: 2.8066\n",
      "Epoch [2/65], Step [30/63], Loss: 2.4443\n",
      "Epoch [2/65], Step [40/63], Loss: 2.4681\n",
      "Epoch [2/65], Step [50/63], Loss: 2.5496\n",
      "Epoch [2/65], Step [60/63], Loss: 2.5723\n",
      "Epoch [3/65], Step [10/63], Loss: 2.3716\n",
      "Epoch [3/65], Step [20/63], Loss: 2.7217\n",
      "Epoch [3/65], Step [30/63], Loss: 2.3974\n",
      "Epoch [3/65], Step [40/63], Loss: 2.5361\n",
      "Epoch [3/65], Step [50/63], Loss: 2.3913\n",
      "Epoch [3/65], Step [60/63], Loss: 2.5582\n",
      "Epoch [4/65], Step [10/63], Loss: 2.3986\n",
      "Epoch [4/65], Step [20/63], Loss: 2.4113\n",
      "Epoch [4/65], Step [30/63], Loss: 2.4782\n",
      "Epoch [4/65], Step [40/63], Loss: 2.3987\n",
      "Epoch [4/65], Step [50/63], Loss: 2.2749\n",
      "Epoch [4/65], Step [60/63], Loss: 2.3357\n",
      "Epoch [5/65], Step [10/63], Loss: 2.3033\n",
      "Epoch [5/65], Step [20/63], Loss: 2.2703\n",
      "Epoch [5/65], Step [30/63], Loss: 2.1782\n",
      "Epoch [5/65], Step [40/63], Loss: 2.0934\n",
      "Epoch [5/65], Step [50/63], Loss: 2.0053\n",
      "Epoch [5/65], Step [60/63], Loss: 2.6202\n",
      "Training:\n",
      "classification acc: 0.385, rotation pred acc: 0.692\n",
      "Validation:\n",
      "classification acc: 0.377, rotation pred acc: 0.668\n",
      "Epoch [6/65], Step [10/63], Loss: 2.2244\n",
      "Epoch [6/65], Step [20/63], Loss: 2.1276\n",
      "Epoch [6/65], Step [30/63], Loss: 2.2374\n",
      "Epoch [6/65], Step [40/63], Loss: 2.1809\n",
      "Epoch [6/65], Step [50/63], Loss: 2.1372\n",
      "Epoch [6/65], Step [60/63], Loss: 2.1455\n",
      "Epoch [7/65], Step [10/63], Loss: 1.9867\n",
      "Epoch [7/65], Step [20/63], Loss: 2.3907\n",
      "Epoch [7/65], Step [30/63], Loss: 2.1217\n",
      "Epoch [7/65], Step [40/63], Loss: 2.0177\n",
      "Epoch [7/65], Step [50/63], Loss: 2.0588\n",
      "Epoch [7/65], Step [60/63], Loss: 2.1027\n",
      "Epoch [8/65], Step [10/63], Loss: 1.8445\n",
      "Epoch [8/65], Step [20/63], Loss: 2.1207\n",
      "Epoch [8/65], Step [30/63], Loss: 2.0320\n",
      "Epoch [8/65], Step [40/63], Loss: 2.0385\n",
      "Epoch [8/65], Step [50/63], Loss: 1.9507\n",
      "Epoch [8/65], Step [60/63], Loss: 1.8758\n",
      "Epoch [9/65], Step [10/63], Loss: 1.7755\n",
      "Epoch [9/65], Step [20/63], Loss: 1.6660\n",
      "Epoch [9/65], Step [30/63], Loss: 2.0073\n",
      "Epoch [9/65], Step [40/63], Loss: 1.8294\n",
      "Epoch [9/65], Step [50/63], Loss: 1.8919\n",
      "Epoch [9/65], Step [60/63], Loss: 1.8831\n",
      "Epoch [10/65], Step [10/63], Loss: 1.6348\n",
      "Epoch [10/65], Step [20/63], Loss: 1.6327\n",
      "Epoch [10/65], Step [30/63], Loss: 1.9620\n",
      "Epoch [10/65], Step [40/63], Loss: 1.8141\n",
      "Epoch [10/65], Step [50/63], Loss: 1.6822\n",
      "Epoch [10/65], Step [60/63], Loss: 1.5387\n",
      "Training:\n",
      "classification acc: 0.487, rotation pred acc: 0.664\n",
      "Validation:\n",
      "classification acc: 0.405, rotation pred acc: 0.626\n",
      "Epoch [11/65], Step [10/63], Loss: 1.7250\n",
      "Epoch [11/65], Step [20/63], Loss: 1.2872\n",
      "Epoch [11/65], Step [30/63], Loss: 1.6004\n",
      "Epoch [11/65], Step [40/63], Loss: 1.4654\n",
      "Epoch [11/65], Step [50/63], Loss: 1.5551\n",
      "Epoch [11/65], Step [60/63], Loss: 1.5545\n",
      "Epoch [12/65], Step [10/63], Loss: 1.5769\n",
      "Epoch [12/65], Step [20/63], Loss: 1.3584\n",
      "Epoch [12/65], Step [30/63], Loss: 1.5995\n",
      "Epoch [12/65], Step [40/63], Loss: 1.4206\n",
      "Epoch [12/65], Step [50/63], Loss: 1.4945\n",
      "Epoch [12/65], Step [60/63], Loss: 1.5834\n",
      "Epoch [13/65], Step [10/63], Loss: 0.9871\n",
      "Epoch [13/65], Step [20/63], Loss: 1.4344\n",
      "Epoch [13/65], Step [30/63], Loss: 1.4855\n",
      "Epoch [13/65], Step [40/63], Loss: 1.3098\n",
      "Epoch [13/65], Step [50/63], Loss: 1.3101\n",
      "Epoch [13/65], Step [60/63], Loss: 1.4076\n",
      "Epoch [14/65], Step [10/63], Loss: 1.0251\n",
      "Epoch [14/65], Step [20/63], Loss: 0.8934\n",
      "Epoch [14/65], Step [30/63], Loss: 1.1700\n",
      "Epoch [14/65], Step [40/63], Loss: 1.2427\n",
      "Epoch [14/65], Step [50/63], Loss: 1.3222\n",
      "Epoch [14/65], Step [60/63], Loss: 0.9365\n",
      "Epoch [15/65], Step [10/63], Loss: 0.9080\n",
      "Epoch [15/65], Step [20/63], Loss: 1.0024\n",
      "Epoch [15/65], Step [30/63], Loss: 1.1066\n",
      "Epoch [15/65], Step [40/63], Loss: 0.8989\n",
      "Epoch [15/65], Step [50/63], Loss: 1.2993\n",
      "Epoch [15/65], Step [60/63], Loss: 1.1653\n",
      "Training:\n",
      "classification acc: 0.589, rotation pred acc: 0.859\n",
      "Validation:\n",
      "classification acc: 0.390, rotation pred acc: 0.739\n",
      "Epoch [16/65], Step [10/63], Loss: 0.8638\n",
      "Epoch [16/65], Step [20/63], Loss: 0.8770\n",
      "Epoch [16/65], Step [30/63], Loss: 0.7306\n",
      "Epoch [16/65], Step [40/63], Loss: 0.7555\n",
      "Epoch [16/65], Step [50/63], Loss: 0.7493\n",
      "Epoch [16/65], Step [60/63], Loss: 1.0753\n",
      "Epoch [17/65], Step [10/63], Loss: 0.7040\n",
      "Epoch [17/65], Step [20/63], Loss: 0.6536\n",
      "Epoch [17/65], Step [30/63], Loss: 0.6097\n",
      "Epoch [17/65], Step [40/63], Loss: 0.7383\n",
      "Epoch [17/65], Step [50/63], Loss: 0.6961\n",
      "Epoch [17/65], Step [60/63], Loss: 0.7731\n",
      "Epoch [18/65], Step [10/63], Loss: 0.5367\n",
      "Epoch [18/65], Step [20/63], Loss: 0.4609\n",
      "Epoch [18/65], Step [30/63], Loss: 0.3576\n",
      "Epoch [18/65], Step [40/63], Loss: 0.6489\n",
      "Epoch [18/65], Step [50/63], Loss: 0.5232\n",
      "Epoch [18/65], Step [60/63], Loss: 0.4745\n",
      "Epoch [19/65], Step [10/63], Loss: 0.3617\n",
      "Epoch [19/65], Step [20/63], Loss: 0.4510\n",
      "Epoch [19/65], Step [30/63], Loss: 0.5918\n",
      "Epoch [19/65], Step [40/63], Loss: 0.3992\n",
      "Epoch [19/65], Step [50/63], Loss: 0.5637\n",
      "Epoch [19/65], Step [60/63], Loss: 0.6212\n",
      "Epoch [20/65], Step [10/63], Loss: 0.2448\n",
      "Epoch [20/65], Step [20/63], Loss: 0.2352\n",
      "Epoch [20/65], Step [30/63], Loss: 0.3422\n",
      "Epoch [20/65], Step [40/63], Loss: 0.2400\n",
      "Epoch [20/65], Step [50/63], Loss: 0.3881\n",
      "Epoch [20/65], Step [60/63], Loss: 0.3227\n",
      "Training:\n",
      "classification acc: 0.885, rotation pred acc: 0.881\n",
      "Validation:\n",
      "classification acc: 0.501, rotation pred acc: 0.719\n",
      "Epoch [21/65], Step [10/63], Loss: 0.3054\n",
      "Epoch [21/65], Step [20/63], Loss: 0.2561\n",
      "Epoch [21/65], Step [30/63], Loss: 0.2574\n",
      "Epoch [21/65], Step [40/63], Loss: 0.2477\n",
      "Epoch [21/65], Step [50/63], Loss: 0.2197\n",
      "Epoch [21/65], Step [60/63], Loss: 0.3322\n",
      "Epoch [22/65], Step [10/63], Loss: 0.2334\n",
      "Epoch [22/65], Step [20/63], Loss: 0.1525\n",
      "Epoch [22/65], Step [30/63], Loss: 0.0953\n",
      "Epoch [22/65], Step [40/63], Loss: 0.2202\n",
      "Epoch [22/65], Step [50/63], Loss: 0.1524\n",
      "Epoch [22/65], Step [60/63], Loss: 0.1267\n",
      "Epoch [23/65], Step [10/63], Loss: 0.1341\n",
      "Epoch [23/65], Step [20/63], Loss: 0.1671\n",
      "Epoch [23/65], Step [30/63], Loss: 0.1350\n",
      "Epoch [23/65], Step [40/63], Loss: 0.1513\n",
      "Epoch [23/65], Step [50/63], Loss: 0.0951\n",
      "Epoch [23/65], Step [60/63], Loss: 0.1715\n",
      "Epoch [24/65], Step [10/63], Loss: 0.1751\n",
      "Epoch [24/65], Step [20/63], Loss: 0.1341\n",
      "Epoch [24/65], Step [30/63], Loss: 0.1993\n",
      "Epoch [24/65], Step [40/63], Loss: 0.1029\n",
      "Epoch [24/65], Step [50/63], Loss: 0.0939\n",
      "Epoch [24/65], Step [60/63], Loss: 0.2283\n",
      "Epoch [25/65], Step [10/63], Loss: 0.2350\n",
      "Epoch [25/65], Step [20/63], Loss: 0.1887\n",
      "Epoch [25/65], Step [30/63], Loss: 0.1719\n",
      "Epoch [25/65], Step [40/63], Loss: 0.1481\n",
      "Epoch [25/65], Step [50/63], Loss: 0.1663\n",
      "Epoch [25/65], Step [60/63], Loss: 0.0774\n",
      "Training:\n",
      "classification acc: 0.924, rotation pred acc: 0.932\n",
      "Validation:\n",
      "classification acc: 0.489, rotation pred acc: 0.744\n",
      "Epoch [26/65], Step [10/63], Loss: 0.1668\n",
      "Epoch [26/65], Step [20/63], Loss: 0.1871\n",
      "Epoch [26/65], Step [30/63], Loss: 0.1968\n",
      "Epoch [26/65], Step [40/63], Loss: 0.1278\n",
      "Epoch [26/65], Step [50/63], Loss: 0.0361\n",
      "Epoch [26/65], Step [60/63], Loss: 0.0889\n",
      "Epoch [27/65], Step [10/63], Loss: 0.1185\n",
      "Epoch [27/65], Step [20/63], Loss: 0.0622\n",
      "Epoch [27/65], Step [30/63], Loss: 0.0256\n",
      "Epoch [27/65], Step [40/63], Loss: 0.0862\n",
      "Epoch [27/65], Step [50/63], Loss: 0.1151\n",
      "Epoch [27/65], Step [60/63], Loss: 0.1152\n",
      "Epoch [28/65], Step [10/63], Loss: 0.0330\n",
      "Epoch [28/65], Step [20/63], Loss: 0.0430\n",
      "Epoch [28/65], Step [30/63], Loss: 0.0596\n",
      "Epoch [28/65], Step [40/63], Loss: 0.1193\n",
      "Epoch [28/65], Step [50/63], Loss: 0.0660\n",
      "Epoch [28/65], Step [60/63], Loss: 0.1105\n",
      "Epoch [29/65], Step [10/63], Loss: 0.0590\n",
      "Epoch [29/65], Step [20/63], Loss: 0.0325\n",
      "Epoch [29/65], Step [30/63], Loss: 0.0341\n",
      "Epoch [29/65], Step [40/63], Loss: 0.0237\n",
      "Epoch [29/65], Step [50/63], Loss: 0.0316\n",
      "Epoch [29/65], Step [60/63], Loss: 0.0218\n",
      "Epoch [30/65], Step [10/63], Loss: 0.0122\n",
      "Epoch [30/65], Step [20/63], Loss: 0.0093\n",
      "Epoch [30/65], Step [30/63], Loss: 0.0097\n",
      "Epoch [30/65], Step [40/63], Loss: 0.0080\n",
      "Epoch [30/65], Step [50/63], Loss: 0.0157\n",
      "Epoch [30/65], Step [60/63], Loss: 0.0101\n",
      "Training:\n",
      "classification acc: 0.998, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.547, rotation pred acc: 0.751\n",
      "Epoch [31/65], Step [10/63], Loss: 0.0058\n",
      "Epoch [31/65], Step [20/63], Loss: 0.0032\n",
      "Epoch [31/65], Step [30/63], Loss: 0.0049\n",
      "Epoch [31/65], Step [40/63], Loss: 0.0058\n",
      "Epoch [31/65], Step [50/63], Loss: 0.0024\n",
      "Epoch [31/65], Step [60/63], Loss: 0.0033\n",
      "Epoch [32/65], Step [10/63], Loss: 0.0009\n",
      "Epoch [32/65], Step [20/63], Loss: 0.0015\n",
      "Epoch [32/65], Step [30/63], Loss: 0.0012\n",
      "Epoch [32/65], Step [40/63], Loss: 0.0009\n",
      "Epoch [32/65], Step [50/63], Loss: 0.0014\n",
      "Epoch [32/65], Step [60/63], Loss: 0.0018\n",
      "Epoch [33/65], Step [10/63], Loss: 0.0008\n",
      "Epoch [33/65], Step [20/63], Loss: 0.0008\n",
      "Epoch [33/65], Step [30/63], Loss: 0.0012\n",
      "Epoch [33/65], Step [40/63], Loss: 0.0008\n",
      "Epoch [33/65], Step [50/63], Loss: 0.0006\n",
      "Epoch [33/65], Step [60/63], Loss: 0.0007\n",
      "Epoch [34/65], Step [10/63], Loss: 0.0008\n",
      "Epoch [34/65], Step [20/63], Loss: 0.0006\n",
      "Epoch [34/65], Step [30/63], Loss: 0.0007\n",
      "Epoch [34/65], Step [40/63], Loss: 0.0007\n",
      "Epoch [34/65], Step [50/63], Loss: 0.0008\n",
      "Epoch [34/65], Step [60/63], Loss: 0.0008\n",
      "Epoch [35/65], Step [10/63], Loss: 0.0010\n",
      "Epoch [35/65], Step [20/63], Loss: 0.0009\n",
      "Epoch [35/65], Step [30/63], Loss: 0.0007\n",
      "Epoch [35/65], Step [40/63], Loss: 0.0017\n",
      "Epoch [35/65], Step [50/63], Loss: 0.0008\n",
      "Epoch [35/65], Step [60/63], Loss: 0.0013\n",
      "Training:\n",
      "classification acc: 1.000, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.575, rotation pred acc: 0.765\n",
      "Epoch [36/65], Step [10/63], Loss: 0.0006\n",
      "Epoch [36/65], Step [20/63], Loss: 0.0009\n",
      "Epoch [36/65], Step [30/63], Loss: 0.0012\n",
      "Epoch [36/65], Step [40/63], Loss: 0.0009\n",
      "Epoch [36/65], Step [50/63], Loss: 0.0009\n",
      "Epoch [36/65], Step [60/63], Loss: 0.0008\n",
      "Epoch [37/65], Step [10/63], Loss: 0.0009\n",
      "Epoch [37/65], Step [20/63], Loss: 0.0007\n",
      "Epoch [37/65], Step [30/63], Loss: 0.0008\n",
      "Epoch [37/65], Step [40/63], Loss: 0.0012\n",
      "Epoch [37/65], Step [50/63], Loss: 0.0008\n",
      "Epoch [37/65], Step [60/63], Loss: 0.0007\n",
      "Epoch [38/65], Step [10/63], Loss: 0.0008\n",
      "Epoch [38/65], Step [20/63], Loss: 0.0009\n",
      "Epoch [38/65], Step [30/63], Loss: 0.0008\n",
      "Epoch [38/65], Step [40/63], Loss: 0.0008\n",
      "Epoch [38/65], Step [50/63], Loss: 0.0007\n",
      "Epoch [38/65], Step [60/63], Loss: 0.0006\n",
      "Epoch [39/65], Step [10/63], Loss: 0.0015\n",
      "Epoch [39/65], Step [20/63], Loss: 0.0012\n",
      "Epoch [39/65], Step [30/63], Loss: 0.0030\n",
      "Epoch [39/65], Step [40/63], Loss: 0.0012\n",
      "Epoch [39/65], Step [50/63], Loss: 0.0011\n",
      "Epoch [39/65], Step [60/63], Loss: 0.0011\n",
      "Epoch [40/65], Step [10/63], Loss: 0.0008\n",
      "Epoch [40/65], Step [20/63], Loss: 0.0010\n",
      "Epoch [40/65], Step [30/63], Loss: 0.0014\n",
      "Epoch [40/65], Step [40/63], Loss: 0.0012\n",
      "Epoch [40/65], Step [50/63], Loss: 0.0011\n",
      "Epoch [40/65], Step [60/63], Loss: 0.0011\n",
      "Training:\n",
      "classification acc: 1.000, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.581, rotation pred acc: 0.760\n",
      "Epoch [41/65], Step [10/63], Loss: 0.0015\n",
      "Epoch [41/65], Step [20/63], Loss: 0.0011\n",
      "Epoch [41/65], Step [30/63], Loss: 0.0010\n",
      "Epoch [41/65], Step [40/63], Loss: 0.0026\n",
      "Epoch [41/65], Step [50/63], Loss: 0.0013\n",
      "Epoch [41/65], Step [60/63], Loss: 0.0014\n",
      "Epoch [42/65], Step [10/63], Loss: 0.0009\n",
      "Epoch [42/65], Step [20/63], Loss: 0.0012\n",
      "Epoch [42/65], Step [30/63], Loss: 0.0013\n",
      "Epoch [42/65], Step [40/63], Loss: 0.0014\n",
      "Epoch [42/65], Step [50/63], Loss: 0.0010\n",
      "Epoch [42/65], Step [60/63], Loss: 0.0015\n",
      "Epoch [43/65], Step [10/63], Loss: 0.0011\n",
      "Epoch [43/65], Step [20/63], Loss: 0.0008\n",
      "Epoch [43/65], Step [30/63], Loss: 0.0008\n",
      "Epoch [43/65], Step [40/63], Loss: 0.0015\n",
      "Epoch [43/65], Step [50/63], Loss: 0.0008\n",
      "Epoch [43/65], Step [60/63], Loss: 0.0011\n",
      "Epoch [44/65], Step [10/63], Loss: 0.0010\n",
      "Epoch [44/65], Step [20/63], Loss: 0.0009\n",
      "Epoch [44/65], Step [30/63], Loss: 0.0010\n",
      "Epoch [44/65], Step [40/63], Loss: 0.0009\n",
      "Epoch [44/65], Step [50/63], Loss: 0.0014\n",
      "Epoch [44/65], Step [60/63], Loss: 0.0010\n",
      "Epoch [45/65], Step [10/63], Loss: 0.0017\n",
      "Epoch [45/65], Step [20/63], Loss: 0.0008\n",
      "Epoch [45/65], Step [30/63], Loss: 0.0012\n",
      "Epoch [45/65], Step [40/63], Loss: 0.0010\n",
      "Epoch [45/65], Step [50/63], Loss: 0.0013\n",
      "Epoch [45/65], Step [60/63], Loss: 0.0013\n",
      "Training:\n",
      "classification acc: 1.000, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.582, rotation pred acc: 0.763\n",
      "Epoch [46/65], Step [10/63], Loss: 0.0012\n",
      "Epoch [46/65], Step [20/63], Loss: 0.0010\n",
      "Epoch [46/65], Step [30/63], Loss: 0.0017\n",
      "Epoch [46/65], Step [40/63], Loss: 0.0011\n",
      "Epoch [46/65], Step [50/63], Loss: 0.0009\n",
      "Epoch [46/65], Step [60/63], Loss: 0.0019\n",
      "Epoch [47/65], Step [10/63], Loss: 0.0009\n",
      "Epoch [47/65], Step [20/63], Loss: 0.0011\n",
      "Epoch [47/65], Step [30/63], Loss: 0.0011\n",
      "Epoch [47/65], Step [40/63], Loss: 0.0010\n",
      "Epoch [47/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [47/65], Step [60/63], Loss: 0.0015\n",
      "Epoch [48/65], Step [10/63], Loss: 0.0010\n",
      "Epoch [48/65], Step [20/63], Loss: 0.0010\n",
      "Epoch [48/65], Step [30/63], Loss: 0.0015\n",
      "Epoch [48/65], Step [40/63], Loss: 0.0011\n",
      "Epoch [48/65], Step [50/63], Loss: 0.0014\n",
      "Epoch [48/65], Step [60/63], Loss: 0.0012\n",
      "Epoch [49/65], Step [10/63], Loss: 0.0016\n",
      "Epoch [49/65], Step [20/63], Loss: 0.0012\n",
      "Epoch [49/65], Step [30/63], Loss: 0.0015\n",
      "Epoch [49/65], Step [40/63], Loss: 0.0013\n",
      "Epoch [49/65], Step [50/63], Loss: 0.0011\n",
      "Epoch [49/65], Step [60/63], Loss: 0.0015\n",
      "Epoch [50/65], Step [10/63], Loss: 0.0008\n",
      "Epoch [50/65], Step [20/63], Loss: 0.0015\n",
      "Epoch [50/65], Step [30/63], Loss: 0.0010\n",
      "Epoch [50/65], Step [40/63], Loss: 0.0010\n",
      "Epoch [50/65], Step [50/63], Loss: 0.0015\n",
      "Epoch [50/65], Step [60/63], Loss: 0.0012\n",
      "Training:\n",
      "classification acc: 1.000, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.581, rotation pred acc: 0.763\n",
      "Epoch [51/65], Step [10/63], Loss: 0.0011\n",
      "Epoch [51/65], Step [20/63], Loss: 0.0011\n",
      "Epoch [51/65], Step [30/63], Loss: 0.0011\n",
      "Epoch [51/65], Step [40/63], Loss: 0.0014\n",
      "Epoch [51/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [51/65], Step [60/63], Loss: 0.0009\n",
      "Epoch [52/65], Step [10/63], Loss: 0.0010\n",
      "Epoch [52/65], Step [20/63], Loss: 0.0015\n",
      "Epoch [52/65], Step [30/63], Loss: 0.0023\n",
      "Epoch [52/65], Step [40/63], Loss: 0.0011\n",
      "Epoch [52/65], Step [50/63], Loss: 0.0014\n",
      "Epoch [52/65], Step [60/63], Loss: 0.0012\n",
      "Epoch [53/65], Step [10/63], Loss: 0.0012\n",
      "Epoch [53/65], Step [20/63], Loss: 0.0015\n",
      "Epoch [53/65], Step [30/63], Loss: 0.0011\n",
      "Epoch [53/65], Step [40/63], Loss: 0.0010\n",
      "Epoch [53/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [53/65], Step [60/63], Loss: 0.0013\n",
      "Epoch [54/65], Step [10/63], Loss: 0.0010\n",
      "Epoch [54/65], Step [20/63], Loss: 0.0015\n",
      "Epoch [54/65], Step [30/63], Loss: 0.0013\n",
      "Epoch [54/65], Step [40/63], Loss: 0.0011\n",
      "Epoch [54/65], Step [50/63], Loss: 0.0015\n",
      "Epoch [54/65], Step [60/63], Loss: 0.0013\n",
      "Epoch [55/65], Step [10/63], Loss: 0.0011\n",
      "Epoch [55/65], Step [20/63], Loss: 0.0014\n",
      "Epoch [55/65], Step [30/63], Loss: 0.0018\n",
      "Epoch [55/65], Step [40/63], Loss: 0.0013\n",
      "Epoch [55/65], Step [50/63], Loss: 0.0015\n",
      "Epoch [55/65], Step [60/63], Loss: 0.0019\n",
      "Training:\n",
      "classification acc: 1.000, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.585, rotation pred acc: 0.761\n",
      "Epoch [56/65], Step [10/63], Loss: 0.0012\n",
      "Epoch [56/65], Step [20/63], Loss: 0.0015\n",
      "Epoch [56/65], Step [30/63], Loss: 0.0019\n",
      "Epoch [56/65], Step [40/63], Loss: 0.0015\n",
      "Epoch [56/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [56/65], Step [60/63], Loss: 0.0016\n",
      "Epoch [57/65], Step [10/63], Loss: 0.0012\n",
      "Epoch [57/65], Step [20/63], Loss: 0.0011\n",
      "Epoch [57/65], Step [30/63], Loss: 0.0015\n",
      "Epoch [57/65], Step [40/63], Loss: 0.0015\n",
      "Epoch [57/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [57/65], Step [60/63], Loss: 0.0013\n",
      "Epoch [58/65], Step [10/63], Loss: 0.0013\n",
      "Epoch [58/65], Step [20/63], Loss: 0.0014\n",
      "Epoch [58/65], Step [30/63], Loss: 0.0014\n",
      "Epoch [58/65], Step [40/63], Loss: 0.0013\n",
      "Epoch [58/65], Step [50/63], Loss: 0.0013\n",
      "Epoch [58/65], Step [60/63], Loss: 0.0013\n",
      "Epoch [59/65], Step [10/63], Loss: 0.0018\n",
      "Epoch [59/65], Step [20/63], Loss: 0.0011\n",
      "Epoch [59/65], Step [30/63], Loss: 0.0015\n",
      "Epoch [59/65], Step [40/63], Loss: 0.0012\n",
      "Epoch [59/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [59/65], Step [60/63], Loss: 0.0014\n",
      "Epoch [60/65], Step [10/63], Loss: 0.0012\n",
      "Epoch [60/65], Step [20/63], Loss: 0.0013\n",
      "Epoch [60/65], Step [30/63], Loss: 0.0011\n",
      "Epoch [60/65], Step [40/63], Loss: 0.0010\n",
      "Epoch [60/65], Step [50/63], Loss: 0.0011\n",
      "Epoch [60/65], Step [60/63], Loss: 0.0011\n",
      "Training:\n",
      "classification acc: 1.000, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.581, rotation pred acc: 0.766\n",
      "Epoch [61/65], Step [10/63], Loss: 0.0013\n",
      "Epoch [61/65], Step [20/63], Loss: 0.0012\n",
      "Epoch [61/65], Step [30/63], Loss: 0.0010\n",
      "Epoch [61/65], Step [40/63], Loss: 0.0015\n",
      "Epoch [61/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [61/65], Step [60/63], Loss: 0.0016\n",
      "Epoch [62/65], Step [10/63], Loss: 0.0013\n",
      "Epoch [62/65], Step [20/63], Loss: 0.0014\n",
      "Epoch [62/65], Step [30/63], Loss: 0.0015\n",
      "Epoch [62/65], Step [40/63], Loss: 0.0012\n",
      "Epoch [62/65], Step [50/63], Loss: 0.0011\n",
      "Epoch [62/65], Step [60/63], Loss: 0.0017\n",
      "Epoch [63/65], Step [10/63], Loss: 0.0011\n",
      "Epoch [63/65], Step [20/63], Loss: 0.0013\n",
      "Epoch [63/65], Step [30/63], Loss: 0.0010\n",
      "Epoch [63/65], Step [40/63], Loss: 0.0014\n",
      "Epoch [63/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [63/65], Step [60/63], Loss: 0.0018\n",
      "Epoch [64/65], Step [10/63], Loss: 0.0013\n",
      "Epoch [64/65], Step [20/63], Loss: 0.0016\n",
      "Epoch [64/65], Step [30/63], Loss: 0.0012\n",
      "Epoch [64/65], Step [40/63], Loss: 0.0011\n",
      "Epoch [64/65], Step [50/63], Loss: 0.0012\n",
      "Epoch [64/65], Step [60/63], Loss: 0.0015\n",
      "Epoch [65/65], Step [10/63], Loss: 0.0012\n",
      "Epoch [65/65], Step [20/63], Loss: 0.0011\n",
      "Epoch [65/65], Step [30/63], Loss: 0.0011\n",
      "Epoch [65/65], Step [40/63], Loss: 0.0011\n",
      "Epoch [65/65], Step [50/63], Loss: 0.0010\n",
      "Epoch [65/65], Step [60/63], Loss: 0.0011\n",
      "Training:\n",
      "classification acc: 1.000, rotation pred acc: 1.000\n",
      "Validation:\n",
      "classification acc: 0.584, rotation pred acc: 0.765\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 65\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_all_loader):\n",
    "        labels_1 = labels[0]\n",
    "        labels_2 = labels[1]\n",
    "        images, labels_1, labels_2 = images.to(device), labels_1.to(device), labels_2.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer1.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        out1, out2 = model1(images)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss1 = criterion1(out1, labels_1)\n",
    "        loss2 = criterion2(out2, labels_2)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer1.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_all_loader)}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    # Update the scheduler\n",
    "#     scheduler.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print('Training:')        \n",
    "        check_accuracy_jointresnet(train_all_loader, model1)    \n",
    "\n",
    "        print('Validation:')        \n",
    "        check_accuracy_jointresnet(val_all_loader, model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "921d4929",
   "metadata": {
    "id": "921d4929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for image classification: 60.33 %\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "correct1 = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out1, _ = model1(images)\n",
    "\n",
    "        # Compute the accuracy for branch\n",
    "        _, predicted = torch.max(out1.data, 1)\n",
    "        correct1 += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print('Accuracy for image classification: {:.2f} %'.format(100 * correct1 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87409d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save({\n",
    "            'model_state_dict': model1.state_dict(),\n",
    "            'optimizer_state_dict': optimizer1.state_dict(),\n",
    "            }, 'models/stl_jointresnet2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac7811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
